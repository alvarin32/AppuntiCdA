\documentclass[a4paper,11pt,titlepage,openright]{book} %usiamo questo comando, con il draft, in fase preliminare per vedere se andiamo fuori riga e dove 
\usepackage[pdftex]{hyperref} %crea l'indice a lato nel pdf
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black}
\usepackage[T1]{fontenc} %usato per gli accenti
\usepackage{geometry} %usato per realizzare una pagina di formato diverso da A4 
\geometry{papersize={17cm,24cm},text={13cm,20cm},centering} 
\usepackage[italian]{babel}
%\usepackage{emptypage}%fa si che nelle pagine vuote non compaia il numero e il fancy
\usepackage{wallpaper} %usato per la copertina
\usepackage{lettrine} %usato per i capolettera
\usepackage{mathrsfs} 
\usepackage{picinpar}%usato per i disegnini a lato
%\usepackage{asymptote} %usato per far funzionare il programma asymptote
\usepackage{pict2e} %usato per le immagini
\usepackage{tikz} %usato per le immagini
\usetikzlibrary{shapes,backgrounds}
\usepackage{dlfltxbcodetips} %usato per la produttoria cartesiana
\usepackage{MnSymbol} %usato per l'unione disgiunta 
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{makeidx} %usato per realizzare l'indice analitico
%\usepackage{showidx} %usato per mostrare, in fase di bozza, l'indice analitico nelle pagine in cui compaiono le voci indicizzate 
\usepackage{fancyhdr} %usato per i margini con i titoli e i numeri di pagina in alto
\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}
\fancyhf{}
\fancyhead[LE,RO]{\bfseries\thepage}
\fancyhead[CO]{\bfseries\rightmark}
\fancyhead[CE]{\bfseries\leftmark}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0pt}
\addtolength{\headheight}{20pt}
\fancypagestyle{plain}{\fancyhead{} \renewcommand{\headrulewidth}{0pt}}
\theoremstyle{definition}
\newtheorem{defin}{Definizione}[section]
\newtheorem{teo}{Teorema}[section]
\newtheorem{cor}{Corollario}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{prop}{Proposizione}[section]
\newtheorem{esem}{Esempio}[section]
\newtheorem{eser}{esercizio}[section]
\newtheorem{oss}{Osservazione}[section]
\newtheorem{defins}{Definizione}[subsection]
\newtheorem{teos}{Teorema}[subsection]
\newtheorem{cors}{Corollario}[subsection]
\newtheorem{lemmas}{Lemma}[subsection]
\newtheorem{props}{Proposizione}[subsection]
\newtheorem{esems}{Esempio}[subsection]
\newtheorem{esers}{esercizio}[subsection]
\newtheorem{osss}{Osservazione}[subsection]
\newtheorem{definss}{Definizione}[section]
\newtheorem{teoss}{Teorema}[section]
\newtheorem{corss}{Corollario}[section]
\newtheorem{lemmass}{Lemma}[section]
\newtheorem{propss}{Proposizione}[section]
\newtheorem{esemss}{Esempio}[section]
\newtheorem{eserss}{esercizio}[section]
\newtheorem{ossss}{Osservazione}[section]
\newcommand{\bfig}{\begin{figure}}
\newcommand{\efig}{\end{figure}}
\newcommand{\bt}{\begin{tikzpicture}}
\newcommand{\et}{\end{tikzpicture}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand{\idefin}{\begin{defin}}
\newcommand{\edefin}{\end{defin}}
\newcommand{\ilemma}{\begin{lemma}}
\newcommand{\elemma}{\end{lemma}\begin{flushright} $\square$ \end{flushright}}
\newcommand{\iesem}{\begin{esem}}
\newcommand{\eesem}{\end{esem}\begin{flushright} $\blacksquare$ \end{flushright}}
\newcommand{\iesems}{\begin{esems}}
\newcommand{\eesems}{\end{esems}\begin{flushright} $\blacksquare$ \end{flushright}}
\newcommand{\iteo}{\begin{teo}}
\newcommand{\eteo}{\begin{flushright} $\square$ \end{flushright} \end{teo}}
\newcommand{\icoro}{\begin{coro}}
\newcommand{\ecoro}{\begin{flushright} $\square$ \end{flushright} \end{coro}}
\newcommand{\icoros}{\begin{coros}}
\newcommand{\ecoros}{\begin{flushright} $\square$ \end{flushright} \end{coros}}
\newcommand{\iprop}{\begin{prop}}
\newcommand{\eprop}{\begin{flushright} $\square$ \end{flushright} \end{prop}}
\newcommand{\iprops}{\begin{props}}
\newcommand{\eprops}{\begin{flushright} $\square$ \end{flushright} \end{props}}
\newcommand{\idefins}{\begin{defins}}
\newcommand{\edefins}{\end{defins}}
\newcommand{\iteos}{\begin{teos}}
\newcommand{\eteos}{\begin{flushright} $\square$ \end{flushright} \end{teos}}
\newcommand{\icoross}{\begin{coross}}
\newcommand{\ecoross}{\begin{flushright} $\square$ \end{flushright} \end{coross}}
\newcommand{\ipropss}{\begin{propss}}
\newcommand{\epropss}{\begin{flushright} $\square$ \end{flushright} \end{propss}}
\newcommand{\idefinss}{\begin{definss}}
\newcommand{\edefinss}{\end{definss}}
\newcommand{\bd}{\begin{displaymath}}
\newcommand{\ed}{\end{displaymath}}
\newcommand{\iesemss}{\begin{esemss}}
\newcommand{\eesemss}{\end{esemss}\begin{flushright} $\blacksquare$ \end{flushright}}
\newcommand{\ioss}{\begin{oss}}
\newcommand{\eoss}{\end{oss}}
\newcommand{\iosss}{\begin{osss}}
\newcommand{\eosss}{\end{osss}}
\newcommand{\iossss}{\begin{ossss}}
\newcommand{\eossss}{\end{ossss}}
\newcommand{\ilemmas}{\begin{lemmas}}
\newcommand{\elemmas}{\end{lemmas}\begin{flushright} $\square$ \end{flushright}}
\newcommand{\prosc}[2]{\langle #1, #2 \rangle}
\newcommand{\prosch}[2]{\big\langle #1, #2 \big\rangle_\h}
\newcommand{\fii}{\varphi}
\newcommand{\fx}{f(x)}
\newcommand{\gx}{g(x)}
\newcommand{\fy}{f(y)}
\newcommand{\zo}{z_0}
\newcommand{\fiix}{\varphi(x)}
\newcommand{\fisx}{\varphi^*(x)}
\newcommand{\fisy}{\varphi^*(y)}
\newcommand{\fisz}{\varphi^*(z)}
\newcommand{\fiixa}{\varphi(|x|)}
\newcommand{\fisxa}{\varphi^*(|x|)}
\newcommand{\fisya}{\varphi^*(|y|)}
\newcommand{\lam}{\lambda}
\newcommand{\Lam}{\Lambda}
\newcommand{\uml}{(1-\lambda)}
\newcommand{\lxpumly}{\lam x +(1-\lam) y}
\newcommand{\lamzu}{\lam\in[0,1]}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\emu}{^{-1}}
\newcommand{\norh}[1]{\|#1\|_\h}
\newcommand{\dimo}{\textsc{Dimostrazione. }}
\newcommand{\Rbar}{\overline{\mathbb{R}}}
\newcommand{\somma}[3]{\sum_{#1=#2}^#3}
\newcommand{\chii}{\textrm{\Large$\chi$\normalsize}}
\newcommand{\lpa}{\mathscr{L}^p(A)}
\newcommand{\lp}{\mathscr{L}^p}
\newcommand{\Lq}{\mathscr{L}^q}
\newcommand{\lia}{\mathscr{L}^\infty(A)}
\newcommand{\li}{\mathscr{L}^\infty}
\newcommand{\lunoi}{\mathscr{L}^1(I)}
\newcommand{\lii}{\mathscr{L}^\infty(I)}
\newcommand{\lunoa}{\mathscr{L}^1(A)}
\newcommand{\luno}{\mathscr{L}^1}
\newcommand{\Lqa}{\mathscr{L}^q(A)}
\newcommand{\inta}{\int_A}
\newcommand{\usp}{{\frac1p}}
\newcommand{\usq}{{\frac1q}}
\newcommand{\intafp}{\int_A|f|^p}
\newcommand{\intagq}{\int_A|g|^q}
\newcommand{\ck}{\mathcal{C}(K)}
\newcommand{\ci}{\mathcal{C}(I)}
\newcommand{\norc}[1]{\|#1\|_{\mathcal C}}
\newcommand{\norlp}[1]{\|#1\|_{\lp}}
\newcommand{\norlq}[1]{\|#1\|_{\Lq}}
\newcommand{\norli}[1]{\|#1\|_{\li}}
\newcommand{\norlu}[1]{\|#1\|_{\luno}}
\newcommand{\norlimsup}[1]{\|#1\|_{\sup}}
\newcommand{\norliminf}[1]{\|#1\|_{\inf}}
\newcommand{\norlim}[1]{\|#1\|_{1}}
\newcommand{\epsi}{{\varepsilon}}
\newcommand{\allora}{\Rightarrow}
\newcommand{\seesolose}{\LeftRightarrow}
\newcommand{\sse}{\subseteq}
\newcommand{\sus}{\subset}
\newcommand{\rapfx}{\frac{|\fx|}{\|x\|}}
\newcommand{\funzlim}{\sup_{x\neq0} \frac{|\fx|}{\|x\|}}
\newcommand{\psuq}{\frac pq}
\newcommand{\deriv}{\frac d {dx}}
\newcommand{\cinf}{\mathcal C^\infty}
\newcommand{\czero}{\mathcal C^0}
\newcommand{\boro}{B(x_0,r)}
\newcommand{\mah}{[???]\index{$???$}}
\newcommand{\Pii}{\mathscr{P}(I)}
\newcommand{\xo}{x_0}
\newcommand{\todebs}{\todeb^*}
\newcommand{\suca}{\mathfrak a}
\newcommand{\sucr}{\mathfrak r}
\newcommand{\sucf}{\mathfrak f}
\newcommand{\sucb}{\mathfrak b}
\newcommand{\suck}{\mathfrak c}
\newcommand{\sucx}{\mathfrak x}
\newcommand{\sucs}{\mathfrak s}
\newcommand{\sucy}{\mathfrak y}
\newcommand{\sucan}{\overline{\mathfrak a}^n}
\newcommand{\cti}{c_i}
\newcommand{\at}[1]{a_{#1}}
\newcommand{\bti}{b^i}
\newcommand{\elp}{\ell^p}
\newcommand{\elq}{\ell^q}
\newcommand{\elu}{\ell^1}
\newcommand{\eli}{\ell^\infty}
\newcommand{\eld}{\ell^2}
\newcommand{\noreld}[1]{\|#1\|_{\ell^2}}
\newcommand{\norelp}[1]{\|#1\|_{\ell^p}}
\newcommand{\norelu}[1]{\|#1\|_{\ell^1}}
\newcommand{\noreli}[1]{\|#1\|_{\ell^\infty}}
\newcommand{\sumui}{\sum_{i=1}^\infty}
\newcommand{\sumu}[1]{\sum_{i=1}^{#1}}
\newcommand{\sumi}[2]{\sum_{#1=#2}^{\infty}}
\hyphenation{qual-si-a-si mi-su-ra-bi-li nu-me-ra-bi-le ne-ces-sa-ria-men-te
me-tri-ca e-si-ste e-qui-va-len-za}
\makeindex
\title{\Huge \textsc{Complementi di Analisi\\ \Large Teoria della misura}}
\author{M. Mariotti, V. Rovera, A. Troni}
\begin{document}
\thispagestyle{empty}
\ThisTileWallPaper{\paperwidth}{\paperheight}{copertina}
\
\newpage
\maketitle
\newpage
\thispagestyle{empty}
\
\newpage
\pagenumbering{Roman}
\tableofcontents
\newpage 
\thispagestyle{empty} \ 
\newpage 
\thispagestyle{empty} \
\newpage
\pagenumbering{arabic}
\begin{chapter}{Incipit}
\lettrine[lines=1]{I}{n questo preambolo} diamo alcune definizioni fondamentali per il seguito, esibendo anche 
qualche esempio ed alcune proposizioncine utili
per poter assimilare adeguatamente questi concetti.
\begin{section}{Prima di cominciare bisogna sapere che...}
\begin{subsection}{Insiemistica}
Cominciamo con una serie di definizioni e di conseguenze delle medesime, la cui 
utilità sarà evidente molto presto:
\begin{defins}
Sia $X$ un insieme qualsiasi. Un sottoinsieme $\mathfrak{S}$ di $2^X$ (insieme delle parti) 
si dice \emph{semianello} se per ogni 
$A,B\in\mathfrak{S}$ si ha
$A\cap B\in\mathfrak{S}$.\index{Semianello}
\end{defins}
\begin{esems} \label{intersezdirett}
L'insieme $\mathfrak{R}$ composto da tutti i rettangoli e da $\emptyset$
è un semianello; siano infatti $P=I_{1}\times I_{2}$ e $Q=J_{1}\times 
J_{2}$ due rettangoli tali che
$I_{1} \cap J_{1} \neq \emptyset$ e $I_{2} \cap J_{2} \neq \emptyset$ 
(se così non è $P\cap Q=\emptyset\in\mathfrak{R}$). Allora
$P \cap Q=(I_{1} \cap J_{1})\times (I_{2} \cap J_{2})$, e siccome l'intersezione di due intervalli
è un intervallo, $P \cap Q$ è un rettangolo.
\end{esems}
Occupiamoci ora di due operazioni tra insiemi, che vanno ad aggiungersi alle gia note unione $\cup$, intersezione 
$\cap$
e differenza $\smallsetminus$. La prima di fatto è solo un caso particolare dell'unione:
\begin{defins}
Dati due insiemi $A$ e $B$, diciamo che $C$ è l'\emph{unione disgiunta di $A$ e $B$}, e scriviamo
$C= A\cupdot B$, se $C=A\cup B$ e $A\cap B=\emptyset$. \index{Unione disgiunta}
\end{defins}
Adesso invece introduciamo una nuova operazione sugli insiemi:
\begin{defins}
Dati due insiemi $A$ e $B$ si dice \emph{differenza simmetrica di $A$ e $B$}, e si indica con
$A \triangle B$, l'insieme
\begin{displaymath}
A \triangle B = (A \cup B) \smallsetminus (A \cap B)=(A\smallsetminus B) \cupdot (B \smallsetminus A).
\end{displaymath}\index{Differenza simmetrica}
\end{defins}
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.2]
\filldraw[fill=green!30!white](-3,0)ellipse(7 and 4);
\filldraw[fill=green!30!white](3,0)ellipse(7 and 4);
\filldraw[fill=white](0,-3.53) arc (-65:65:7 and 4);
\filldraw[fill=white](0,3.53) arc (115:245:7 and 4);
\draw[line width=1.2pt](-3,0)ellipse(7 and 4);
\draw[line width=1.2pt](3,0)ellipse(7 and 4);
\draw(-6,0)node{$A$};
\draw(6,0)node{$B$};
\draw(0,5)node{$A\triangle B$};
\end{tikzpicture}
\caption{La differenza simmetrica $A\triangle B$.}
\end{center}
\end{figure}
\begin{defins}
Sia $X$ un insieme qualsiasi. Un sottoinsieme $\mathfrak{A}$ di $2^X$ si dice \emph{anello} se valgono le seguenti
condizioni: \index{Anello}
\begin{itemize}
\item[$i)$] per ogni $A,B\in\mathfrak{A}$ si ha che $A\cap B\in\mathfrak{A}$;
\item[$ii)$] per ogni $A,B\in\mathfrak{A}$ si ha che $A\triangle B\in\mathfrak{A}$.
\end{itemize}
Se inoltre $X\in\mathfrak{A}$, si dice che $\mathfrak{A}$ è un'\emph{algebra}. In tal caso $X$ si dice
 \emph{unità dell'algebra}. \index{Algebra} \index{Unità!dell'algebra}
\end{defins}
\begin{defins}
Sia $X$ un insieme qualsiasi; preso un semianello $\mathfrak{S}$ di $2^X$, definiamo
\emph{anello minimale costruito sopra $\mathfrak{S}$} l'intersezione $\mathfrak{A}(\mathfrak{S})$
di tutti gli anelli di $X$ contenenti $\mathfrak{S}$. \index{Anello!minimale}
\end{defins}
\begin{props} \label{condizionidianello}
Sia $X$ un insieme e sia $\mathfrak{A}\subset2^{X}$. Allora $\mathfrak{A}$ è un anello se e solo
se per ogni $A,B \in X$ si ha che $A \cup B\in\mathfrak{A}$ e $A \smallsetminus B\in\mathfrak{A}$\\
\newline
\dimo$(\Rightarrow)$ Se $\mathfrak{A}$ è un anello, per ogni $A,B \in\mathfrak{A}$ 
si ha che $A \cap B \in\mathfrak{A}$  e  $A \triangle B \in\mathfrak{A}$; valgono allora le uguaglianze 
$A \cup B = {(A \triangle B)} \triangle {(A \cap B)}$ e $A \smallsetminus B = A \triangle {(A \cap B)}$, 
e ci siamo.\\
$(\Leftarrow)$ Viceversa
sapendo che per ogni $A,B \in\mathfrak{A}$ si ha che $A \cup B \in\mathfrak{A}$ e $A \smallsetminus B \in\mathfrak{A}$, 
si ricavano le relazioni $A \cap B = A \smallsetminus {(A \smallsetminus B)}$
e $A \triangle B = {(A \smallsetminus B)} \cup {(B \smallsetminus A)}$.  
\begin{flushright}
$\square$
\end{flushright}
\end{props} 
\begin{osss}
Grazie alla proposizione  \ref{condizionidianello} possiamo dare un'altra definizione, equivalente, di algebra:
un insieme $\mathfrak{A}\subset 2^X$ è un'algebra su $X$ se
\begin{itemize}
\item[$i)$] $\varnothing\in\mathfrak{A}$ , $X\in\mathfrak{A}$;
\item[$ii)$] Se $\{A_i\}_{i=1}^{n}$ è una famiglia finita di elementi di $\mathfrak{A}$, allora 
$\bigcup_{i=1}^{n}A_i\in\mathfrak{A}$;
\item[$iii)$] Se $A\in\mathfrak{A}$ allora $X\smallsetminus A\in\mathfrak{A}$.
\end{itemize}
\end{osss}
\begin{osss}
Se $\mathfrak{A}$ è chiuso rispetto a unione e intersezione, non necessariamente è un anello: 
ad esempio gli aperti di $\mathbb{R}$ sono chiusi
per unioni qualsiasi e intersezioni finite, ma non costituiscono un anello (infatti scelti $a < c < b < d$ in 
$\mathbb{R}$, allora $(a,b) \triangle (c,d)=(a,c] \cup [b,d)$ non è aperto in $\mathbb{R}$).
\end{osss}
\begin{defins}
Sia $X$ un qualsiasi insieme. Un sottoinsieme $\mathfrak{M}\subset 2^X$ si dice \emph{$\sigma$-anello} se valgono
le seguenti condizioni: \index{$\sigma$-anello}
\begin{itemize}
\item[$i)$] per ogni $A,B\in\mathfrak{M}$ si ha che $A\triangle B\in\mathfrak{M}$;
\item[$ii)$] Se $\{A_i\}_{i=1}^{\infty}$ è una famiglia numerabile di elementi di $\mathfrak{M}$, 
allora $\bigcap_{i=1}^{\infty}A_i\in\mathfrak{M}$.
\end{itemize}
Se in più $X\in\mathfrak{M}$, allora $\mathfrak{M}$ si dice \emph{$\sigma$-algebra} \index{$\sigma$-algebra} 
e, in tal caso, $X$ si dice \emph{unità della $\sigma$-algebra}.\index{Unità!della $\sigma$-algebra}
\footnote{il lettore maestro nella lessicografia
si chiederà sicuramente perchè si usi la lettera $\sigma$ nella definizione di questi insiemi; la ragione è 
che in matematica, per convenzione, essa assurge a prefisso segnalatore del fatto che lavoriamo
con quantità numerabili di oggetti. Troveremo spesso delle $\sigma$-qualcosa nel seguito.}
\end{defins}
\begin{osss}
Come visto nel caso delle algebre, possiamo dare una definizione equivalente di $\sigma$-algebra in tal modo:
un insieme $\mathfrak{M}\subset 2^X$ è una $\sigma$-algebra su $X$ se
\begin{itemize}
\item[$i)$] $\varnothing\in\mathfrak{M}$ , $X\in\mathfrak{M}$;
\item[$ii)$] Se $\{A_i\}_{i=1}^{\infty}$ è una famiglia numerabile di elementi di $\mathfrak{M}$, allora 
$\bigcup_{i=1}^{\infty}A_i\in\mathfrak{M}$;
\item[$iii)$] Se $A\in\mathfrak{M}$, allora $X\smallsetminus A\in\mathfrak{M}$.
\end{itemize}
\end{osss}
\begin{esems}
L'insieme
\begin{displaymath}
\mathfrak{E}:=\Big\{E\subset\mathbb{R}\Big|  E=\bigcup_{i=1}^{n}I_i\quad\textrm{per certi $I_i$ intervalli 
reali}\Big\}
\end{displaymath}
è un'algebra (ovvio e quindi esercizio) ma non una $\sigma$-algebra: infatti gli insiemi del tipo 
$E_k:=(k,k+1)\in\mathfrak{E}$,
ma $\bigcup_{k=1}^{\infty}E_k\notin\mathfrak{E}$.
\end{esems}
\begin{esems}
Sia $X$ un insieme non numerabile. Allora l'insieme
\begin{displaymath}
\mathfrak{F}:=\{\textrm{$F\subset x\ |\  $ solo uno tra $F$ e $X\smallsetminus F$ è al più numerabile}\}
\end{displaymath}
è una $\sigma$-algebra. Dimostriamo che è chiuso rispetto all'unione numerabile (le altre proprietà vengono 
lasciate come esercizio): sia quindi $\{F_n\}_{n\in\mathbb{N}}$ una famiglia di elementi di $\mathfrak{F}$ e 
proviamo che $\bigcup_{n\in\mathbb{N}}F_n\in\mathfrak{F}$; ci sono due possibilità:
\begin{itemize}
\item[$i)$] gli $F_n$ sono tutti numerabili: in tal caso $\bigcup_{n\in\mathbb{N}}F_n$ è numerabile e quindi 
sta in $\mathfrak{F}$; 
\item[$ii)$] esiste $\bar{n}$ tale che $F_{\bar{n}}$ non è numerabile: in tal caso 
$X\smallsetminus F_{\bar{n}}$ è numerabile e quindi
\begin{displaymath}
X\smallsetminus\bigcup_{n\in\mathbb{N}}F_n=(X\smallsetminus F_{\bar{n}})\cap \bigcap_{n\neq\bar{n}}(X
\smallsetminus F_n)\subset X\smallsetminus F_{\bar{n}},
\end{displaymath}
per cui $X\smallsetminus\bigcup_{n\in\mathbb{N}}F_n$ è un insieme numerabile, ergo $\bigcup_{n\in\mathbb{N}}F_n$ 
sta in $\mathfrak{F}$.
\end{itemize}
\end{esems}
\begin{osss}
Si noti che, in generale, l'unione di $\sigma$-algebre non è una $\sigma$-algebra: a titolo di esempio 
sull'insieme $\mathbb{N}\times\mathbb{N}$ si considerino le $\sigma$-algebre $\mathfrak{N}_1:=\{A\times\mathbb{N}
|  A\subset\mathbb{N}\}$ e $\mathfrak{N}_2:=\{\mathbb{N}\times B |  B\subset\mathbb{N}\}$
(verificare come esercizio che tali insiemi sono effettivamente delle $\sigma$-algebre). L'insieme
\begin{displaymath}
\mathfrak{N}_1\cup\mathfrak{N}_2=\{A\times\mathbb{N}\quad\vee\quad \mathbb{N}\times B |  A,B\subset
\mathbb{N}\}
\end{displaymath}
non è però una $\sigma$-algebra: ad esempio non contiene $({\mathbb{N}\times\{0\}})\cup({\{0\}\times
\mathbb{N}})$.
\end{osss}
Tuttavia le $\sigma$-algebre si comportano bene rispetto all'intersezione:
\begin{props}
Sia $X$ un insieme e $\{\mathfrak{M}_j\}_{j\in J}$ una famiglia qualsiasi di $\sigma$-algebre di $X$. 
Allora $\bigcap_{j\in J}\mathfrak{M}_j$
è una $\sigma$-algebra.\\
\newline
\dimo è un fatto ovvio.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
Grazie a questo risultato, possiamo giustificare la seguente definizione:
\begin{defins}
Sia $X$ un insieme qualsiasi e sia $\mathcal C$ un sottoinsieme di $2^X$. Si dice 
\emph{$\sigma$-algebra generata da $\mathcal C$} la più piccola $\sigma$-algebra che contiene $\mathcal C$ 
(i.e. l'intersezione di tutte le $\sigma$-algebre che contengono $\mathcal C$), 
e si indica con $\sigma(\mathcal C)$. \index{$\sigma$-algebra!generata}
\end{defins}
\begin{esems}
Sia $X$ un insieme e $E$ un qualsivoglia suo sottoinsieme. Allora
\begin{displaymath}
\sigma(E)=\{\varnothing,X,E,X\smallsetminus E\}.
\end{displaymath}
Dimostriamolo: poniamo $\mathfrak{L}:=\{\varnothing,X,E,X\smallsetminus E\}$. Questa è una
$\sigma$-algebra contenente $E$ (esercizio banalissimo) e quindi $\mathfrak{L}\supseteq\sigma(E)$.
Viceversa $\sigma(E)$ è una $\sigma$-algebra e quindi possiamo affermare i seguenti fatti:
\begin{itemize}
\item[$i)$] $E\in\sigma(E)$ e quindi $X\smallsetminus E\in\sigma(E)$;
\item[$ii)$] $E\cup (X\smallsetminus E)=X\in\sigma(E)$ e $E\cap (X\smallsetminus E)=\varnothing\in\sigma(E)$.
\end{itemize}
Per cui $\mathfrak{L}\subseteq\sigma(E)$, da cui segue l'uguaglianza. 
\end{esems}
Definiamo adesso una $\sigma$-algebra di vitale importanza in matematica:
\begin{defins}
Sia $\mathcal{T}$ la famiglia degli aperti di $\mathbb{R}$ (i.e. la topologia metrica reale). Definiamo 
\emph{boreliani} di $\mathbb{R}$ (da \'Emile Borel, matematico francese) l'insieme \index{Boreliani di $\mathbb{R}$} \index{Topologia}
\begin{displaymath}
\mathfrak{B}(\mathbb{R}):=\sigma(\mathcal{T}),
\end{displaymath}
cioè la $\sigma$-algebra generata dagli intervalli aperti.
\end{defins}
\begin{lemmas}
Sia $X$ un qualsiasi insieme e siano $\mathcal{C}_1,\mathcal{C}_2$ sottoinsiemi di $2^X$ tali che 
$\mathcal{C}_1\subseteq \mathcal{C}_2$. 
Allora $\sigma(\mathcal{C}_1)\subseteq \sigma(\mathcal{C}_2)$.\\
\newline
\dimo Si ha $\mathcal{C}_1\subseteq\sigma(\mathcal{C}_2)$ e quindi 
$\sigma(\mathcal{C}_1)\subseteq\sigma(\mathcal{C}_2)$.
\begin{flushright}
$\square$
\end{flushright}
\end{lemmas}
\begin{props}
Vale la seguente uguaglianza:
\begin{displaymath}
\mathfrak{B}(\mathbb{R})=\sigma\{(a,+\infty)|  a\in\mathbb{Q}\}.
\end{displaymath}
\dimo Sia $\mathcal{T}$ la topologia euclidea e $\mathcal{Q}:=\{(a,+\infty)|  
a\in\mathbb{Q}\}$; siccome $\mathcal{T}\supset\mathcal{Q}$, 
il lemma precedente ci assicura che $\mathfrak{B}(\mathbb{R})\supseteq\sigma(\mathcal{Q})$. Viceversa possiamo 
scrivere ogni elemento di $\mathcal{T}$ come combinazione di elementi di $\mathcal{Q}$:
\begin{displaymath}
(a,+\infty) = \bigcup_{\substack{b>a\\b\in\mathbb{Q}}}(b,+\infty)\in\sigma(\mathcal{Q});
\end{displaymath}
\begin{displaymath}
[a,+\infty) = \bigcap_{\substack{b<a\\b\in\mathbb{Q}}}(b,+\infty)\in\sigma(\mathcal{Q});
\end{displaymath}
\begin{displaymath}
(-\infty,a)=\mathbb{R}\smallsetminus[a,+\infty)\in\sigma(\mathcal{Q});
\end{displaymath}
\begin{displaymath}
(-\infty,a]=\mathbb{R}\smallsetminus(a,+\infty)\in\sigma(\mathcal{Q});
\end{displaymath}
\begin{displaymath}
(a,b)=(-\infty,b)\cap(a,+\infty)\in\sigma(\mathcal{Q}).
\end{displaymath}
Pertanto $\mathcal T\subseteq \sigma(\mathcal{Q})$ da cui $\mathfrak{B}(\mathbb{R})\subseteq\sigma(\mathcal{Q})$. 
Valendo l'inclusione in entrambi i sensi, si ha l'uguaglianza.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\begin{osss}
Il lettore più intraprendente avrà notato il comportamento alquanto esotico dell'insieme 
$\mathfrak{B}(\mathbb{R})$:
nonostante quest'ultimo abbia potenza superiore al continuo, esso ammette un sistema di generatori numerabile! 
Tuttavia possiamo generarlo
anche con un insieme con la potenza del continuo: infatti si verifica subito che vale anche
\begin{displaymath}
\mathfrak{B}(\mathbb{R})=\sigma\{(a,+\infty)|  a\in\mathbb{R}\}.
\end{displaymath}
E se ne possono trovare molti altri, di generatori (il lettore potrà divertirsi a cercarli, non ci vuole 
particolare fantasia). In generale questa versatilità è comune alle $\sigma$-algebre generate, che risultano
essere quindi oggetti decisamente maneggevoli. 
\end{osss}
Vediamo infine quest'ultimo risultato:
\begin{props}
La $\sigma$-algebra generata dagli intervalli reali coincide con $\mathfrak{B}(\mathbb{R})$.\\
\newline
\dimo Sia $\mathcal{T}$ la topologia euclidea e poniamo 
\begin{displaymath}
\mathcal{I} := \{I\subset\mathbb{R}|  I \textrm{ è un intervallo}\};
\end{displaymath}
allora $\mathcal{T}\subseteq\mathcal{I}$ implica che $\mathfrak{B}(\mathbb{R})\subseteq\sigma(\mathcal{I})$. 
Viceversa, presi $a < b$ reali, seguono le relazioni
\begin{displaymath}
[a,b) = \bigcap_n \Big(a - \frac{1}{n},b\Big)\in\mathfrak{B}(\mathbb{R}),
\end{displaymath}
\begin{displaymath}
(a,b] = \bigcap_n \Big(a,b + \frac{1}{n}\Big)\in\mathfrak{B}(\mathbb{R}), 
\end{displaymath}
\begin{displaymath}
[a,b] = \bigcap_n \Big(a - \frac{1}{n},b + \frac{1}{n}\Big)\in\mathfrak{B}(\mathbb{R}).
\end{displaymath}
Pertanto $\mathcal{I}\subseteq\mathfrak{B}(\mathbb{R})$ da cui 
$\sigma(\mathcal{I})\subseteq\mathfrak{B}(\mathbb{R})$; segue l'uguaglianza.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\end{subsection}
\begin{subsection}{Serie}
Richiamiamo il concetto di serie:
\idefin
Sia ${a_n}_n$ una famiglia infinita di elementi. Definiamo \emph{$k$-esima somma parziale}
\index{Somma parziale} la somma dei primi $k$ termini della famiglia; definiamo \emph{serie}\index{Serie} il limite
delle somme parziali.
\edefin
Non sempre le somme sono date in una forma \lq\lq facile'' da maneggiare: potremmo avere una famiglia di numeri $\{a_\alpha\}_{\alpha\in A}$
indicizzata da un insieme qualsiasi invece che da un insieme di numeri; come facciamo a calcolare $\sum_{\alpha\in A}a_\alpha$? Se 
$A$ è finito è più che semplice, basta numerare gli elementi di $A$ e la somma è presto fatta; se $A$ è numerabile procediamo in 
modo analogo, stabilendo un'\emph{enumerazione di $A$}\index{Enumerazione di un insieme}, cioè assegnando un \lq\lq ordine'' agli $\alpha$ ed,
in termini matematici, stabilendo una corrispondenza biunivoca $e:A\to \N$. A questo punto possiamo scrivere
$$\sum_{\alpha\in A}a_\alpha=\sum_{n=1}^\infty a_{\alpha_n}=\sum_{n=1}^\infty a_n,$$
dove abbiamo posto $ a_{\alpha_n}=a_n$ per alleggerire la notazione; grazie a quanto appena visto, d'ora in poi scriveremo 
sempre $\sum_{n=1}^\infty a_n$ per indicare una somma senza porci problemi di alcun tipo. Diamo ora la seguente
\idefin
Una \emph{permutazione}\index{Permutazione} è una biezione $\pi:\N\to \N$. Sia ora $\sum_{n=1}^\infty a_n$
una serie; si dice \emph{serie permutata}\index{Serie!permutata} la serie $\sum_{n=1}^\infty a_{\pi(n)}$, ove
$\pi$ è una permutazione.
\edefin

\end{subsection}
\end{section}
\end{chapter}
\begin{chapter}{Misure}
\lettrine[lines=1]{C}{ominciamo ora} ad addentrarci nella teoria della misura. Introdurremo
dapprima alcuni strumenti molto semplici e intuitivi che faranno da base per il seguito; tali
risultati hanno validità in $\mathbb{R}^{n}$, ma spesso e volentieri per semplicità di
comprensione converrà ragionare in $\mathbb{R}^{2}$.
\begin{section}{La misura degli insiemi elementari}
\begin{defin}\label{rettangolo}
Si dice \emph{rettangolo $n$-dimensionale} il prodotto cartesiano di $n$ intervalli reali
$I_{k}$:
\begin{displaymath}
R = \bigtimes_{k=1}^{n} I_{k}.\index{Rettangolo}
\end{displaymath}
\end{defin}
Si noti che la definizione non richiede che gli intervalli siano necessariamente tutti
dello stesso tipo (aperti o chiusi), il generico $I_{k}$ può essere anche semichiuso o
semiaperto; per esempio $(2,3]$ in $\mathbb{R}$ e $(3,5)\times[7,9]$ in $\mathbb{R}^{2}$ sono
rettangoli.
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.7]
\draw[line width=1.2pt] (0,1,3)--(3,1,3); 
\filldraw[fill=green!30!white, draw=green!30!white](4,0,3)--(6,0,3)--(6,2,3)--(4,2,3);
\filldraw[fill=green!30!white, draw=green!30!white](7,0,3)--(10,0,3)--(10,0,0)--(7,0,0)--(7,0,3)--(7,1,3)--
(10,1,3)--(10,1,0)--(7,1,0)--(7,1,3)--(10,1,3)--(10,0,3)--(10,0,0)--(10,1,0)--(7,1,0)--(7,0,0);
\draw[line width=1.2pt,dashed](4,0,3)--(6,0,3)--(6,2,3);
\draw[line width=1.2pt](6,2,3)--(4,2,3)--(4,0,3);
\draw[line width=1.2pt](7,0,3)--(10,0,3); 
\draw[line width=1.2pt](7,0,3)--(7,1,3);
\draw[line width=1.2pt](7,0,0)--(7,0,3);
\draw[line width=1.2pt](10,0,0)--(7,0,0); 
\draw[line width=1.2pt](10,1,3)--(10,1,0);
\draw[line width=1.2pt](7,1,0)--(7,1,3); 
\draw[line width=1.2pt](7,1,3)--(10,1,3);
\draw[line width=1.2pt](10,1,3)--(10,0,3);
\draw[line width=1.2pt](10,0,0)--(10,1,0);
\draw[line width=1.2pt](10,1,0)--(7,1,0);
\draw[line width=1.2pt](7,1,0)--(7,0,0);
\draw[line width=1.2pt](10,0,3)--(10,0,0);
\end{tikzpicture}
\caption{Esempi di rettangoli 1,2,3-dimensionali.}
\end{center}
\end{figure}
\newline
Una volta denotato con $\mathfrak{R}$ l'insieme dei rettangoli secondo la definizione 
\ref{rettangolo}, introduciamo ora un
concetto di misura che generalizza le familiari nozioni di area e volume.
\begin{defin}
Sia $R \in \mathfrak{R}$; si definisce \emph{misura} di $R$ la quantità
\begin{displaymath}
m(R) = \prod_{k=1}^{n} (b_{k}-a_{k}),
\end{displaymath}
ove $a_{k}$ e $b_{k}$ sono gli estremi degli intervalli $I_{k}$ della
definizione \ref{rettangolo}. \index{Misura! di un rettangolo}
\end{defin}
Segue immediatamente dalla definizione che la misura $m$ gode delle
seguenti proprietà:
\begin{itemize}
\item[$i)$] $m(R) \geq 0$ per ogni $R \in \mathfrak{R}$; (\emph{non negatività}) \index{Non negatività}
\item[$ii)$] se $R=\bigcupdot_{k=1}^{n} R_{k}$, allora $m(R)=\sum_{k=1}^{n} m(R_{k})$. (\emph{additività})\index{Additività}
\end{itemize}
La dimostrazione di questi fatti di per sè intuitivi è lasciata come
esercizio al lettore. Introduciamo ora un nuovo concetto che generalizza quello di
rettangolo:
\begin{defin}
Si dice \emph{insieme elementare} l'unione di un numero finito di rettangoli disgiunti;
indicheremo l'insieme degli insiemi elementari con $\mathfrak{E}$.\index{Insieme! elementare}
\end{defin}
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.35]
\filldraw[fill=green!30!white, draw=black, line width=1.2pt]
(3,13)--(7,13)--(7,11)--(10,11)--(10,9)--(11,9)--(11,12)--(9,12)--
(9,13)--(14,13)--(14,10)--(17,10)--(17,8)--(15,8)--(15,7)--
(14,7)--(14,6)--(16,6)--(16,7)--(19,7)--(19,6)--(20,6)--
(20,4)--(21,4)--(21,3)--(20,3)--(20,2)--(18,2)--(18,1)--
(16,1)--(16,0)--(15,0)--(15,2)--(17,2)--(17,3)--(18,3)--
(18,4)--(17,4)--(17,5)--(16,5)--(16,4)--(14,4)--(14,2)--
(12,2)--(12,4)--(11,4)--(11,5)--(10,5)--(10,3)--(8,3)--
(8,3)--(8,1)--(6,1)--(6,2)--(4,2)--(4,3)--(2,3)--(2,5)--
(4,5)--(4,6)--(3,6)--(3,7)--(0,7)--(0,9)--(3,9)--(3,10)--
(5,10)--(5,11)--(3,11)--cycle;
\filldraw[fill=green!30!white, line width=1.2pt](18,10)--(18,13)--(21,13)--(21,10)--cycle;
\filldraw[fill=white, line width=1.2pt](5,6)--(5,7)--(6,7)--(6,8)--(7,8)--
(7,7)--(8,7)--(8,6)--(7,6)--(7,5)--(6,5)--(6,6)--cycle;
\draw[thin](3,7)--(3,9);
\draw[thin](4,3)--(4,5);
\draw[thin](5,7)--(5,13);
\draw[thin](6,7)--(6,13);
\draw[thin](6,2)--(6,5);
\draw[thin](6,3)--(8,3);
\draw[thin](7,3)--(7,5);
\draw[thin](8,3)--(8,6);
\draw[thin](7,8)--(14,8);
\draw[thin](10,8)--(10,11);
\draw[thin](8,7)--(11,7);
\draw[thin](8,5)--(10,5);
\draw[thin](11,9)--(14,9);
\draw[thin](12,4)--(14,4);
\draw[thin](14,2)--(14,13);
\draw[thin](15,7)--(15,10);
\draw[thin](11,12)--(11,13);
\draw[thin](16,4)--(16,6);
\draw[thin](16,0)--(16,2);
\draw[thin](17,2)--(18,2);
\draw[thin](18,3)--(20,3);
\draw[thin](18,4)--(21,4);
\draw[thin](19,4)--(19,6);
\draw[thin](17,5)--(19,5);
\draw[thin](11,5)--(11,8);
\draw[thin](4,6)--(5,6);
\draw[thin](6,11)--(7,11);
\draw[thin](20,10)--(20,13);
\draw[thin](18,12)--(21,12);
\end{tikzpicture}
\caption{Esempio di insieme elementare bidimensionale.}
\end{center}
\end{figure}
\begin{teo}
Siano $A$, $B \in \mathfrak{E}$; allora:
\begin{center}
$A \cup B$, $A \cap B$, $A \smallsetminus B$, $A \triangle B \in \mathfrak{E}$.
\end{center}
\dimo
Innanzitutto sappiamo che l'intersezione di due rettangoli è un
rettangolo (vedi l'esempio \ref{intersezdirett}). Siano ora $A$, $B$ due insiemi elementari, ovvero
$A=\bigcupdot_{i} P_{i}$, $B=\bigcupdot_{j} Q_{j}$; segue immediatamente
\begin{displaymath}
A \cap B = \Big(\bigcupdot_{i} P_{i}\Big)\cap\Big(\bigcupdot_{j} Q_{j}\Big) = \bigcupdot_{i,j} (P_{i} \cap Q_{j}),
\end{displaymath}
e i $P_{i} \cap Q_{j}$, per quanto visto, sono rettangoli, sicché $A\cap B\in\mathfrak{E}$.\\
Osserviamo ora che sottraendo un rettangolo $Q$ a un rettangolo $P$ si ottiene un insieme
elementare, da cui segue che sottraendo un insieme elementare ad un rettangolo si ottiene
ancora un insieme elementare.
\newline
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\filldraw[fill=green!30!white, line width=1.2pt](0,0)--(10,0)--(10,8)--(0,8)--cycle;
\filldraw[fill=white, line width=1.2pt](7,7)--(9,7)--
(9,3)--(7,3)--cycle;
\draw[thin](9,0)--(9,8);
\draw[thin](7,0)--(7,8);
\draw[thin](0,7)--(10,7);
\draw[thin](0,3)--(10,3);
\filldraw[fill=green!30!white, line width=1.2pt](15,0)--(25,0)--(25,8)--(15,8)--cycle;
\filldraw[fill=white, line width=1.2pt](18,2)--
(17,2)--(17,5)--(19,5)--(19,4)--(20,4)--(20,3)--(21,3)--(21,4)--(22,4)--(22,7)--(24,7)--
(24,3)--(22,3)--(22,1)--(21,1)--(21,2)--(20,2)--(20,1)--(18,1)--(18,2)--cycle;
\draw[thin](15,2)--(17,2);
\draw[thin](15,5)--(17,5);
\draw[thin](17,8)--(17,5);
\draw[thin](19,8)--(19,5);
\draw[thin](20,8)--(20,4);
\draw[thin](21,8)--(21,4);
\draw[thin](22,8)--(22,7);
\draw[thin](24,8)--(24,7);
\draw[thin](22,0)--(22,1);
\draw[thin](21,0)--(21,1);
\draw[thin](20,0)--(20,1);
\draw[thin](18,0)--(18,1);
\draw[thin](24,3)--(25,3);
\end{tikzpicture}
\end{center}
\end{figure}
\newline
Dati due insiemi elementari $A$ e $B$ è sempre possibile trovare un rettangolo $R$
che li contenga entrambi, e quindi avremo
\begin{center}
$A \cup B = R \smallsetminus ((R \smallsetminus A) \cap (R \smallsetminus B))$,\\
$A \smallsetminus B = A \cap (R \smallsetminus B)$,\\
$A \triangle B = (A \cup B) \smallsetminus (A \cap B)$\\
\end{center}
da cui segue la tesi. \begin{flushright} $\square$ \end{flushright}
\end{teo}
Possiamo ora introdurre una misura su $\mathfrak{E}$, estendendo il concetto di misura
espresso nella precedente definizione:
\begin{defin}
Si definisce \emph{misura di un insieme elementare}, e si indica con $m'$, la quantità
\begin{displaymath}
m'(A) = \sum_{k=1}^{n} m(R_{k}), \index{Misura!di un insieme elementare}
\end{displaymath}
ove $A \in \mathfrak{E}$ e $A=\bigcupdot_{k=1}^{n} R_{k}$.
\end{defin}
Mostriamo che questa definizione è ben posta, nel senso che non dipende dalla
particolare decomposizione in rettangoli di $A$. Sia dunque
\begin{displaymath}
A = \bigcupdot_{i} P_{i} = \bigcupdot_{j} Q_{j};
\end{displaymath}
poiché per opportuni $P_{i}$ e $Q_{j}$ vale $P_{i}=\bigcupdot_{j} (P_{i} \cap Q_{j})$ e
$Q_{j}=\bigcupdot_{i} (P_{i} \cap Q_{j})$, per ogni $i$, $j$ si ha subito
\begin{displaymath}
m(P_{i}) = \sum_{j} m(P_{i} \cap Q_{j}),\quad
m(Q_{j}) = \sum_{i} m(P_{i} \cap Q_{j});
\end{displaymath}
allora
\begin{displaymath}
\sum_{i} m(P_{i}) = \sum_{i,j} m(P_{i} \cap Q_{j}) = \sum_{j} m(Q_{j}) = m'(A).
\end{displaymath}
\begin{oss}
Essendo $m'$ univocamente determinata da $m$, essa ne eredita le proprietà di
non-negatività e additività.
\end{oss}
\begin{defin}
Sia $A$ un insieme e sia $\{A_{n}\}_{n}$ una famiglia al più numerabile di \label{defsubaddit}
insiemi tale che $A \subseteq \bigcup_{n} A_{n}$. Si dice che una misura $\mathfrak{m}$ 
è \emph{subadditiva} se per ogni $A$ e $\{A_n\}_n$ definiti come sopra vale \index{Subadditività}
\begin{displaymath}
\mathfrak{m}(A) \leq \sum_{n} \mathfrak{m}(A_{n}).
\end{displaymath}
\end{defin}
\begin{teo}\textbf{(di subadditività di $m'$)}
La misura $m'$ è subadditiva.\\
\newline
\dimo
Per ogni $\varepsilon >0$ sia $C \subseteq A$ elementare e chiuso tale che 
\begin{equation}
m'(A)\geq m'(C) \geq m'(A) - \frac{\varepsilon}{2}; \label{miscmisa}
\end{equation}
un tale $C$ esiste sempre: poiché possiamo scrivere $A=\bigcupdot_{k} P_{k}$, basta sostituire ogni
$P_{k}$ con un $Q_{k}$ tale che $Q_{k} \subseteq P_{k}$, con $m(P_k)\geq m(Q_{k}) \geq m(P_{k}) -
\varepsilon/2^{k}$, e porre $C=\bigcupdot_k Q_k$. Per motivi analoghi per ogni $n$ si trova
$\tilde{A}_{n}$ elementare aperto tale che $\tilde{A}_{n} \supseteq A_{n}$ e che verifichi 
$m'(A_n)\leq m'(\tilde{A}_{n}) \leq m'(A_{n}) + \varepsilon/2^{n}$. 
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\filldraw[fill=green!30!white, line width=1.2pt]
(0,1)--(0,3)--(2,3)--(2,5)--(4,5)--(4,6)--(3,6)--(3,8)--(5,8)--(5,9)--
(8,9)--(8,7)--(10,7)--(10,5)--(8,5)--(8,4)--(12,4)--(12,2)
--(10,2)--(10,0)--(7,0)--(7,2)--(5,2)--(5,0)--(2,0)--(2,1)--cycle;
\draw[thin](2,1)--(2,3);
\draw[thin](5,2)--(5,9);
\draw[thin](4,6)--(4,8);
\draw[thin](4,5)--(5,5);
\draw[thin](5,4)--(8,4);
\draw[thin](7,2)--(10,2);
\draw[thin](8,5)--(8,7);
\draw(6,5)node{$A$};
\filldraw[fill=green!30!white, line width=1.2pt]
(15+0,1)--(15+0,3)--(15+2,3)--(15+2,5)--(15+4,5)--(15+4,6)--(15+3,6)--(15+3,8)--(15+5,8)--(15+5,9)--
(15+8,9)--(15+8,7)--(15+10,7)--(15+10,5)--(15+8,5)--(15+8,4)--(15+12,4)--(15+12,2)
--(15+10,2)--(15+10,0)--(15+7,0)--(15+7,2)--(15+5,2)--(15+5,0)--(15+2,0)--(15+2,1)--cycle;
\filldraw[fill=green!10!white, line width=1pt,dashed](15+5,8)--(15+8,8)--(15+8,6.5)--(15+9,6.5)--
(15+9,5.5)--(15+8,5.5)--(15+8,4)--(15+11,4)--(15+11,2)--(15+10,2)--(15+10,1)--(15+7,1)--(15+7,2)--
(15+5,2)--(15+5,.5)--(15+2,.5)--(15+2,1.5)--(15+.5,1.5)--(15+.5,2.5)--(15+2,2.5)--(15+2,5)--
(15+4,5)--(15+4,6.5)--(15+3.5,6.5)--(15+3.5,7.5)--(15+5,7.5)--cycle;
\draw[thin](15+2,1)--(15+2,3);
\draw[thin](15+5,2)--(15+5,9);
\draw[thin](15+4,6)--(15+4,8);
\draw[thin](15+4,5)--(15+5,5);
\draw[thin](15+5,4)--(15+8,4);
\draw[thin](15+7,2)--(15+10,2);
\draw[thin](15+8,5)--(15+8,7);
\draw(15+6,5)node{$C$};
\draw[line width=1.2pt]
(15+0,1)--(15+0,3)--(15+2,3)--(15+2,5)--(15+4,5)--(15+4,6)--(15+3,6)--(15+3,8)--(15+5,8)--(15+5,9)--
(15+8,9)--(15+8,7)--(15+10,7)--(15+10,5)--(15+8,5)--(15+8,4)--(15+12,4)--(15+12,2)
--(15+10,2)--(15+10,0)--(15+7,0)--(15+7,2)--(15+5,2)--(15+5,0)--(15+2,0)--(15+2,1)--cycle;
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+2,0)--(30.5+2,-.5)--(30.5+5,-.5)--(30.5+5,0);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+2,.5)--(30.5+-.5,.5)--(30.5+-.5,3.5)--(30.5+2,3.5);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+3,6)--(30.5+2.5,6)--(30.5+2.5,8)--(30.5+3,8);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+4,8)--(30.5+4,8.5)--(30.5+5,8.5)--(30.5+5,8);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+5,9)--(30.5+5,9.5)--(30.5+8,9.5)--(30.5+8,9);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+8,7.5)--(30.5+10.5,7.5)--(30.5+10.5,4.5)--(30.5+8,4.5);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+12,4)--(30.5+12.5,4)--(30.5+12.5,2)--(30.5+12,2);
\filldraw[fill=green!50!white, line width=1pt, dashed](30.5+6.5,2)--(30.5+6.5,-.5)--(30.5+10.5,-.5)--(30.5+10.5,2);
\filldraw[fill=green!30.5!white, line width=1.2pt]
(30.5+0,1)--(30.5+0,3)--(30.5+2,3)--(30.5+2,5)--(30.5+4,5)--(30.5+4,6)--(30.5+3,6)--(30.5+3,8)--(30.5+5,8)--(30.5+5,9)--
(30.5+8,9)--(30.5+8,7)--(30.5+10,7)--(30.5+10,5)--(30.5+8,5)--(30.5+8,4)--(30.5+12,4)--(30.5+12,2)
--(30.5+10,2)--(30.5+10,0)--(30.5+7,0)--(30.5+7,2)--(30.5+5,2)--(30.5+5,0)--(30.5+2,0)--(30.5+2,1)--cycle;
\draw[thin](30.5+2,1)--(30.5+2,3);
\draw[thin](30.5+5,2)--(30.5+5,9);
\draw[thin](30.5+4,6)--(30.5+4,8);
\draw[thin](30.5+4,5)--(30.5+5,5);
\draw[thin](30.5+5,4)--(30.5+8,4);
\draw[thin](30.5+7,2)--(30.5+10,2);
\draw[thin](30.5+8,5)--(30.5+8,7);
\end{tikzpicture}
\caption{L'insieme $A$ ed un esempio di costruzione di $C$ e degli $\tilde{A}_n$.}
\end{center}
\end{figure}
Ovviamente da 
$C \subseteq A$ segue $C \subseteq \bigcup_{n} \tilde{A}_{n}$; ma $C$ è
chiuso e limitato, ed in forza del teorema di Heine-Borel è compatto, quindi
possiamo estrarre dalla copertura aperta $\bigcup_{n} \tilde{A}_{n}$ una sottocopertura finita
$\bigcup_{k=1}^{r} \tilde{A}_{n_{k}}$; è allora chiaro che $m'(C) \leq
\sum_{k=1}^{r} m'(\tilde{A}_{n_{k}})$, da cui, sfruttando la formula \ref{miscmisa}, si conclude
\begin{multline*}
m'(A) \leq m'(C) + \frac{\varepsilon}{2} \leq \sum_{k=1}^{r} m'(\tilde{A}_{n_{k}}) + \frac{\varepsilon}{2}\leq\\
\leq \sum_{n} m'(\tilde{A}_{n}) + \frac{\varepsilon}{2} \leq \sum_{n} m'(A_{n}) + \sum_{n} \frac{\varepsilon}
{2^{n+1}} + \frac{\varepsilon}{2}
\leq \sum_{n} m'(A_{n}) + \varepsilon,
\end{multline*}
\begin{flushright} $\square$ \end{flushright}
\end{teo}
\begin{defin}
Sia $\{A_{n}\}_{n}$ una famiglia numerabile di insiemi elementari; si dice che una
misura $\mathfrak{m}$ è \emph{$\sigma$-additiva} se
\begin{displaymath}
\mathfrak{m}\Big(\bigcupdot_{n=1}^\infty A_{n}\Big) = \sum_{n=1}^\infty \mathfrak{m}(A_{n}). \index{$\sigma$-additività}
\end{displaymath}
\end{defin} 
\begin{teo}\textbf{(di $\sigma$-additività di $m'$)}
La misura $m'$ è $\sigma$-additiva.\\
\newline
\dimo Sia $A$ un insieme elementare e $\{A_{n}\}_{n}$ una famiglia numerabile di insiemi
elementari tale che $A=\bigcupdot_{n=1}^{\infty} A_{n}$; dobbiamo mostrare che
$m'(A) = \sum_{n=1}^{\infty} m'(A_{n})$. Anzitutto segue dal teorema precedente che
\begin{displaymath}
m'(A) \leq \sum_{n=1}^{\infty} m'(A_{n});
\end{displaymath}
viceversa per ogni $N$ fissato risulta $A \supset \bigcupdot_{k=1}^{N} A_{k}$, da cui
\begin{displaymath}
m'(A) \geq m'\Big(\bigcupdot_{k=1}^{N} A_{n}\Big) = \sum_{k=1}^{N} m'(A_{n}),
\end{displaymath}
dove l'ultima eguaglianza è dovuta all'additività di $m'$ ereditata da $m$; così, passando al
limite per $N \to +\infty$, otteniamo
\begin{displaymath}
m'(A) \geq \sum_{n=1}^{\infty} m'(A_{n}).
\end{displaymath} 
\begin{flushright} $\square$ \end{flushright}
\end{teo}
Abbiamo così mostrato esaurientemente che la misura $m'$ gode delle proprietà di \emph{non-negatività},
\emph{additività}, \emph{subadditività} e \emph{$\sigma$-additività}. Sfortunatamente (o per fortuna)
però il mondo non è fatto di soli rettangoli e unioni al più numerabili di
essi, per cui si rende irrinunciabile l'introduzione di ulteriori misure, magari più esotiche,
che ne estendano la classe di applicazione.
\end{section}
\begin{section}{Misura esterna}
\begin{defin} \label{defmisuraest}
Sia $A$ un insieme qualunque; si dice \emph{misura esterna di $A$},
e si indica con $\mu^*$, la quantità \index{Misura!esterna}
\begin{displaymath}
\mu^{*}(A) = \inf_{\substack{A \subseteq \bigcupdot_{k} R_{k}\\R_k\in\mathfrak{R}}} \sum_{k} m(R_{k}).
\end{displaymath}
\end{defin}
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.2]
\filldraw[fill=green!30!white, thin](2,1)--(1,1)--(1,4)--(2,4)--(2,9)--(3,9)
--(3,10)--(4,10)--(4,11)--(5,11)--(5,12)--(4,12)--(4,13)--
(7,13)--(7,14)--(8,14)--(14,14)--(14,15)--(15,15)--(15,14)--(18,14)--
(18,13)--(19,13)--(19,12)--(21,12)--(21,11)--(23,11)--(23,9)--
(23,8)--(24,8)--(24,6)--(26,6)--(26,5)--(25,5)--(25,0)--(23,0)--(23,1)--(19,1)--
(19,2)--(17,2)--(17,1)--(15,1)--(15,3)--(14,3)--(14,2)--
(11,2)--(11,1)--(8,1)--(8,0)--(5,0)--(5,1)--cycle;
\filldraw[fill=white, thin](10,8.5)--(10,9.5)--(11,9.5)--(11,10.5)--(14,10.5)--(14,9.5)--(16,9.5)--(16,7)
--(15,7)--(15,6)--(12,6)--(12,7)--(10,7)--cycle;
\draw[line width=1.2pt](7,2)..controls(3,0)and(0,3)..(4,9)..controls(8,15)and(18,15)..(22,9)..
controls(26,3)and(23,0)..(19,2)..controls(15,4)and(11,4)..(7,2);
\draw[line width=1.2pt](13,8) ellipse (4 and 3);
\draw[thin](5,1)--(5,4);
\draw[thin](5,4)--(2,4);
\draw[thin](5,4)--(6,4);
\draw[thin](6,9)--(6,3);
\draw[thin](5,3)--(8,3);
\draw[thin](6,9)--(2,9);
\draw[thin](8,1)--(8,5);
\draw[thin](6,5)--(11,5);
\draw[thin](11,7)--(11,2);
\draw[thin](6,7)--(10,7);
\draw[thin](6,9)--(10,9);
\draw[thin](4,10)--(10,10);
\draw[thin](5,10)--(5,11);
\draw[thin](8,10)--(8,14);
\draw[thin](5,12)--(8,12);
\draw[thin](10,9)--(10,14);
\draw[thin](7,13)--(7,14);
\draw[thin](11,9.5)--(11,14);
\draw[thin](16,10.5)--(16,14);
\draw[thin](11,10.5)--(16,10.5);
\draw[thin](11,14)--(16,14);
\draw[thin](16,10.5)--(19,10.5);
\draw[thin](18,10.5)--(18,13);
\draw[thin](19,13)--(19,7);
\draw[thin](19,7)--(16,7);
\draw[thin](19,9.5)--(16,9.5);
\draw[thin](21,12)--(21,3);
\draw[thin](21,3)--(19,3);
\draw[thin](19,3)--(19,8);
\draw[thin](19,6)--(11,6);
\draw[thin](7,13)--(7,12);
\draw[thin](11,3)--(19,3);
\draw[thin](21,8)--(23,8);
\draw[thin](21,6)--(24,6);
\draw[thin](21,5)--(25,5);
\draw[thin](23,5)--(23,0);
\draw[thin](19,3)--(23,3);
\draw[thin](19,2)--(23,2);
\draw[thin](17,2)--(17,3);
\draw(3.8,2.7)node{$A$};
\end{tikzpicture}
\caption{L'idea che sta sotto la misura esterna.}
\end{center}
\end{figure}
\begin{oss}
Siccome un insieme elementare è unione disgiunta di rettangoli, la definizione
precedente può essere riformulata come segue:
\begin{displaymath}
\mu^{*}(A) = \inf_{\substack{A \subseteq \bigcupdot_{k} E_{k}\\E_k\in\mathfrak{E}}} \sum_{k} m'(E_{k}).
\end{displaymath}
\end{oss}
Notiamo che $\mu^{*}$ è un'estensione di $m'$, cioé che se ristretta agli insiemi
elementari coincide con essa. Sia infatti $A=\bigcupdot_{k=1}^{N}R_k$; si ha allora
\begin{displaymath}
m'(A) = m'\Big(\bigcupdot_{k=1}^{N}R_k\Big) = \sum_{k=1}^{N} m(R_{k}),
\end{displaymath}
e poiché gli $R_{k}$ costituiscono una copertura per $A$ deve valere, per
definizione,
\begin{displaymath}
\mu^{*}(A) \leq \sum_{k=1}^{N} m(R_{k}) = m'(A);
\end{displaymath}
ora prendiamo delle famiglie al più numerabili $\{Q_{j}^h\}_{j}$ di rettangoli disgiunti tali che
$A \subseteq \bigcupdot_{j} Q^h_{j}$; per subadditività segue $m'(A) \leq
\sum_{j} m(Q^h_{j})$, e quindi
\begin{displaymath}
m'(A) \leq \inf_h {\sum_{j} m(Q^h_{j})} = \mu^{*}(A).
\end{displaymath}
Pertanto deve valere l'uguaglianza.\\
\newline
Estenderemo ora la nozione di subadditività agli insiemi qualsiasi.
\begin{teo} \label{minugusom}
\textbf{(di subadditività di $\mu^*$)} La misura $\mu^*$ è subadditiva.\\
\newline
\dimo Rifacendoci alla definizione \ref{defsubaddit}
prendiamo per ogni $n$ una famiglia di rettangoli $\{R^n_k\}_{k}$ tale che
$A_{n} \subseteq \bigcupdot_{k} R^n_k$; per la definizione \ref{defmisuraest}, è possibile scegliere gli 
$R^n_k$ in modo tale che valga, con $\varepsilon >0$,
\begin{displaymath}
\sum_{k} m(R^n_k) \leq \mu^{*}(A_{n}) + \frac{\varepsilon}{2^{n}},
\end{displaymath}
e da questo si ricava
\begin{displaymath}
\mu^{*}(A) \leq \sum_{n,k} m(R^n_k) \leq \sum_{n} \mu^{*}(A_{n}) + \varepsilon
\end{displaymath}
e la tesi segue dall'arbitrarietà di $\varepsilon$. \begin{flushright} $\square$ \end{flushright}
\end{teo}
Dal teorema precedente segue che, se $A \subseteq B$, allora $\mu^{*}(A) \leq \mu^{*}(B)$.
\end{section}
\begin{section}{Misura di Lebesgue}
\begin{defin}
Un insieme $A$ si dice \emph{misurabile secondo Lebesgue} se per ogni $\varepsilon >0$
esiste un insieme elementare $E$ tale che \index{Insieme!Lebesgue-misurabile}
\begin{displaymath}
\mu^{*}(A \triangle E) \leq \varepsilon.
\end{displaymath}
\end{defin}
D'ora in poi con il termine \emph{misurabile}, intenderemo secondo Lebesgue.
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.25]
\filldraw[fill=green!30!white,line width=1.2pt](2,2)..controls(0,4)and(3,11)..(6,12)..controls(9,14)and(14,6)..
(12,3)..controls(10,0)and(4,0)..(2,2)--(2,2)
--(3,2)--(3,-1)--(6,-1)--(6,1)--(8,1)--(8,-1)--(9,-1)--(9,0)--(10,0)--(10,2)--(12,2)--(12,6)--(14,6)--(14,7)--
(12,7)--(12,8)--(13,8)--(13,9)--(11,9)--(11,12)--(9,12)--(9,11)--(8,11)--(8,12)--(7,12)--(7,11)--
(6,11)--(6,13)--(5,13)--(5,12)--(4,12)--(4,10)--(2,10)--(2,7)--(0,7)--(0,5)--(2,5)--(2,3)--(1,3)--(1,2)--(2,2);
\filldraw[fill=green!30!white, thin](28,-2)--(30,-2)--(30,2.5)--(28,2.5)--cycle;
\filldraw[fill=green!30!white, thin](30,1.5)--(33.5,1.5)--(33.5,3)--(30,3)--cycle;
\filldraw[fill=green!30!white, thin](31.5,3)--(33,3)--(33,7.5)--(31.5,7.5)--cycle;
\filldraw[fill=green!30!white, thin](33,5)--(34.5,5)--(34.5,7.5)--(33,7.5)--cycle;
\filldraw[fill=green!30!white, thin](30.5,7.5)--(33.5,7.5)--(33.5,10)--(30.5,10)--cycle;
\filldraw[fill=green!30!white, thin](28.5,10)--(31.5,10)--(31.5,12.5)--(28.5,12.5)--cycle;
\filldraw[fill=green!30!white, thin](24.5,11)--(28.5,11)--(28.5,13.5)--(24.5,13.5)--cycle;
\filldraw[fill=green!30!white, thin](23.5,9.5)--(24.5,9.5)--(24.5,12.5)--(23.5,12.5)--cycle;
\filldraw[fill=green!30!white, thin](21,8.5)--(23.5,8.5)--(23.5,11)--(21,11)--cycle;
\filldraw[fill=green!30!white, thin](21.5,7.5)--(23,7.5)--(23,8.5)--(21.5,8.5)--cycle;
\filldraw[fill=green!30!white, thin](19.5,4.5)--(22.5,4.5)--(22.5,7.5)--(19.5,7.5)--cycle;
\filldraw[fill=green!30!white, thin](21,3)--(22,3)--(22,4.5)--(21,4.5)--cycle;
\filldraw[fill=green!30!white, thin](20.5,1)--(24,1)--(24,3)--(20.5,3)--cycle;
\filldraw[fill=green!30!white, thin](22.5,-1)--(27,-1)--(27,1)--(22.5,1)--cycle;
\filldraw[fill=green!30!white, thin](27,.5)--(28,.5)--(28,2)--(27,2)--cycle;
\draw[line width=1.2pt](20+2,2)..controls(20+0,4)and(20+3,11)..(20+6,12)..controls(20+9,14)and(20+14,6)..
(20+12,3)..controls(20+10,0)and(20+4,0)..(20+2,2)--(20+2,2)
--(20+3,2)--(20+3,-1)--(20+6,-1)--(20+6,1)--(20+8,1)--(20+8,-1)--(20+9,-1)--(20+9,0)--(20+10,0)--(20+10,2)--
(20+12,2)--(20+12,6)--(20+14,6)--(20+14,7)--(20+12,7)--(20+12,8)--(20+13,8)--(20+13,9)--(20+11,9)--(20+11,12)--
(20+9,12)--(20+9,11)--(20+8,11)--(20+8,12)--(20+7,12)--(20+7,11)--(20+6,11)--(20+6,13)--(20+5,13)--(20+5,12)--
(20+4,12)--(20+4,10)--(20+2,10)--(20+2,7)--(20+0,7)--(20+0,5)--(20+2,5)--(20+2,3)--(20+1,3)--(20+1,2)--(20+2,2);
\draw(7,5)node{$A$};
\draw(15,6)node{$E$};
\draw(0,0)node{$A\triangle E$};
\draw(36,12)node{$\mu^*(A\triangle E)$};
\end{tikzpicture}
\caption{L'idea che sta sotto la misurabilità secondo Lebesgue.}
\end{center}
\end{figure}
\newline
Come si nota nella figura, la misurabilità di un insieme si esprime nell'esistenza
di almeno un insieme elementare tale da approssimare arbitrariamente bene $A$, nel senso
che l'area di $A \triangle B$, quantificata mediante la $\mu^*$ e che rappresenta una sorta 
di scarto tra i due insiemi, è arbitrariamente piccola.
\begin{defin}
Si dice \emph{misura di Lebesgue}, e si denota con $\mu$, la misura $\mu^{*}$ ristretta
all'insieme degli insiemi misurabili secondo Lebesgue. \index{Misura! di Lebesgue}
\end{defin}
Denoteremo con $\mathfrak{M}_{R}$ l'insieme degli insiemi misurabili contenuti
in un insieme limitato $R$ che identificheremo per semplicità con un rettangolo. Ogni insieme
nel seguito sarà tacitamente preso, salvo diverso avviso, da $\mathfrak{M}_{R}$.
\begin{lemma}
Il complementare di un insieme misurabile è misurabile.\\ \label{lemmaompmisemis}
\newline 
\dimo Sia $A$ un insieme misurabile; allora per definizione esiste $E$ 
elementare tale che per
ogni $\varepsilon >0$ si abbia $\mu^{*}(A \triangle E)<\varepsilon$. Ma allora
considerando $A^{C}$ basta prendere $E^{C}$ come insieme elementare e notare che
$A^{C} \triangle E^{C}=A \triangle E$, da cui otteniamo
\begin{displaymath}
\mu^{*}(A^{C} \triangle E^{C}) = \mu^{*}(A \triangle E) < \varepsilon.
\end{displaymath}
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
\begin{teo} \label{teouniintdifdifsimmisurabili}
Unione, intersezione, differenza e differenza simmetrica di un numero finito di insiemi
misurabili sono insiemi misurabili.\\
\newline 
\dimo 
Ovviamente basta dimostrare il teorema per due soli insiemi $A_{1}$ e
$A_{2}$. Per definizione esistono $E_{1}$ e $E_{2}$ elementari tali che, per ogni
$\varepsilon >0$,
\begin{center}
$\mu^{*}(A_{1} \triangle E_{1}) < \varepsilon/2$,\\
$\mu^{*}(A_{2} \triangle E_{2}) < \varepsilon/2$;
\end{center}
\begin{window}[0,r,{\includegraphics[width=3cm,height=1.7cm]{fig1}},{}]
ora,
$(A_{1} \cup A_{2}) \triangle (E_{1} \cup E_{2}) \subseteq (A_{1} \triangle E_{1}) \cup (A_{2} \triangle E_{2})$,
 come si dimostra facilmente per esercizio, e da questo segue (ricordando il teorema \ref{minugusom}) immediatamente
\end{window}
\
\begin{displaymath}
\mu^{*}((A_{1} \cup A_{2}) \triangle (E_{1} \cup E_{2})) \leq \mu^{*}(A_{1} \triangle E_{1}) + 
\mu^{*}(A_{2} \triangle E_{2}) < \varepsilon,
\end{displaymath}
e poiché $E_{1} \cup E_{2}$ è elementare ci siamo: $A_1\cup A_2$ è misurabile. Dunque,
grazie a questo risultato ed al lemma precedente, $A_{1}^{C} \cup A_{2}^{C}$ è
misurabile; questo ci serve perchè vale
$A_{1} \cap A_{2}=(A_{1}^{C} \cup A_{2}^{C})^{C}$ e otteniamo 
così, usando nuovamente il lemma \ref{lemmaompmisemis}, che $A_{1} \cap A_{2}$ è misurabile. Valgono inoltre
\begin{center}
$A_{1} \smallsetminus A_{2} = A_{1} \cap A_{2}^{C}$,\\
$A_{1} \triangle A_{2} = (A_{1} \smallsetminus A_{2}) \cup (A_{2} \smallsetminus A_{1})$,
\end{center}
dalle quali identità, sfruttando quanto esposto sopra, segue la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Ora che abbiamo dimostrato il comportamento ``buono'' degli insiemi misurabili rispetto alla
misura $\mu^{*}$, per poter lavorare in modo ottimale con essa introduciamo il
seguente
\begin{lemma} \label{valassmis}
Per ogni $A$ e $B$ vale
\begin{displaymath}
|\mu^{*}(A) - \mu^{*}(B)|  \leq \mu^{*}(A \triangle B).
\end{displaymath}
\dimo 
Sia dapprima $\mu^{*}(A) \geq \mu^{*}(B)$; dal momento che possiamo scrivere
$A \subseteq A \cup B=B \cup (A \triangle B)$, al solito si ha $\mu^{*}(A) \leq
\mu^{*}(B)+\mu^{*}(A \triangle B)$, e quindi
\begin{displaymath}
\mu^{*}(A) - \mu^{*}(B) \leq \mu^{*}(A \triangle B);
\end{displaymath}
Se invece $\mu^{*}(A) \leq \mu^{*}(B)$, si ripete il ragionamento con
$B \subseteq A \cup (A \triangle B)$ e si perviene a
\begin{displaymath}
\mu^{*}(B) - \mu^{*}(A) \leq \mu^{*}(A \triangle B).
\end{displaymath}
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
\begin{teo}\textbf{(di additività di $\mu$)} La misura $\mu$ è additiva.\\
\newline 
\dimo 
Consideriamo per semplicità il caso $k=2$; la dimostrazione è assolutamente
analoga per valori più grandi di $k$. \\
Poichè $A_{1}$ e $A_{2}$ sono misurabili, dato $\varepsilon >0$ ci sono $E_{1}$ e $E_{2}$ elementari tali che
\begin{center}
$\mu^{*}(A_{1} \triangle E_{1}) < \varepsilon,\quad\mu^{*}(A_{2} \triangle E_{2}) < \varepsilon$.
\end{center}
\begin{window}[0,r,{\includegraphics[width=3cm,height=1.5cm]{fig2}},{}]
$A_{1}$ e $A_{2}$ sono disgiunti per ipotesi, quindi deve necessariamente valere l'inclusione
$E_{1} \cap E_{2} \subseteq (A_{1} \triangle E_{1}) \cup (A_{2} \triangle E_{2})$
da cui segue per subadditività
\end{window}
\
\begin{equation}
m'(E_{1} \cap E_{2}) \leq \mu^{*}(A_{1} \triangle E_{1}) + \mu^{*}(A_{2} \triangle E_{2}) < 2\varepsilon,
\label{propedeuticoam'(E)1}
\end{equation}
ed in forza del lemma \ref{valassmis} si ha anche
\begin{align}
|  m'(E_{1}) - \mu^{*}(A_{1})|  \leq \mu^{*}(A_{1} \triangle E_{1}) < \varepsilon,\label{propedeuticoam'(E)2}\\
|  m'(E_{2}) - \mu^{*}(A_{2})|  \leq \mu^{*}(A_{2} \triangle E_{2}) < \varepsilon. \label{propedeuticoam'(E)3}
\end{align}
Ora, grazie alle formule \ref{propedeuticoam'(E)1}, \ref{propedeuticoam'(E)2} e \ref{propedeuticoam'(E)3}, 
ponendo $E=E_1\cup E_2$ vale \footnote{cercare per esercizio di dimostrare la seconda uguaglianza; se non ci si riesce, la dimostrazione generale
è fornita nella proposizione \ref{proprietàmisura}}
\begin{displaymath} 
m'(E)=m'(E_{1} \cup E_{2}) = m'(E_{1}) + m'(E_{2}) - m'(E_{1} \cap E_{2}) \geq \mu^{*}(A_{1}) + \mu^{*}(A_{2}) - 
4\varepsilon;
\end{displaymath}
sfruttando la relazione $(A_{1} \cup A_{2}) \triangle (E_{1} \cup E_{2}) \subseteq
(A_{1} \triangle E_{1}) \cup (A_{2} \triangle E_{2})$, già vista nel teorema \ref{teouniintdifdifsimmisurabili}
si ha, ponendo $A=A_1\cup A_2$,
\begin{displaymath}
\mu^*(A\triangle E)=\mu^{*}((A_{1} \cup A_{2}) \triangle (E_{1} \cup E_{2})) \leq \mu^{*}(A_{1} \triangle E_{1}) + \mu^{*}(A_{2} 
\triangle E_{2}) < 2\varepsilon.
\end{displaymath}
Ora, mettiamo insieme tutto ciò: applicando di nuovo il lemma \ref{valassmis} abbiamo
$$|  m'(E) - \mu^{*}(A)|  \leq \mu^{*}(A \triangle E)<2\varepsilon,$$
da cui segue, grazie alle uguaglianze su $m'(E)$ e $\mu^*(A\triangle E)$ ricavate prima,
$$\mu^{*}(A) \geq m'(E) - \mu^{*}(A \triangle E) \geq \mu^{*}(A_{1}) + \mu^{*}(A_{2}) - 6\varepsilon.$$
Poiché $\varepsilon$ è arbitrario segue $\mu^{*}(A) \geq
\mu^{*}(A_{1})+\mu^{*}(A_{2})$ e per la subadditività di $\mu^{*}$ deve valere anche la
disuguaglianza opposta, da cui
\begin{displaymath}
\mu^{*}(A) = \sum_{k=1}^{n} \mu^{*}(A_{k}).
\end{displaymath}
Inoltre poiché $A_{1}$ e $A_{2}$ sono misurabili si conclude $\mu^{*}(A)=\mu(A)$.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Da questo teorema segue che se $A$ è misurabile, lo è anche $\mu(A^{C})$:
\begin{displaymath}
\mu(R) = \mu((R \smallsetminus A) \cupdot A) = \mu(R \smallsetminus A) + \mu(A) = \mu(A^{C}) + \mu(A).
\end{displaymath}
\begin{teo}
Unione e intersezione di un'infinità numerabile di insiemi misurabili sono ancora insiemi
misurabili.\\
\newline \dimo 
Consideriamo una famiglia infinita numerabile $\{A_{n}\}_{n\in\mathbb{N}}$ di insiemi misurabili e sia
$A=\bigcup_{n=1}^{\infty} A_{n}$. Definiamo
$\{{\widehat{A}}_{n}\}_{n\in\mathbb{N}}$ come segue:
\begin{center}
$\widehat{A}_{1} = A_{1}$, $\widehat{A}_{2}=A_2\smallsetminus A_{1}$, $\ldots$, $\widehat{A}_{n} = A_{n}
\smallsetminus \bigcup_{k=1}^{n-1} A_{k}, \quad n=2, \ldots$
\end{center}
in modo tale che si abbia ancora $A=\bigcup_{n=1}^{\infty} \widehat{A}_{n}$, però
$\widehat{A}_{i} \cap \widehat{A}_{j}=\emptyset$ se $i \neq j$. Per i risultati
ottenuti nei teoremi precedenti, gli $\widehat{A}_{n}$ sono ancora misurabili e vale
\begin{displaymath}
\sum_{n=1}^{k} \mu(\widehat{A}_{n}) = \mu\Big(\bigcupdot_{n=1}^{k} 
\widehat{A}_{k}\Big) \leq \mu^{*}(A) < +\infty,
\end{displaymath}
il che implica la convergenza della serie $\sum_{n=1}^{\infty} \mu(\widehat{A}_{n})$,cioé
\begin{displaymath}
\forall \varepsilon >0 \quad \exists N : \sum_{n \geq N} \mu(\widehat{A}_{n}) < \frac{\varepsilon}{2}.
\end{displaymath}
L'insieme $C=\bigcupdot_{n=1}^{N} \widehat{A}_{n}$ è unione finita di insiemi
misurabili e quindi è misurabile, cioé per definizione esiste $E$
elementare tale che, per $\varepsilon >0$, $\mu^{*}(C \triangle E) <
\varepsilon/2$. Scrivendo l'inclusione opportuna $A \triangle E \subseteq
(C \triangle E) \cup (\bigcup_{n > N}(\widehat{A}_{n}))$ ricaviamo
\begin{center}
$\mu^{*}(A \triangle E) < \varepsilon/2 + \varepsilon/2 = \varepsilon$,
\end{center}
e da questo segue che $A$ è misurabile. Finiamo notando che
$\bigcup_{n} A_{n}=(\bigcap_{n} A_{n}^{C})^{C}$ e ricordando che il complementare di un insieme
misurabile è misurabile.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{oss} \textbf{(Importante!)} Notiamo che, quasi senza accorgercene, abbiamo dimostrato che 
$\mathfrak{M}_R$ è una $\sigma$-algebra: infatti $\varnothing$ e $R$ sono misurabili; grazie al lemma
\ref{lemmaompmisemis} abbiamo la chiusura per complementazione; infine, il teorema testé dimostrato
ci fornisce la chiusura per unioni numerabili. Dunque $\mu$ è definita su una $\sigma$-algebra.
\color{red} CONCLUDERE APPROPRIATAMENTE \color{black} \label{misurasusigmaalgebra}
\end{oss}
\begin{teo}\textbf{(di $\sigma$-additività di $\mu$)} La misura $\mu$ è $\sigma$-additiva.\\
\newline 
\dimo 
Sappiamo che per ogni $N$ fissato vale
\begin{displaymath}
\mu\Big(\bigcupdot_{k=1}^{N}A_k\Big) = \sum_{k=1}^{N} \mu(A_{k}) < \mu(A),
\end{displaymath}
da cui passando al limite per $N \to +\infty$
\begin{displaymath}
\lim_{n \to \infty} \sum_{k=1}^{N} \mu(A_{k}) = \sum_{k=1}^{\infty} \mu(A_{k}) \leq \mu(A),
\end{displaymath}
ma il teorema \ref{minugusom} ci dice che $\mu(A) \leq \sum_{k=1}^{\infty} \mu(A_{k})$, e ci siamo.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Ed ora un teorema uno e bino (nel senso che è contemporaneamente un teorema, ma anche una definizione):
\begin{teo}\textbf{(di continuità di $\mu$)}
\begin{itemize}
\item[$i)$] Siano $A_{1} \supseteq A_{2} \supseteq \ldots \supseteq A_{n} \supseteq \ldots$
insiemi misurabili e $A=\bigcap_{n} A_{n}$; allora $\mu(A)=\lim_{n\to \infty} \mu(A_{n})$;
\item[$ii)$] Siano $A_{1} \subseteq A_{2} \subseteq \ldots \subseteq A_{n} \subseteq \ldots$
insiemi misurabili e $A=\bigcup_{n} A_{n}$; allora $\mu(A)=\lim_{n\to \infty} \mu(A_{n})$.
\end{itemize}
\dimo 
\begin{itemize}
\item[$i)$] Anzitutto senza perdere in generalità possiamo ridurci al caso in cui
$A=\emptyset$; in caso contrario basterebbe ridefinire gli $A_{n}$ ponendo
$\widehat{A}_{n}=A_{n} \smallsetminus A$. Se $A=\emptyset$,
$\mu(A)=\mu(\emptyset)=0$. Possiamo scrivere
\begin{center}
$A_{1} = (A_{1} \smallsetminus A_{2}) \cupdot (A_{2} \smallsetminus A_{3}) \cupdot \ldots \cupdot (A_{k} \smallsetminus
A_{k+1}) \cupdot \ldots$\\ 
$A_{n} = (A_{n} \smallsetminus A_{n+1}) \cupdot (A_{n+1} \smallsetminus A_{n+2}) \cupdot \ldots \cupdot (A_{n+k} 
\smallsetminus A_{n+k+1}) \cupdot \ldots$
\end{center}
in modo tale che gli $A_{k} \smallsetminus A_{k+1}$ siano disgiunti e quindi valga
\begin{equation}
\mu(A_{1}) = \sum_{k=1}^{\infty} \mu(A_{k} \smallsetminus A_{k+1}),  \label{seriequellallà1}
\end{equation}
\newline
ed in generale
\begin{equation}
\mu(A_{n}) = \sum_{k=n}^{\infty} \mu(A_{k} \smallsetminus A_{k+1}).  \label{seriequellallà2}
\end{equation}
La serie \ref{seriequellallà1} converge, perché $\mu(A_{1})<+\infty$ e quindi la serie 
\ref{seriequellallà2}, essendo
il resto di \ref{seriequellallà1}, tende a $0$ per $n$ che tende a $+\infty$, il che equivale a
\begin{displaymath}
\lim_{n\to \infty} \mu(A_{n}) = 0 = \mu(A).
\end{displaymath}
\item[$ii)$] Consideriamo i complementari degli $A_{n}$: $A=\bigcup_{n} A_{n}=(\bigcap_{n} A_{n}^{C})^{C}$,
da cui
\begin{displaymath}
\lim_{n\to \infty} \mu\Big(\Big(\bigcap_{n} A_{n}^{C}\Big)^{C}\Big) 
= \mu(R) - \lim_{n\to \infty} \mu\Big(\bigcap_{n} A_{n}^{C}\Big) = \mu(R) - \mu(A^{C}) = \mu(A).
\end{displaymath}
\end{itemize}
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\end{section}
\begin{section}{Insiemi misurabili}
Quello che ci proponiamo di fare in questa sezione è di dare alcuni teoremi specifici che caratterizzano gli insiemi
misurabili; dimostreremo anche che esiste un insieme non misurabile. Cominciamo con un lemma:
\ilemma Sia $A\sus \R$ un insieme aperto e limitato; allora $A$ è unione disgiunta al più numerabile di intervalli (eventualmente \label{apertounioneintervalli}
vuoti)\\
\newline
\dimo Su $A$, stabiliamo la relazione $\sim$: diremo che $x\sim y$ se esiste un intervallo $I$
contenuto in $A$ (questo è fondamentale se no scivoliamo nel caso più banale possibile) cui
appartengono $x$ e $y$. Tale relazione, si vede subito, è di equivalenza per cui possiamo
quozientare $A$ rispetto a $\sim$; le classi di equivalenza sono degli intervalli aperti. 
Ora, ognuno di questi intervalli contiene certamente un razionale (altrimenti non sarebbe un intervallo) e 
poichè per costruzione le classi di equivalenza sono una partizione per $A$, ogni razionale in $A$ sta in 
uno ed un solo intervallo e per questa ragione possiamo costruire infinite applicazioni iniettive tutte diverse
(di volta in volta ben definite, basta scegliere prima il rappresentante di ogni classe)
da $A/\sim$ a $\Q$, e ci siamo.  
\elemma
Ora, grazie a questo lemma possiamo dimostrare che ogni aperto e limitato di $\R$ è misurabile, in quanto unione
di insiemi misurabili. Questo risultato in realtà si può migliorare: si può dimostrare (ma non lo faremo) che
\emph{ogni insieme aperto in $\R^n$ è misurabile;} in particolare dunque tutti i boreliani di $\R$ sono misurabili.
\iprop
Se $A$ è misurabile, per ogni $\epsi>0$ esiste un aperto $B_\epsi\supset A$ tale che $\mu(B_\epsi)<\mu(A)+\epsi.$ \\
\newline
\dimo Per la misurabilità di $A$, per ogni $\epsi>0$ esiste $E=\bigcupdot_{k=1}^nR_k$ elementare tale che $\mu^*(A\triangle E)<\epsi.$
Ora, a meno di eventuali riordine di indici, sicuramente esiste $N$ tale che $\bigcupdot_{k=N+1}^n R_k\supset (A\triangle B)$ (basta
\lq\lq allontanarsi'' della frontiera di $A$); sostituiamo tutti gli $R_k$ con dei rettangoli aperti $R_k^\epsi$ tali che
$m(R_k^\epsi)<m(R_k)+\epsi/2^k$ e tali che la loro unione $B_\epsi$ ricopra $A$. A questo punto l'unione degli
$R_k^\epsi$ è aperta, ricopre $A$ ed in più per la sua misura si ha 
$$\mu\Big(\bigcup_{k=1}^n R_k^\epsi \Big)<\mu(A)+2\epsi.$$
\eprop
\iprop Ogni insieme numerabile ha misura nulla.\\
\newline
Sia $A=\{a_1,a_2,a_3,\ldots\}$ il nostro insieme numerabile; possiamo scrivere
$$A\sse \bigcup_{n=1}^\infty \Big(a_n-\frac\epsi{2^{n+1}},a_n+\frac\epsi{2^{n+1}}\Big);$$
ora per subadditività abbiamo $\mu(A)\leq \sum_{n=1}^\infty \epsi/2^n=\epsi$ e siccome questo vale
per ogni $\epsi$, da cui $\mu(A)=0.$
\eprop
Veniamo ora al risultato che forse incuriosisce di più: l'esistenza di insiemi non misurabili. Prima un lemma che non dimostriamo:
\ilemma Se $A$ è misurabile, l'insieme $x+A=\{x+y|\ y\in A\}$ è misurabile e $\mu(A)=\mu(x+A)$ (ovvero la misura di Lebesgue
è \emph{invariante per trasalazioni}).\index{Invarianza per traslazioni} \label{mistrasl}
\end{lemma}
\iteo
Esistono insiemi non misurabili.\\
\newline
\dimo Prendiamo l'intervallo $x=[0,1]$ e definiamo la relazione di equivalenza $x\sim y \Leftrightarrow x-y\in \Q;$ consideriamo
ora $X/\sim$ e creiamo l'insieme $A$ prendendo da ogni classe di equivalenza un rappresentante ($A$ è noto come
\emph{insieme di Vitali}).\index{Insieme!di Vitali} Per costruzione di $A$, se 
$x,y\in A$ allora $x-y\not\in\Q.$ Sia ora $B=[-1,1]\cap \Q=\{r_n\}_{n\in\N}$ e consideriamo l'insieme
$A+B=\{x+r|\ x\in A,r\in B\}$; avremo $[0,1]\sus A+B \sus [-1,2]$. Dimostriamo che vale \footnote{per comodità lavoriamo con
$A$ e $A+r_n$, ma il risultato vale tale e quale anche con $A+r_n$ e $A+r_{n+p}$, cioè nel caso del tutto generico.}
$$A+B=\bigcupdot_{n=1}^\infty (A+r_n):$$
Che $A+B$ sia unione non è un problema, bisogna dimostrare che è disgiunta: per farlo supponiamo che
esista $z\in A\cap (A+r_n)$; allora $z=w+r_n$ per un certo $w\in A$, cioè $z-w\in \Q$, ma questo è assurdo perchè
per costruzione di $A$ ciò è contradditorio. Con questo risultato ben stretto in mano, osserviamo che
se $A$ fosse misurabile allora anche $A+B$, unione di traslati di $A$ (misurabili per il lemma \ref{mistrasl}), sarebbe
misurabile, di misura finita (perchè $[0,1]\sus A+B \sus [-1,2]$) e per l'esattezza avremmo
$$\mu(A+B)=\sum_{n=1}^\infty \mu(A+r_n)=\sum_{n=1}^\infty \mu(A);$$
ma in questo caso abbiamo uguagliato una quantità finita, $\mu(A+B)$ ad una somma infinita di costanti, $\mu(A)$, per cui
necessariamente $\mu(A+B)=\mu(A)=0$. Ora, intuitivamente (tra poco, nell'osservazione \ref{completezzadimu}, lo dimostreremo rigorosamente), 
se un insieme misurabile $\Xi$
è contenuto in un altro insieme misurabile $\Omega$ di misura nulla, anche $\mu(\Xi)$ sarà nulla; noi ci troviamo in questo caso,
perchè $[0,1]\sus A+B$ e $\mu(A+B)=0$, per cui $[0,1]$ avrebbe misura nulla, assurdo. Dunque $A$ non è misurabile.
\eteo
\end{section}
\begin{section}{Ulteriori concetti sulla misura di Lebesgue}
\begin{subsection}{Misura interna}
\begin{defins}
Sia $A$ un insieme contenuto in un rettangolo $R$. Si dice \emph{misura interna} di $A$ 
la quantità $\mu_{*}(A)=\mu^{*}(R)-\mu^*(R\smallsetminus A)$. \index{Misura!interna}
\end{defins}
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.4]
\filldraw[fill=green!30!white,line width=1.2pt](0,0)--(13,0)--(13,10)--(0,10)--cycle;
\filldraw[fill=white, thin](0,0)--(3,0)--(3,1)--(0,1)--cycle;
\filldraw[fill=white, thin](0,1)--(1,1)--(1,4)--(0,4)--cycle;
\filldraw[fill=white, thin](1,3)--(4,3)--(4,4)--(1,4)--cycle;
\filldraw[fill=white, thin](3,3)--(4,3)--(4,0)--(3,0)--cycle;
\filldraw[fill=white, thin](1,1)--(3,1)--(3,3)--(1,3)--cycle;
\filldraw[fill=white, thin](4,0)--(5.5,0)--(5.5,3)--(4,3)--cycle;
\filldraw[fill=white, thin](5.5,0)--(6.5,0)--(6.5,2.5)--(5.5,2.5)--cycle;
\filldraw[fill=white, thin](6.5,0)--(10,0)--(10,2)--(6.5,2)--cycle;
\filldraw[fill=white, thin](10,0)--(13,0)--(13,1)--(10,1)--cycle;
\filldraw[fill=white, thin](12,1)--(13,1)--(13,6)--(12,6)--cycle;
\filldraw[fill=white, thin](10,1)--(12,1)--(12,3)--(10,3)--cycle;
\filldraw[fill=white, thin](10.5,6)--(13,6)--(13,10)--(10.5,10)--cycle;
\filldraw[fill=white, thin](7.5,9)--(10.5,9)--(10.5,10)--(7.5,10)--cycle;
\filldraw[fill=white, thin](7,7)--(10.5,7)--(10.5,9)--(7,9)--cycle;
\filldraw[fill=white, thin](8,6)--(10.5,6)--(10.5,7)--(8,7)--cycle;
\filldraw[fill=white, thin](9,3)--(12,3)--(12,6)--(9,6)--cycle;
\filldraw[fill=white, thin](8.5,4.5)--(9,4.5)--(9,6)--(8.5,6)--cycle;
\filldraw[fill=white, thin](9,2.5)--(9,3)--(10,3)--(10,2.5)--cycle;
\filldraw[fill=white, thin](8.5,2)--(10,2)--(10,2.5)--(8.5,2.5)--cycle;
\filldraw[fill=white, thin](5.5,9)--(7.5,9)--(7.5,10)--(5.5,10)--cycle;
\filldraw[fill=white, thin](5.5,8)--(7,8)--(7,9)--(5.5,9)--cycle;
\filldraw[fill=white, thin](5.5,7.5)--(5.5,10)--(5,10)--(5,7.5)--cycle;
\filldraw[fill=white, thin](5,7)--(5,10)--(4.5,10)--(4.5,7)--cycle;
\filldraw[fill=white, thin](4.5,6.5)--(4.5,10)--(4,10)--(4,6.5)--cycle;
\filldraw[fill=white, thin](2,10)--(4,10)--(4,5.5)--(2,5.5)--cycle;
\filldraw[fill=white, thin](0,4)--(3,4)--(3,5.5)--(0,5.5)--cycle;
\filldraw[fill=white, thin](0,5.5)--(2,5.5)--(2,7.5)--(0,7.5)--cycle;
\filldraw[fill=white, thin](0,7.5)--(2,7.5)--(2,10)--(0,10)--cycle;
\draw[line width=1.2pt](6,2)..controls(2,3.5)and(2,5)..(4,7)..controls(6,9)and(7.5,9)..(9,5)..
controls(10.5,2)and(8,1)..(6,2);
\draw[line width=1.2pt](0,0)--(13,0)--(13,10)--(0,10)--cycle;
\draw(0.5,0.5)node{$R$};
\draw(3,7)node{$A$};
\draw(10.6,8)node{$\mu^*(R\smallsetminus A)$};
\draw(6,5)node{$\mu_*(A)$};
\end{tikzpicture}
\caption{L'idea che sta sotto la misura interna}
\end{center}
\end{figure}
Possiamo caratterizzare gli insiemi Lebesgue-misurabili attraverso la mi\-su\-ra esterna e quella interna; vale
infatti il seguente risultato:
\begin{props}
Sia $A$ un qualsiasi insieme contenuto in un rettangolo $R$. Allora:
\begin{itemize}
\item[$i)$] $\mu_{*}(A)\leq \mu^{*}(A)$;
\item[$ii)$] $A$ è misurabile se e solo se $\mu_{*}(A)=\mu^{*}(A)$.
\end{itemize}
\dimo$i)$ Siccome $R = A\cup {(R\smallsetminus A)}$ allora la subadditivtà di $\mu^*$ implica 
che $\mu^*(R)\leq\mu^*(A)+\mu^*(R\smallsetminus A)$,
da cui $\mu^*(A)\geq \mu^*(R)-\mu^*(R\smallsetminus A)=\mu_*(A)$.\\
$ii)$ $(\Rightarrow)$ Se $A$ è misurabile allora anche $R\smallsetminus A$ è misurabile e vale la relazione
$$\mu^*(R\smallsetminus A)=\mu(R\smallsetminus A)=\mu(R)-\mu(A)=\mu^*(R)-\mu^*(A)$$
da cui segue $\mu^*(A)=\mu^*(R)-\mu^*(R\smallsetminus A):=\mu_*(A)$.\\ 
$(\Leftarrow)$ Viceversa se $\mu_{*}(A)=\mu^{*}(A)$ allora valgono entrambe le relazioni 
$$\mu^*(R)=\mu_*(A)+\mu^*(R\smallsetminus A)=\mu^*(A)+\mu^*(R\smallsetminus A)$$
$$\mu^*(R)=\mu^*(A\cupdot{(R\smallsetminus A)}).$$
Siccome abbiamo scelto $A$ arbitrariamente segue che la misura $\mu^*$ è additiva; per cui $\mu^*\equiv \mu$ e
quindi $A$ è misurabile.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\end{subsection}
\begin{subsection}{Misurabilità degli insiemi illimitati}
Acceniamo ora al concetto di insieme misurabile nel caso in cui questo sia illimitato (i.e. non esiste un 
rettangolo $R$ di misura finita che contenga l'insieme):
\begin{defins}\label{defmisill}
Sia $A$ un insieme illimitato $n$-dimensionale. Partizioniamo $\mathbb{R}^n$ in 
un infinità numerabile di rettangoli di misura finita $\{R_n\}_{n\in\mathbb{N}}$ (per esempio, nel caso della figura
a pagina \pageref{figuraillimit} abbiamo ``quadrettato'' $\mathbb{R}^2$). 
Si dice che $A$ è \emph{misurabile} se per ogni $n$ 
l'insieme $R_n\cap A$ è un misurabile; in tal caso si pone 
\index{Misura!di insiemi illimitati} 
$$\mu(A):=\sum_{n=1}^\infty \mu(R_n\cap A).$$
\end{defins}
\begin{figure}[h!] \label{figuraillimit}
\begin{center}
\begin{tikzpicture}[scale=0.3]
\fill[green!30!white](0,0)..controls(6,2)and(15,2)..(21,0)--
(21,1)..controls(15,3)and(12,12)..(12,15)--(11,15)..controls(11,12)and(6,3)..(0,1)--cycle;
\draw[line width=1.2 pt](0,0)..controls(6,2)and(15,2)..(21,0);
\draw[line width=1.2 pt](21,1)..controls(15,3)and(12,12)..(12,15);
\draw[line width=1.2 pt](11,15)..controls(11,12)and(6,3)..(0,1);
\shade[bottom color=green!30!white, top color=white](11,15)--(12,15)--(12,17)--(11,17)--cycle; 
\shade[left color=green!30!white, right color=white](21,0)--(23,-0.6)--(23,0.4)--(21,1)--cycle; 
\shade[right color=green!30!white, left color=white](0,0)--(-2,-0.6)--(-2,0.4)--(0,1)--cycle; 
\draw[dashed,line width=1.2 pt](12,15)--(12,17);
\draw[dashed,line width=1.2 pt](11,15)--(11,17);
\draw[dashed,line width=1.2 pt](21,0)--(23,-0.6);
\draw[dashed,line width=1.2 pt](23,0.4)--(21,1);
\draw[dashed,line width=1.2 pt](0,0)--(-2,-0.6);
\draw[dashed,line width=1.2 pt](-2,0.4)--(0,1);
\draw[step=4cm, thin] (-3,-2) grid (24.9,17.9);
\draw(3,3.5)node{$A$};
\end{tikzpicture}
\caption{L'idea che sta sotto la misura degli insiemi illimitati}
\end{center}
\end{figure}
\begin{osss}
Come nel caso degli insiemi limitati, si indica con $\mathfrak{M_{\infty}}$ l'insieme degli insiemi illimitati 
misurabili. Affinchè la definizione \ref{defmisill} sia ben posta dobbiamo mostrare che $\mathfrak{M_{\infty}}$ è
una $\sigma$-algebra: a titolo d'esempio proviamo che $\mathfrak{M_{\infty}}$ è chiusa rispetto all'unione numerabile; 
la verifica delle altre proprietà viene lasciata come esercizio. Siano allora $\{A_n\}_{n\in\mathbb{N}}$ una 
famiglia di insiemi in $\mathfrak{M_{\infty}}$ e consideriamo l'insieme $\bigcup_n A_n$: allora per ogni 
rettangolo $R$ di misura finita vale la relazione 
\begin{displaymath}
R\cap \Big(\bigcup_n A_n\Big)=\bigcup_n (R\cap A_n)
\end{displaymath}
e siccome $R\cap A_n$ è misurabile per ogni $n$, segue che $R\cap (\bigcup_n A_n)$ è misurabile. Da cui 
$\bigcup_n A_n\in\mathfrak{M_{\infty}}$.
\end{osss}
\end{subsection}
\begin{subsection}{Misure complete e assolutamente continue}
In questa sezione esibiamo due nozioni essenziali in teoria della misura, che richiameremo spesso nel seguito: 
\begin{defins}
Si dice che una misura $\mathfrak m$ è \emph{completa} se considerato un insieme $A$ tale che $\mathfrak m(A)=0$, 
allora per ogni $A'\subset A$ segue che $A'$ è misurabile.\index{Misura!completa}
\end{defins}
\begin{osss}\label{mu(A')=0}
Dalla definzione di misura completa segue immediatamente che $\mathfrak m(A')=0$: infatti deve essere che $
0\leq m(A')\leq \mathfrak m(A)=0$ da cui $\mathfrak m(A')=0$
\end{osss}
\begin{osss}\label{completezzadimu}
La misura di Lebesgue $\mu$ è completa : infatti presi $A$ e $A'\subset A$ con $\mu(A)=0$, 
allora la subadditività di $\mu^*$ implica che $0\leq\mu^*(A')\leq\mu^*(A)=0$, da cui $\mu^*(A')=0$. Siccome ogni 
insieme di misura esterna nulla è misurabile (basta prendere come insieme elementare $\varnothing$), segue 
che $A'$ è misurabile (e in particolare $\mu(A')=0$ per l'osservazione \ref{mu(A')=0}).
\end{osss}
\begin{defins}
Una misura $\mathfrak m$ si dice \emph{assolutamente continua rispetto ad una misura 
$\mathfrak n$} se per ogni $A$ misurabile tale che $\mathfrak n(A)=0$ 
segue che $\mathfrak m(A)=0$. \index{Misura!assolutamente continua}
\end{defins}
Enunciamo ora una condizione equivalente a tale definzione, la cui dimostrazione, piuttosto laboriosa, viene 
lasciata come esercizio:
\begin{props}
Le seguenti affermazioni sono equivalenti:
\begin{itemize}
\item[$i)$] La misura $\mathfrak m$ è assolutamente continua rispetto alla misura $\mathfrak n$;
\item[$ii)$] Per ogni $\varepsilon >0$ esiste $\delta >0$ tale che per ogni $A$ misurabile con 
$\mathfrak n(A)<\delta$ segue che $\mathfrak m(A)<\varepsilon$ 
\end{itemize}
\end{props}
\end{subsection}
\end{section}
Abbiamo così concluso l'esposizione delle principali proprieta di $\mu$; ora vogliamo ampliare 
ulteriormente il nostro bagaglio culturale sulle misure e questo ci spinge a vele spiegate
verso il capitolo successivo.
\end{chapter}
\begin{chapter}{Complementi}
\lettrine[lines=1]{I}{n questo capitolo} principalmente esporremo
gli elementi base della teoria della misura in generale (perchè la misura di Lebesgue sarà pure
bella, simpatica ed educata, ma non è mica l'unica su questa terra!), per trattare in 
modo dettagliato, infine, un caso ``patologico'' della matematica sul quale non anticipiamo
nulla per non infrangere la suspence dalla quale il lettore starà \emph{indubbiamente} 
essendo divorato (...). 
\begin{section}{Teoria generale della misura}
Fino ad ora abbiamo definito in maniera precisa solo \emph{alcune} misure; ma cos'è \emph{in generale}
una misura?
\begin{defin}\label{defmisura}
Sia $X$ un insieme e $\mathfrak{S}\subset 2^{X}$ il semianello costruito sopra $X$. Si dice che una funzione 
$\mathfrak m:\mathfrak{S}\to\mathbb{R}^+\cup\{0\}$ è una \emph{misura} su $X$
se è additiva, cioé presa una qualsiasi partizione finita $\{A_n\}_{i=1}^n$ di un elemento $A$ di $\mathfrak{S}$, 
vale che $\mathfrak m(A)=\sum_{i=1}^n \mathfrak m(A_i)$. \index{Misura} 
\end{defin}
Dalla definizione generale di misura si deducono le seguenti proprietà:
\begin{prop}\label{proprietàmisura}
Sia  $\mathfrak m:\mathfrak{S}\to\mathbb{R}\cup\{0\}$ una misura. Allora:
\begin{itemize}
\item[$i)$] $\mathfrak m(\varnothing)=0$
\item[$ii)$] $\mathfrak m(A_1\cup A_2)=\mathfrak m(A_1)+\mathfrak m(A_2)-\mathfrak m(A_1\cap A_2)$ per ogni $A_1,A_2\in\mathfrak{S}$
\end{itemize}
\dimo$i)$ L'additività di $\mathfrak m$ implica $\mathfrak m(\varnothing)=\mathfrak m(\varnothing\cup\varnothing)=2\mathfrak m
(\varnothing)=0$.\\
$ii)$ Notiamo che possiamo scrivere l'insieme $A_1\cup A_2$ come segue:
\begin{displaymath}
A_1\cup A_2={(A_1\smallsetminus A_2)}\cupdot{(A_1\cap A_2)}\cupdot{(A_2\smallsetminus A_1)}
\end{displaymath}
e quindi dall'additività della misura $\mathfrak m$ segue che 
\begin{equation}\label{m(A1unioneA2)}
\mathfrak m(A_1\cup A_2)=\mathfrak m(A_1\smallsetminus A_2)+\mathfrak m(A_1\cap A_2)+\mathfrak m(A_2\smallsetminus A_1)
\end{equation}
Tuttavia anche $A_1$ e $A_2$ possono essere scritti come unioni disgiunte:
\begin{displaymath}
A_1={(A_1\smallsetminus A_2)}\cupdot{(A_1\cap A_2)}\quad\textrm{e}\quad A_2={(A_2\smallsetminus A_1)}
\cupdot{(A_1\cap  A_2)} 
\end{displaymath}
e quindi nuovamente l'additività di $\mathfrak m$ implica che
\begin{align}
\mathfrak m(A_1\smallsetminus A_2)=\mathfrak m(A_1)-\mathfrak m(A_1\cap A_2) \label{m(A1menoA2)}\\
\mathfrak m(A_2\smallsetminus A_1)=\mathfrak m(A_2)-\mathfrak m(A_1\cap A_2) \label{m(A_2menoA_1)} 
\end{align}
Sostituendo le relazioni \ref{m(A1menoA2)} e \ref{m(A_2menoA_1)} nella formula 
\ref{m(A1unioneA2)} si ottiene la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{esem}
Se si pone $\mathfrak{S}=\{\textrm{rettangoli in $\mathbb{R}^d$}\}$, 
allora si riconosce che $\mathfrak{S}$ è un semianello
(esempio \ref{intersezdirett}) e che la misura $m$ definita sull'insieme dei rettangoli $d$-dimensonali è 
effettivamente una misura secondo la definizione \ref{defmisura}.
\end{esem}
\begin{defin}\label{prolungamento}
Siano $\mathfrak m:\mathfrak{S}\to\mathbb{R}^+\cup\{0\}$ e $\mathfrak m':\mathfrak{S}'\to\mathbb{R}^+\cup\{0\}$ 
due misure. Si dice che 
$\mathfrak m'$ è un \emph{prolungamento di $\mathfrak m$} se: \index{Prolungamento di una misura}
\begin{itemize}
\item[$i)$] $\mathfrak{S}'\supset \mathfrak{S}$
\item[$ii)$] $\mathfrak m'_{|  \mathfrak{S}}\equiv \mathfrak m$, cioé $\mathfrak m'(A)=\mathfrak m(A)$ per ogni $A\in\mathfrak{S}$
\end{itemize}
\end{defin}
\begin{prop}\label{costruzionem'}
Sia $\mathfrak m:\mathfrak{S}\to\mathbb{R}^+\cup\{0\}$ una misura e sia $\mathfrak{A}(\mathfrak{S})$ 
l'anello minimale costruito sopra $\mathfrak{S}$. Allora esiste ed è unico un prolungamento 
$\mathfrak m'$ di $\mathfrak m$ che ammetta $\mathfrak{A}(\mathfrak{S})$ come dominio.\\  
\newline
\dimo Preso un elemento $B\in\mathfrak{A}(\mathfrak{S})$, allora esistono 
\color{red} \color{black} degli insiemi 
$\{B_k\}_{k=1}^n, B_k\in\mathfrak{S}$, a due a due disgiunti,
tali che $B=\bigcup_{k=1}^n B_k$. Allora è sufficiente definire $\mathfrak m'$ in tal modo:
\begin{displaymath}
\mathfrak m'(B):=\sum_{k=1}^n \mathfrak m(B_k)\quad\textrm{per ogni $B\in\mathfrak{A}(\mathfrak{S})$}
\end{displaymath}
Si verifica banalmente che $\mathfrak m'$ è una misura additiva che non dipende dalla decomposizione di $B$ nei $B_k$ 
(la dimostrazione di tal fatto è identica a quella fatta per la misura degli insiemi elementari).
Inoltre $\mathfrak m'$ è unica poiché è univocamente determinata dalla misura dei $B_k$. 
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{esem}
Nel caso in cui si scelga $\mathfrak{S}=\{\textrm{rettangoli in $\mathbb{R}^d$}\}$ e $\mathfrak{A}(\mathfrak{S})=
\{\textrm{insiemi elementari in $\mathbb{R}^d$} \}$
(esercizio facile: provare che in effetti l'insieme $\mathfrak{E}$ degli insiemi elementari è l'anello minimale 
costruito sull'insieme $\mathfrak{R}$ dei rettangoli),
allora la misura $m'$ definita sugli insiemi elementari prolunga la misura $m$ secondo la definizione 
\ref{prolungamento}. In particolare la misura $m'$ coincide esattamente con quella definita nella dimostrazione
della proposizione \ref{costruzionem'}.
\end{esem}
\begin{prop}\label{semiesupadditività}
Sia $\mathfrak{A}$ un anello e $\mathfrak m':\mathfrak{A}\to\mathbb{R}^+\cup\{0\}$ una misura. Valgono le seguenti condizioni:
\begin{itemize}
\item[$i)$] Sia $\{A_i\}_{i=1}^n$ una famiglia finita di elementi di $\mathfrak{A}$ tale che $A\subset
\bigcup_{i=1}^n A_i$; 
allora $\mathfrak m'(A)\leq\sum_{i=1}^n \mathfrak m'(A_i)$.
\item[$ii)$] Sia $\{A_i\}_{i=1}^n$ una famiglia finita di elementi di $\mathfrak{A}$ a due a due disgiunti tale che 
$A\supset\bigcup_{i=1}^n A_i$; allora $\mathfrak m'(A)\geq\sum_{i=1}^n \mathfrak m'(A_i)$.
\end{itemize}
\dimo$i)$ Dalla proposizione \ref{proprietàmisura} segue che 
$\mathfrak m'(A_1\cup A_2)\leq \mathfrak m'(A_1)+\mathfrak m'(A_2)$; per induzione 
segue quindi che 
\begin{equation}\label{m'unione<=sommam'}
\mathfrak m'\Big(\bigcup_{i=1}^n A_i\Big)\leq\sum_{i=1}^n \mathfrak m'(A_i)
\end{equation}
Inoltre è evidente che possiamo scrivere l'insieme $\bigcup_{i=1}^n A_i$ come un'unione disgiunta:
\begin{displaymath}
\bigcup_{i=1}^n A_i=A\cup\Big(\bigcup_{i=1}^n A_i\smallsetminus A\Big)
\end{displaymath}
da cui, per l'additività della misura, segue che
\begin{equation}\label{m'A<=m'unione}
\mathfrak m'(A)\leq \mathfrak m'\Big(\bigcup_{i=1}^n A_i\Big)
\end{equation}
Mettendo assieme le relazioni \ref{m'unione<=sommam'} e \ref{m'A<=m'unione} segue subito il punto $i)$.\\
$ii)$ Possiamo scrivere $A$ come unione disgiunta:
\begin{displaymath}
A=\bigcup_{i=1}^n A_i\cup \Big(A\smallsetminus\bigcup_{i=1}^n A_i\Big);
\end{displaymath}
dall'additivtà di $\mathfrak m'$ deduciamo quindi che 
\begin{displaymath}
\mathfrak m'(A)=\sum_{i=1}^n \mathfrak m'(A_i)+\mathfrak m'\Big(A\smallsetminus\bigcup_{i=1}^n A_i\Big)
\end{displaymath}
da cui segue subito che $\sum_{i=1}^n \mathfrak m'(A_i)\leq \mathfrak m'(A)$, cioé la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{defin}
Sia data una misura $\mathfrak m:\mathfrak{S}\to\mathbb{R}^+\cup\{0\}$ sul semianello $\mathfrak{S}$. $\mathfrak m$ si 
dice \emph{$\sigma$-additiva} se preso $A\in\mathfrak{S}$
e considerata una partizione al più numerabile $\{A_n\}_{n=1}^{\infty}$ di $A$, 
allora $\mathfrak m(A)=\sum_{i=1}^{\infty}\mathfrak m(A_i)$. \index{$\sigma$-additività}
\end{defin}
\begin{prop}
Sia $\mathfrak m:\mathfrak{S}\to\mathbb{R}^+\cup\{0\}$ una misura $\sigma$-additiva. Allora la misura
$\mathfrak m':\mathfrak{A}(\mathfrak{S})\to\mathbb{R}^+\cup\{0\}$ 
che prolunga $\mathfrak m$ è $\sigma$-additiva.\\
\newline
\dimo Sia $A\in\mathfrak{A}(\mathfrak{S})$ e sia $\{B_n\}_{n=1}^{\infty}$ una partizione 
numerabile di $A$. Esistono allora
$A_j\in\mathfrak{S}$, $B_{nk}\in\mathfrak{A}(\mathfrak{S})$ a due a due disgiunti tali che 
\begin{displaymath}
A=\bigcup_{j=1}^t A_j,\quad B_n=\bigcup_{k=1}^s B_{nk}
\end{displaymath}
Poniamo allora $C_{nkj}=B_{nk}\cap A_j$: è facile vedere che i $C_{nkj}$ sono a due a due disgiunti 
e che valgono le relazioni
\begin{displaymath}
A_j=\bigcup_{n=1}^{\infty}\bigcup_{k=1}^s {C_{nkj}},\quad B_{nk}=\bigcup_{j=1}^t {C_{nkj}}
\end{displaymath}
da cui, applicando la $\sigma$-additività di $\mathfrak m$, segue che 
\begin{equation}\label{mAj}
\mathfrak m(A_j)=\sum_{n=1}^{\infty}\sum_{k=1}^s \mathfrak m(C_{nkj})
\end{equation}
\begin{equation}\label{mBnk}
\mathfrak m(B_{nk})=\sum_{j=1}^t \mathfrak m(C_{nkj}) 
\end{equation}
Inoltre sfruttando la definizione di $\mathfrak m'$ sappiamo che:
\begin{equation}\label{m'A}
\mathfrak m'(A)=\sum_{j=1}^t \mathfrak m(A_j)
\end{equation}
\begin{equation}\label{m'Bn}
\mathfrak m'(B_n)=\sum_{k=1}^s \mathfrak m(B_{nk}) 
\end{equation}
Mettendo assieme le relazioni \ref{mAj}, \ref{mBnk}, \ref{m'A}, \ref{m'Bn}  
segue immediatamente la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{prop}\label{sigmasemisupadditività}
Sia $\mathfrak{A}$ un anello e sia $\mathfrak m':\mathfrak{A}\to\mathbb{R}^+\cup\{0\}$ una misura $\sigma$-additiva. Allora:
\begin{itemize}
\item[$i)$] Per ogni $A, \{A_n\}_{n=1}^{\infty}$ in $\mathfrak{A}$ tali che $A\subset
\bigcup_{n=1}^{\infty}A_n$,
segue che $\mathfrak m'(A)\leq\sum_{n=1}^{\infty}\mathfrak m'(A_n)$.
\item[$ii)$] Per ogni $A\in\mathfrak{A}$ e $\{A_n\}_{n=1}^{\infty}$ famiglia di elementi di $\mathfrak{A}$ a due 
a due disgiunti tali che $A\supset\bigcup_{n=1}^{\infty}A_n$,
segue che $\mathfrak m'(A)\geq\sum_{n=1}^{\infty}\mathfrak m'(A_n)$.
\end{itemize}
\dimo$i)$ Poniamo $B_n:={(A\cap A_n)}\smallsetminus\bigcup_{k=1}^{n-1}A_k$: ovviamente $B_n\in
\mathfrak{A}$ e $B_n\subset A_n$; inoltre è facile verificare che i $B_n$ sono a due a due disgiunti e che $A=
\bigcup_{n=1}^{\infty}B_n$. Da tutto ciò segue che 
\begin{displaymath}
\mathfrak m'(A)=\sum_{n=1}^{\infty}\mathfrak m'(B_n)\leq\sum_{n=1}^{\infty}\mathfrak m'(A_n)
\end{displaymath}
e quindi il punto $i)$ è provato.\\
$ii)$ Per il punto $ii)$ della proposizione \ref{semiesupadditività} sappiamo che 
\begin{displaymath}
\mathfrak m'(A)\geq\sum_{n=1}^{t}\mathfrak m'(A_n)
\end{displaymath}
Passando al limite quando $t\to +\infty$ segue il punto $ii)$. 
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{cor}
L'affermazione $ii)$ della proposizione \ref{sigmasemisupadditività} è equivalente alla $\sigma$-additività di 
$\mathfrak m'$.\\
\newline
\dimo Se $\mathfrak m'$ è $\sigma$-additiva, per la proposizione \ref{sigmasemisupadditività} vale $ii)$.\\
Viceversa supponiamo che valga $ii)$, e consideriamo una partizione al più numerabile $\{A_n\}_{n=1}^{\infty}$ di
$A$: siccome deve valere che 
\begin{displaymath}
A=\bigcup_{n=1}^{\infty}A_n
\end{displaymath}
allora dall'ipotesi segue che 
\begin{equation}\label{sigmasupadditività}
\mathfrak m'(A)\geq\sum_{n=1}^{\infty}\mathfrak m'(A_n)
\end{equation}
Inoltre il punto $i)$ della proposizione \ref{sigmasemisupadditività} implica che 
\begin{equation}\label{sigmasemiadditività}
\mathfrak m'(A)\leq\sum_{n=1}^{\infty}\mathfrak m'(A_n)
\end{equation}
Mettendo assieme \ref{sigmasupadditività} e \ref{sigmasemiadditività} segue che $\mathfrak m'$ è $\sigma$-additiva.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{subsection}{Prolungamento della misura su semianelli dotati di unità}
In questo paragrafo non effettueremo dimostrazioni poiché queste sono identiche parola per parola a quelle già viste 
nei capitoli 1 e 2, apportando ovviamente le generalizzazioni del caso. Ci limiteremo quindi a riportare una serie 
noiosa (ma necessaria!) di risultati che il lettore è vivamente invitato a provare per esercizio: anche se al pigro 
e indolente studente questo esercizio di ricopiatura potrà sembrare inutile, in realtà esso è un utilissima 
ginnastica mentale che ha lo scopo prinicipale di far digerire meglio tali dimostrazioni.
\begin{defins}
Sia $A\subset X$ un insieme qualsiasi e $\mathfrak{S}$ un suo semianello su cui
è definita una misura $\mathfrak m$. Si dice \emph{misura esterna} di $A$ la quantità: \index{Misura!esterna}
\begin{displaymath}
\mu^*(A):=\inf_{A\subset\bigcup_i A_i} \sum_i m(A_i).
\end{displaymath}
\end{defins}
\begin{osss}
Sia $A\subset X$ tale che $A\in\mathfrak{A}(\mathfrak{S})$. Allora $\mu^*(A)=\mathfrak m'(A)$ 
\end{osss}
\begin{teos}{\textbf{(Subaddività di $\mu^*$)}}
Siano $A,A_1,A_2\ldots$ sottoinsiemi di $X$ tali che $A\subset \bigcup_i A_i$. Allora
\begin{displaymath}
\mu^*(A)\leq\sum_{i=1}^{\infty}\mu^*(A_i)
\end{displaymath}
\end{teos}
\begin{defins}
Un insieme $A\subset X$ si dice \emph{misurabile (secondo Lebesgue)} se per ogni $\varepsilon >0$ esiste un insieme 
$B\in\mathfrak{A}(\mathfrak{S})$ tale che 
\begin{displaymath} \index{Insieme!Lebesgue-misurabile}
\mu^*(A\triangle B)<\varepsilon
\end{displaymath}
La funzione $\mu^*$ ristretta all'insieme degli insiemi misurabili (il quale si indica con $\mathfrak{M}_X$) si 
chiama misura di Lebesgue 
e si indica con $\mu$.
\end{defins}
\begin{osss}
La misura di Lebesgue appena definita costituisce il prolungamento di Lebesgue della misura $\mathfrak m$ definita sul 
semianello $\mathfrak{S}$.
In particolare ogni prolungamento di Lebesgue è completo per l'osservazione \ref{completezzadimu}.
\end{osss}
\begin{props}
L'insieme $\mathfrak{M}_X$ è una $\sigma$-algebra con unità $X$.
\end{props}
\begin{teos}{\textbf{($\sigma$-additività di} $\mu$)}
La misura di Lebesgue è $\sigma$-additiva.
\end{teos}
\begin{teos}{\textbf{(Continuità della misura $\mu$)}}
Siano $\{A_n\}_{n\in\mathbb{N}}$ una famiglia di elementi di  $\mathfrak{M}_X$ tali che $A_1\subseteq A_2\subseteq
\ldots\subseteq A_n\subseteq\ldots$; allora
\begin{displaymath}
\mu\Big(\bigcup_{k=1}^{\infty}A_k\Big)=\lim_{k\to +\infty}\mu(A_k)=\sup_{k\in\mathbb{N}}\mu(A_k).
\end{displaymath}
Siano $\{A_n\}_{n\in\mathbb{N}}$ una famiglia di elementi di  $\mathfrak{M}_X$ tali che $A_1\supseteq A_2\supseteq
\ldots\supseteq A_n\supseteq\ldots$; allora
\begin{displaymath}
\mu\Big(\bigcap_{k=1}^{\infty}A_k\Big)=\lim_{k\to +\infty}\mu(A_k)=\inf_{k\in\mathbb{N}}\mu(A_k)
\end{displaymath}
\end{teos}
\end{subsection}
\end{section}
\begin{section}{(Complementi)$^2$}
Ed eccoci a discutere del ``mostro'' matematico cui avevamo accennato all'inizio di questo capitolo,
l'insieme di Cantor, forse a qualcuno già familiare (è, tutto sommato, piuttosto noto essendo anche un frattale,
ma noi non ci soffermeremo oltre su questa proprietà). Dopo esserci occupati di lui,
seguirà a ruota a pagina \pageref{PJL} un interessante un confronto tra il concetto di misura secondo 
Peano-Jordan e secondo Lebesgue.  
\begin{subsection}{L'insieme di Cantor}
Consideriamo l'insieme $C_0=[0,1]\subset\mathbb{R}$ e dividiamolo in 3 intervalli di ugual ampiezza come segue:
\begin{displaymath}
C_0=\Big[0,\frac{1}{3}\Big]\cup\Big(\frac{1}{3},\frac{2}{3}\Big)\cup\Big[\frac{2}{3},1\Big];
\end{displaymath}
ciò fatto, eliminiano l'intervallo aperto centrale ottenendo così l'insieme
\begin{displaymath}
C_1=\Big[0,\frac{1}{3}\Big]\cup\Big[\frac{2}{3},1\Big].
\end{displaymath}
Operiamo ora come fatto sopra sugli intervalli chiusi $\Big[0,\frac{1}{3}\Big]$ e $\Big[\frac{2}{3},1\Big]$,
così da ottenere l'insieme
\begin{displaymath}
C_2=\Big[0,\frac{1}{9}\Big]\cup\Big[\frac{2}{9},\frac{1}{3}\Big]\cup\Big[\frac{2}{3},\frac{7}{9}\Big]
\cup\Big[\frac{8}{9},1\Big].
\end{displaymath}
Iteriamo ora questa procedura indefinitamente: l'insieme così ottenuto, sia esso $C$, prende il nome di 
\emph{insieme di Cantor}.\index{Insieme!di Cantor}
\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{cantor}
\caption{La costruzione dell'insieme di Cantor (primi 7 passi)}
\end{center}
\end{figure}
\newline
Adesso che abbiamo costruito $C$, vediamone prima di tutto le proprietà topologiche essenziali:
\begin{itemize}
\item[$i)$] $C$ è chiuso (nella topologia metrica di $\mathbb{R}$): infatti, per costruzione, il complementare 
di $C$ in $C_0$ è un'unione numerabile di intervalli aperti, e quindi è un aperto;
\item[$ii)$] $C$ è compatto: infatti $C\subset C_0$ è limitato e chiuso per $i)$, quindi compatto per il 
teorema di Heine-Borel; 
\item[$iii)$] $C$ è perfetto: \index{Insieme!perfetto} \footnote{un insieme si dice \emph{perfetto} se tutti i 
suoi punti sono di accumulazione e di frontiera} siccome $C$ è chiuso e non ha punti non isolati, deve 
essere $C=\mathrm{Der}(C)$, cioè coincide con il suo insieme derivato (che è l'insieme dei punti di 
accumulazione); \index{Insieme!derivato}proviamo
inoltre che $\partial C=C$: se, per assurdo, esistesse $x_0\in C$ tale che $x_0$ non 
è di frontiera per $C$, allora esisterebbe un intorno $U_{x_0}$ di $x_0$ tale che  $U_{x_0}\subset C$. Tuttavia
tale intorno ha misura positiva, e questo implica che $\mu(C)>0$, assurdo (infatti, fra pochissimo, dimosteremo 
che l'insieme di Cantor ha misura nulla, il lettore più trepidante sappia attendere!). 
\item[$iv)$] $C$ è sconnesso: infatti $C$ si può scrivere come unione di intervalli chiusi disgiunti e non
vuoti.
\end{itemize}
Dimostrate tale semplici proprietà, passiamo al piatto forte, cioè al motivo per cui abbiamo discusso 
dell'insieme di Cantor in questa sede: ogni insieme numerabile è misurabile ed ha misura nulla 
\label{insnummisnulla} (dimostrarlo per esercizio; suggerimento: si dimostri dapprima che i singletons sono 
misurabili ed hanno misura nulla, poi si 
generalizzi); tuttavia il viceversa non è vero, cioè esiste un insieme misurabile di misura nulla 
non numerabile. Dimostriamo ora che l'insieme di Cantor fornisce il controesempio cercato: proviamo quindi che 
\begin{itemize}
\item[$i)$] $C$ è misurabile ed ha misura nulla;
\item[$ii)$] $C$ non è numerabile.
\end{itemize}
\dimo $i)$ Dalla definizione di $C$ segue che $C=\bigcap_{n=1}^{\infty}C_n$ con i $C_n$ tutti
 misurabili, e quindi $C$ è misurabile. Notiamo ora che 
\begin{displaymath}
\mu([0,1]\setminus C) = \frac{1}{3}+\frac{2}{9}+\cdots +\frac{2^n}{3^{n+1}}+\cdots = \frac{1}{3}\sum_{n=0}^
{\infty}\Big(\frac{2}{3}\Big)^n=1.
\end{displaymath}
Per cui $\mu(C)=\mu([0,1])-\mu([0,1]\setminus C)=0$.\\
$ii)$ Proviamo che $C$ ha la potenza del continuo: per far ciò sarà sufficiente mostrare che esiste una 
funzione suriettiva $F:C\to [0,1]$ (perchè? esercizio: dimostrare che se esiste una suriezione $f:B\to A$ e 
$B\subset A$, allora $B$ ed $A$ sono equipotenti). Per prima cosa, scriviamo ogni elemento di $[0,1]$ in base 3,
cioè se $x\in [0,1]$, allora 
\begin{displaymath}
x=\sum_{k=1}^{\infty}\frac{\xi_k}{3^k} 
\end{displaymath}
per certi $\xi_k\in\mathbb{R}$ (ad esempio $\frac{1}{3}=(0,1)_3$ oppure $\frac{2}{3}=(0,2)_3$); definiamo poi $F$ 
attraverso i seguenti passi:
\begin{itemize}
\item[$(a)$] prendiamo il numero $(x)_3$ e sostituiamo il primo 1 con un 2, i successivi con 0;
\item[$(b)$] sostituiamo tutti i 2 con la cifra 1;
\item[$(c)$] interpretiamo il numero ottenuto nella base due, ottenendo così ancora un punto di $[0,1]$. 
Questo numero sarà il nostro $F((x)_3)$
\end{itemize}
Abbiamo così costruito una funzione $F:[0,1]\to[0,1]$, detta funzione di Cantor-Vitali (nota anche come scala di 
Cantor o scala del diavolo). 
\index{Funzione!di Cantor-Vitali}
\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.5\textwidth]{cantorvitali}
\end{center}
\caption{La funzione di Cantor-Vitali}
\end{figure}
\newline
Dimostriamo che tale $F$ è una suriezione da $C$ in $[0,1]$:
dato che ogni numero in $[0,1]$ ammette rappresentazione binaria, sarà sufficiente mostrare che ogni elemento di 
$C$ ha una rappresentazione in base 3 del tipo $(0,\xi_1\xi_2\xi_3\ldots)_3$ con $\xi_i=0$ oppure $\xi_i=2$ 
(infatti il passo $(a)$ definisce proprio un elemento di questo tipo; risulta così semplice costruire un'inversa 
destra di $F$ con una procedura che applichi i punti $(a),(b),(c)$ in ordine inverso rispetto alla procedura che
 definisce $F$). Procediamo: al primo passso nella costruzione di $C$ abbiamo eliminato l'aperto $(\frac{1}{3},
\frac{2}{3})$, i cui estremi hanno rappresentazione ternaria $\frac{1}{3}=(0,1)_3=(0,0\bar{2})_3$ e $\frac{2}{3}=
(0,2)_3=(0,1\bar{2})_3$ (questo perchè il periodo 2 in base 3 è equivalente al periodo 9 in base 10), e quindi 
in $C_1$ sono rimasti solo i numeri del tipo $(0,0xxx\ldots)_3$ e $(0,2xxx\ldots)_3$; procedendo allo stesso 
modo al passo successivo, gli elementi in $C_2$ saranno del tipo $(0,00xxx\ldots)_3$ o $(0,02xxx\ldots)_3$ o 
$(0,20xxx\ldots)_3$ o ancora $(0,22xxx\ldots)_3$; iterando la procedura si arriva alla tesi. Abbiamo così 
provato che $F$ è suriettiva e quindi $C$ ha la potenza del continuo.
\end{subsection}
\begin{subsection}{Misurabilità di un insieme secondo Peano-Jordan} 
Diamo ora una definizione ulteriore di misurabilità per gli insiemi, senza dubbio già familiare a chi ha 
avuto a che fare con l'integrazione riemanniana: \label{PJL}
\begin{defin}\label{primadefdimis}
Sia $\mathfrak{A}$ un anello costruito su un insieme $X$ e sia $\mathfrak m':\mathfrak{A}\to\mathbb{R}^+\cup\{0\}$ 
una misura su $X$. Un insieme $A\subset X$ si dice \emph{Peano-Jordan misurabile} se per ogni $\varepsilon >0$ 
esistono $A',A''\in\mathfrak{A}$ tali che $A'\subset A\subset A''$ e $\mathfrak m'(A''\setminus A')<\varepsilon$ 
\index{Insieme!Peano-Jordan-misurabile}. 
\end{defin}
Nel caso dei sottoinsiemi di $\mathbb{R}^n$ si può anche procedere in altro modo per definire la 
Peano-Jordan-misurabilità: consideriamo i soliti insiemi elementari\footnote{in questo contesto gli insiemi 
elementari vengono spesso chiamati \emph{plurirettangoli}}\index{Plurirettangolo} 
e un insieme $A\subset\mathbb{R}^n$, indi consideriamo gli insiemi di tutti i plurirettangoli contenuti e 
contenenti $A$; una volta definita la misura $m'$ dei plurirettangoli attraverso quella dei rettangoli nel 
solito modo, definiamo misura esterna e misura interna secondo Peano-Jordan ponendo rispettivamente:
\begin{displaymath}
\overline{m}(A):=\inf_{i\in I}\{m'(E_i)|  E_i\textrm{ è un plurirettangolo che contiene $A$}\};
\end{displaymath}
\begin{displaymath}
\underline{m}(A):=\sup_{i\in I}\{m'(E_i)|  E_i\textrm{ è un plurirettangolo contenuto in $A$}\}.
\end{displaymath}
A questo punto diciamo che $A$ è misurabile secondo Peano-Jordan se $\underline{m}(A)=\overline{m}(A)$:
è chiaro che questa definizione
coincide con quella data sopra, più generale, nel caso in cui si prenda come anello $\mathfrak{P}$ 
l'insieme dei plurirettangoli (dimostreremo comunque questo fatto
nel caso più generale alla fine di tale paragrafo).
In particolare possiamo riassumere entrambe le definizioni in questo modo: 
un insieme $A$ è Peano-Jordan
misurabile se e solo se la sua frontiera ha misura nulla
(infatti per ogni $\varepsilon >0$ esistono $A',A''$ plurirettangoli tali che $\partial A\subset A''\setminus A'$ 
e $m'(A''\setminus A')<\varepsilon$).
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.4]
\filldraw[fill=green!30!white,line width=1 pt](1,4)--(1,6)--(2,6)--(2,7)--(3,7)--(3,8)--
(8,8)--(8,7)--(11,7)--(11,4)--(12,4)--(12,0)--
(10,0)--(10,-1)--(2,-1)--(2,0)--(0,0)--(0,4)--cycle;
\draw[line width=1.2 pt](2,5)..controls(4,8)and(8,8)..(10,5)..controls(12,2)and(10,0)..(6,0)..
controls(2,0)and(0,2)..(2,5);
\filldraw[fill=white,line width=1 pt](3,1)--(8,1)--(8,2)--(10,2)--(10,4)--
(9,4)--(9,5.5)--(6,5.5)--(6,6.5)--(4,6.5)--(4,5)--(3,5)--(3,4)--(2,4)--(2,2)--(3,2)--cycle;
\end{tikzpicture}
\end{center}
\caption{L'idea che sta sotto la misurabilità secondo Peano-Jordan}
\end{figure}
\newline
Per completare il discorso, diamo anche le definizioni più generali 
di misura esterna e interna secondo Peano-Jordan:
\begin{defin}\label{secondadefdimis}
Sia $m':\mathfrak{A}\to\mathbb{R}^+\cup\{0\}$ come nella definizione precedente. Si dice \emph{misura esterna 
secondo Peano-Jordan} di $A\subset X$ la quantità
\begin{displaymath}
\overline{m}(A):=\inf_{B\in\mathfrak{A}}\{m'(B)|  B\supset A\}.
\end{displaymath}
Si definisce invece \emph{misura interna secondo Peano-Jordan} di $A$ la quantità
\begin{displaymath}
\underline{m}(A):=\sup_{B\in\mathfrak{A}}\{m'(B)|  B\subset A\}.
\end{displaymath} \index{Misura!esterna (di Peano-Jordan)}  \index{Misura!interna (di Peano-Jordan)}
Nel caso in cui $\overline{m}(A)=\underline{m}(A)$, si dice che $A$ è \emph{Peano-Jordan misurabile} e si chiama
\emph{misura di Peano-Jordan} la funzione $m:=\overline{m}=\underline{m}$. 
\index{Insieme!Peano-Jordan-misurabile}\index{Misura!di Peano-Jordan}
\end{defin}
è chiaro che queste definizioni coincidono con quelle date in $\mathbb{R}^n$ nel caso in cui si prenda come anello
 $\mathfrak{P}$ l'insieme di tutti i plurirettangoli. Dimostriamo ora a livello generale quanto promesso 
in precedenza, cioè che le due definizioni di misurabilità enunciate in questa sezione sono equivalenti: 
\begin{prop}
Le definizioni \ref{primadefdimis} e \ref{secondadefdimis} sono equivalenti.\\
\newline
\dimo$(\Leftarrow)$ Supponiamo che valga la definizione \ref{primadefdimis}: sappiamo che per ogni
 $\varepsilon >0$ esistono $A',A''\in\mathfrak{A}$ tali che $A'\subset A\subset A''$ e $m'(A''\setminus A')=
m'(A'')-m'(A')<\varepsilon$; dalla definizione di $\underline{m}$ e di $\overline{m}$ deduciamo immediatamente che 
$\underline{m}(A)\leq\overline{m}(A)$, e dalle definizioni di estremo superiore ed inferiore
seguono le seguenti diseguaglianze:
\begin{displaymath}
m'(A')\leq\underline{m}(A)\leq\overline{m}(A)\leq m'(A''),
\end{displaymath}
da cui segue che
\begin{displaymath}
|\overline{m}(A)-\underline{m}(A)|\leq|  m'(A'')-m'(A')| <\varepsilon,
\end{displaymath}
cioè abbiamo raggiunto la definizione \ref{secondadefdimis}.\\
$(\Rightarrow)$ Viceversa valga la definizione \ref{secondadefdimis}, cioè supponiamo che $\overline{m}(A)=
\underline{m}(A)$. Sempre dalle definizioni di estremo superiore ed inferiore, deduciamo che per ogni 
$\varepsilon >0$ esistono due insiemi $A',A''$ tali che:
\begin{align*}
\underline{m}(A)-\varepsilon/2 &< m'(A')\leq\underline{m}(A)\\
&= \overline{m}(A)\leq m'(A'')<\overline{m}(A)+\varepsilon/2;
\end{align*}
segue quindi che 
\begin{displaymath}
|  m'(A'')-m'(A')| <|\overline{m}(A)+\varepsilon/2-\underline{m}(A)+\varepsilon/2| =\varepsilon.
\end{displaymath}
Ne discende quindi la definizione \ref{primadefdimis}.
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{oss}
Esattamente come accade per la misura interna di Lebesgue, la misura interna di Peano-Jordan si può scrivere 
attraverso la seguente espressione:
\begin{displaymath}
\underline{m}(A)=\overline{m}(X)-\overline{m}(X\setminus A).
\end{displaymath}
Infatti, considerato un plurirettangolo $E_i$ contenuto in $A$, segue che il suo complementare $X\setminus E_i$ 
sarà un plurirettangolo che contiene $X\setminus A$. Passando alle misure, si ottiene la formula scritta sopra. 
\end{oss}
\begin{subsubsection}{Confronto fra la misurabilità di un insieme secondo Peano-Jordan e secondo Lebesgue}
In questa sezione cercheremo di capire se ci sono dei legami fra questi due concetti di misurabilità, ed in caso 
affermativo quali. Consideriamo l'insieme $A:=[0,1]\cap\mathbb{Q}=\{r_k\}_{k\in\mathbb{N}}$: tale insieme è 
numerabile, per cui è misurabile secondo Lebesgue ed ha misura nulla;
in particolare $\mu^*(A)=0$; tuttavia non è misurabile secondo Peano-Jordan visto che 
\begin{displaymath}
\overline{m}(A)=m'([0,1])=1\quad\textrm{e}\quad\underline{m}(A)=m'(\{r_k\}_k)=0
\end{displaymath}
Questo esempio prova che, dato un certo insieme A, vale che $\mu^*(A)\leq \overline{m}(A)$.
Viceversa, vale il seguente risultato:
\begin{props}
Se un insieme $A\subset X$ è Peano-Jordan misurabile, allora è Lebesgue misurabile e la sua misura secondo 
Peano-Jordan coincide con quella secondo Lebesgue.\\
\newline
\dimo Se $A$ è Peano-Jordan misurabile, allora per ogni $\varepsilon >0$ esistono $A',A''$ 
plurirettangoli tali che
$A'\subset A\subset A''$ e $m'(A''\setminus A')<\varepsilon$; ne segue che 
\begin{align*}
\mu^*(A\bigtriangleup A'') &\leq \overline{m}(A\bigtriangleup A'')\leq\overline{m}(A''\setminus A')\\
&= m'(A''\setminus A')<\varepsilon,
\end{align*}
per cui $A$ è Lebesgue-misurabile. Inoltre vale la seguente catena di diseguaglianze:
\begin{align*}
\mu(A) &= \mu^*(A)\leq\overline{m}(A)=\underline{m}(A)\\
&= \overline{m}(X)-\overline{m}(X\setminus A)\leq \mu^*(X)-\mu^*(x\setminus A)=\mu_*(A),
\end{align*}
e ricordando che si ha sempre $\mu_*(A)\leq\mu^*(A)$, segue che $\mu\equiv m$.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\begin{esems}
Concludiamo col seguente esempio: definiamo la successione $A_n:=[0,1]\setminus \{r_1,\ldots,r_n\}$, ove 
$\{r_k\}_{k\in\mathbb{N}}$ 
è la successione dei razionali in $[0,1]$. Consideriamo ora l'insieme
\begin{displaymath}
A:=\bigcap_{n=1}^{\infty}A_n,
\end{displaymath}
cioè l'insieme $[0,1]$ privato di tutti i razionali. Notiamo che si verificano i seguenti fatti:
\begin{itemize}
\item[$i)$] $A_1\supset A_2\supset\ldots\supset A_n\supset\ldots$;
\item[$ii)$] $A$ è misurabile e $\mu(A)=1$;
\item[$iii)$] Gli $A_n$ sono Peano-Jordan misurabili per ogni $n$ fissato, e quindi $\mu(A_n)=m(A_n)=1$;
\item[$iv)$] $A$ non è Peano-Jordan misurabile, poichè $1=\overline{m}(A)>\underline{m}(A)=0$.
\end{itemize}
Per la proprietà di continuità di $\mu$ segue che 
\begin{displaymath}
1=\mu(A)=\lim_{n\to+\infty}\mu(A_n)=\lim_{n\to+\infty}m(A_n).
\end{displaymath}
Risulterebbe quindi che $A$ è Peano-Jordan misurabile ed ha misura 1, falso dato che vale $iv)$. Si conclude 
quindi che la misura $m$ di Peano-Jordan non soddisfa la proprietà di continuità.
\end{esems}
\end{subsubsection}
\end{subsection}
\end{section}
\end{chapter}
\begin{chapter}{Funzioni misurabili}
\lettrine[lines=1]{S}{iamo così giunti} al secondo argomento cardine della nostra
trattazione. Abbandonato lo studio delle misure, ci occupiamo ora di una classe particolare di funzioni che
aprono le porte ad un gran numero di applicazioni.
\begin{section}{Un nuovo punto di vista sulle funzioni}
\begin{defin}
Siano $(X,\mathfrak{S}_X)$ e $(Y,\mathfrak{S}_Y)$ due spazi misurabili\footnote{Per spazi misurabili intendiamo 
dire spazi dove è possibile definire il concetto di misura; ecco perché risulta necessario definrli con delle 
$\sigma$-algebre (vedi l'osservazione \ref{misurasusigmaalgebra})} \index{Spazio!misurabile} con $\sigma$-algebre
$\mathfrak{S}_X$ e $\mathfrak{S}_Y$ rispettivamente. 
Una funzione $f:(X,\mathfrak{S}_X)\to(Y,\mathfrak{S}_Y)$ si dice \emph{misurabile} se per ogni $A \in
\mathfrak{S}_Y$ segue che $f^{-1} (A) \in \mathfrak{S}_X$. In particolare se $f$ è definita sul
dominio \footnote{$\mathfrak{M}$ è la $\sigma$-algebra degli insiemi Lebesgue-misurabili e $\mu$ è 
la misura di Lebesgue}
$(X,\mathfrak{M},\mu)$ allora si dice che $f$ è una funzione \emph{$\mu$-misurabile}.\index{Funzione!misurabile} 
\index{Funzione!$\mu$-misurabile}
\end{defin}
\begin{prop}\label{tcomp}
Siano $(X,\mathfrak{S}_X)$, $(Y,\mathfrak{S}_Y)$, $(Z,\mathfrak{S}_Z)$ spazi misurabili, e siano 
$f:(X,\mathfrak{S}_X)\to(Y,\mathfrak{S}_Y)$, $g:(Y,\mathfrak{S}_Y)\to(Z,\mathfrak{S}_Z)$
due funzioni misurabili. Allora la funzione $f \circ g:(X,\mathfrak{S}_X)\to(Z,\mathfrak{S}_Z)$ è una funzione 
misurabile.\\
\newline 
\dimo  Siccome $g$ è misurabile segue che per ogni $A \in \mathfrak{S}_Z$ allora $f^{-1} (A) 
\in \mathfrak{S}_Y$; inoltre $f$ è misurabile,
e quindi $f^{-1}(g^{-1} (A)) = (g \circ f)^{-1}(A) \in \mathfrak{S}_X$, cioé $g \circ f$ è misurabile.  
\begin{flushright} $\square$
\end{flushright}
\end{prop}
Ora dimostriamo dei lemmi che useremo varie volte nel seguito:
\begin{lemma} \label{lemmtess}
Siano $(X,\mathfrak{S}_X)$ e $(Y,\mathfrak{S}_Y)$ due spazi misurabili e $f:(X,\mathfrak{S}_X)\to
(Y,\mathfrak{S}_Y)$ funzione. Esista $\mathcal{C}$ 
tale che $\mathfrak{S}_Y = \sigma(\mathcal{C})$. Allora $f$ è misurabile se e solo se per ogni $A \in  
\mathcal{C}$ segue che $f^{-1}(A) \in \mathfrak{S}_X$ .\\
\newline \dimo  $(\Rightarrow)$ Segue subito dalla definizione.\\
$(\Leftarrow)$ Viceversa definiamo l'insieme
\begin{displaymath}
\mathfrak{L}= \{A \in \mathfrak{S}_Y |  f^{-1}(A) \in \mathfrak{S}_X\}.
\end{displaymath}
Si verifica facilmente che $\mathfrak{L}$ è una $\sigma$-algebra (esercizio); inoltre dall'ipotesi segue subito 
che $\mathfrak{L} \supset \mathcal{C}$ .
Ma allora $\mathfrak{L} \supset \mathfrak{S}_Y = \sigma(\mathcal{C})$, da cui la tesi.  
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
\begin{lemma} \label{lemmfnzcont}
Siano $(X,\mathfrak{B}(X))$ e $(Y,\mathfrak{B}(Y))$ spazi topologici misurabili e sia $f:(X,\mathfrak{B}(X))\to
(Y,\mathfrak{B}(Y))$ una funzione continua. Allora $f$ è misurabile.\\
\newline \dimo  Siccome $f$ è continua, sappiamo che per ogni aperto $A \in \mathfrak{B}(Y)$ segue
che $f^{-1}(A) \in \mathfrak{B}(X)$ (poiché $f^{-1}(A)$ è aperto). Alla luce del fatto che $\mathfrak{B}(Y) = 
\sigma\{A \subset Y |  \textrm{$A$ è aperto in $Y$}\}$, segue subito la tesi per il lemma \ref{lemmtess}.   
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
Da questi lemmi scende un corollario banalissimo, ma importante:
\begin{cor} \label{compfnzcontmis}
La composizione di una funzione misurabile con una funzione continua è ancora una funzione misurabile.
\end{cor}
Da ora in poi prenderemo in considerazione solo funzioni $\mu$-misurabili a valori reali, cioé prenderemo
$(X,\mathfrak{S}_X) = (X,\mathfrak{M},\mu)$ e $(Y,\mathfrak{S}_Y) = (\mathbb{R},\mathfrak{B}(\mathbb{R}))$.\\
Possiamo ora mostrare una condizione equivalente alla misurabilità di una funzione $\mu$-misurabile di variabile
reale: \begin{prop} \label{critmis}
Sia $f:(X,\mathfrak{M},\mu)\to(\mathbb{R},\mathfrak{B}(\mathbb{R}))$ una funzione. Allora $f$ è misurabile se e solo se
l'insieme $\{x\ |\   f(x) < c\}$ è misurabile per ogni $c \in \mathbb{R}$.\\
\newline \dimo 
$(\Rightarrow)$ Se $f$ è misurabile, per ogni $A \in \mathfrak{B}(\mathbb{R})$ si ha che $f^{-1}(A) \in 
\mathfrak{M}$; siccome per ogni $c \in \mathbb{R}$ troviamo che $(-\infty,c) \in \mathfrak{B}(\mathbb{R})$,
si ha che $f^{-1} (-\infty,c) = \{x\ |\   f(x) < c\} \in \mathfrak{M}$, 
cioé $\{x\ |\   f(x) < c\}$ è un insieme misurabile.\\ 
$(\Leftarrow)$ Viceversa supponiamo che l'insieme
$\{x\ |\   f(x) < c\}$ sia misurabile per ogni $c \in \mathbb{R}$ : risulta quindi che per ogni $c \in \mathbb{R}$ si ha
\begin{displaymath}
f^{-1}(-\infty,c) = \{x\ |\   f(x) < c\} \in \mathfrak{M} .
\end{displaymath}
Ricordando che $\mathfrak{B}(\mathbb{R}) = \sigma\{(-\infty,c) |  c \in \mathbb{R}\}$ e applicando il lemma 
\ref{lemmtess}, segue immediatamente la tesi.  
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
Vediamo ora che le funzioni misurabili si comportano bene rispetto alle quattro operazioni:
\begin{prop}
Somma, differenza, prodotto e quoziente (laddove ben definito) di funzioni misurabili sono misurabili.\\
\newline \dimo 
La dimostrazione si articola in più passi:
\begin{description}
\item[passo $i)$] dimostriamo che se $f$ è misurabile, allora $f+a$ e $kf$ sono misurabili per ogni $a,k \in 
\mathbb{R}$: sappiamo che per la proposizione \ref{critmis}, l'insieme $\{x\ |\   f(x) < c \}$ è misurabile per 
ogni $c \in \mathbb{R}$, da cui segue che sono misurabili gli insiemi $\{x\ |\   f(x) < c-a \}$ e 
$\{x\ |\   f(x) < c/k \}$ rispettivamente per ogni $a \in \mathbb{R}$ e per ogni $k \in \mathbb{R} 
\smallsetminus \{0\}$; ma $\{x\ |\   f(x) < c-a \}=\{x\ |\   f(x)+a < c \}$ e $\{x\ |\   f(x) < c/k \}=\{x\ |\   kf(x) < c \}$
e quindi sempre per la proposizione \ref{critmis} segue che $f+a$ e $kf$ sono misurabili.
Nel caso in cui $k = 0$, si ha che $f(x) = 0$ è una funzione misurabile (infatti $f^{-1}(0) = 
\mathbb{R} \in \mathfrak{M}$).\\ 
\item[passo $ii)$] dimostriamo che, prese $f$, $g$ misurabili, allora $f+g$ è una funzione misurabile. 
Per farlo proviamo che l'insieme $\{x\ |\   f(x) < g(x)\}$ è misurabile: a tal scopo scriviamo prima l'uguaglianza
\begin{equation} \label{eqpazz}
\{x\ |\   f(x) < g(x)\} = \bigcup_{r_k \in \mathbb{Q}}\{x\ |\   f(x) < r_k\} \cap \{x\ |\   g(x) > r_k\},
\end{equation}
ove $\{r_k\}_{k \in \mathbb{N}}$ è la successione dei razionali (lasciamo la dimostrazione della disuguaglianza,
facile, e quella della misurabilità, facilissima, per esercizio). Ciò premesso risulta subito che per ogni
$c \in \mathbb{R}$ vale l'uguaglianza 
\begin{displaymath}
\{x\ |\   f(x)+g(x) < c\} = \{x\ |\   f(x) < c-g(x)\}
\end{displaymath}
e quindi dall'equazione \ref{eqpazz} e dal passo $i)$ segue pedissequamente che $f+g$ è misurabile;
analogamente si procede per $f-g$.\\
\item[passo $iii)$] dimostriamo che se $f,g$ sono misurabili allora $fg$ è misurabile: 
anzitutto vale l'ovvia identità (detta identità di polarizzazione)\index{Identità di polarizzazione}
\begin{equation} \label{idpol}
fg = \frac{1}{4} [(f+g)^2 - (f-g)^2] ; 
\end{equation}
inoltre il passo $ii)$ e il corollario \ref{compfnzcontmis} implicano che le funzioni $(f+g)^2$ e 
$(f-g)^2$ sono misurabili.
Se combiniamo quanto appena detto con l'equazione \ref{idpol}, otteniamo che $fg$ è misurabile.\\
\item[passo $iv)$] dimostriamo che se $f,g$ sono misurabili, allora $\frac{f}{g}$ è misurabile per ogni $x$ tale che 
$g(x) \neq 0$: a tal proposito dimostriamo anzitutto che $\frac{1}{g(x)}$ è misurabile per ogni $x$ tale che $g(x) \neq 0$. 
Sfruttiamo allora le seguenti banali identità (che il lettore è pregato di verificare per esercizio):
se $c > 0$ allora
\begin{equation} \label{c > 0}
\Big\{x \Big|  \frac{1}{g(x)} < c\Big\} = \{x\ |\   g(x) < 0\} \cup \Big\{x \Big|  g(x) > \frac{1}{c}\Big\} ;
\end{equation}
se $c = 0$ allora 
\begin{equation}\label{c = 0}
\Big\{x \Big|  \frac{1}{g(x)} < c\Big\} = \{x\ |\   g(x) < c\} ;
\end{equation}
infine se $c < 0$ allora
\begin{equation} \label{c < 0}
\Big\{x \Big|  \frac{1}{g(x)} < c\Big\} = \{x\ |\   g(x) < 0\} \cap \Big\{x \Big|  g(x) > \frac{1}{c}\Big\} ;
\end{equation}
A questo punto mettendo assieme le relazioni \ref{c > 0}, \ref{c = 0}, \ref{c < 0} ed il lemma \ref{critmis}, segue che 
$\frac{1}{g(x)}$ è misurabile per ogni $x$ tale che $g(x) \neq 0$. Infine il passo $iii)$ ci conduce alla tesi.\\*
\end{description}
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
Introduciamo ora due concetti che ci semplificheranno spesso la vita nel seguito (in particolare quando tratteremo 
l'integrazione astratta):
\begin{defin}\label{q.o.}
Sia  $\mathscr{P}$ una generica proprietà e sia $X$ un insieme. Si dice che $X$ soddisfa $\mathscr{P}$ 
\emph{quasi ovunque} (e si scrive $X$ soddisfa $\mathscr{P}$ $q.o.$)
se
\begin{displaymath}
\mu\{x\in x\ |\   \textrm{$x$ non soddisfa $\mathscr{P}$}\} = 0. \index{Quasi ovunque}
\end{displaymath}
\end{defin}
\begin{defin}\label{equiv}
Siano $f,g$ definite su uno stesso insieme misurabile. Si dice che $f$ è \emph{equivalente} a $g$ (e si scrive $f\sim g$)
se vale la seguente proprietà:
\begin{displaymath}
\mu\{x\ |\   f(x)\neq g(x)\} = 0.
\end{displaymath}
\end{defin} \index{Funzione!equivalente}
\begin{esem}
Alla luce della definizione \ref{q.o.}, la definizione \ref{equiv} si può riscrivere così: due funzioni $f,g$ definite su 
uno stesso insieme misurabile si dicono equivalenti se e solo se sono quasi ovunque uguali.
\end{esem}
\begin{esem}
La nozione di equivalenza tra funzioni permette di semplificare notelvomente funzioni molto complicate, 
addiritura il cui grafico è intracciabile:
si consideri la ben nota funzione di Dirichlet (estesa a tutta la retta reale): \index{Funzione! di Dirichlet}
\begin{displaymath}
D(x) = \left\{ \begin{array}{ll}
1 & \textrm{se $x\in \mathbb{Q}$}\\
0 & \textrm{altrimenti}
 \end{array} \right.
\end{displaymath}
Tale funzione è equivalente alla funzione banale $f(x)=0$ (poiché $\mathbb{Q}$ ha misura nulla; vedi la sottosezione \ref{insnummisnulla}).
\end{esem}
\begin{oss}
L'attento lettore avrà notato che la simbologia $f\sim g$ ed il termine equivalenza sono lessicograficamente correlati alla terminologia utilizzata
quando si lavora con le relazioni di equivalenza. In effetti definiamo la relazione $\sim$ sull'insieme $\mathcal{M}$ 
di tutte le funzioni aventi dominio su uno stesso insieme misurabile ponendo
\begin{displaymath}
f\sim g \iff \textrm{$f$ è equivalente a $g$} 
\end{displaymath}
Si prova che tale relazione è di equivalenza: la riflessività e la simmetria sono ovvie, e pertanto vengono lasciate come esercizio.
Verichiamo la transitività: prendiamo tre funzioni $f,g,h$ in $\mathcal{M}$ tali che $f\sim g$ e $g\sim h$; allora vale la relazione
\begin{equation}\label{eqequiv}
\{x\ |\   f(x)\neq h(x)\} \subseteq \{x\ |\   f(x)\neq g(x)\}\cup \{x\ |\   g(x)\neq h(x)\}
\end{equation}
Infatti se esistesse $x_0\in \{x\ |\   f(x)\neq h(x)\}$ tale da sooddifare
la condizione $x_0\notin \{x\ |\   f(x)\neq g(x)\}\cup \{x\ |\   g(x)\neq h(x)\}$,
allora per tale $x_0$ avremmo che $f(x_0) = g(x_0) = h(x_0)$, contro l'ipotesi. Pertanto abbiamo provato la relazione \ref{eqequiv}, 
la quale implica che 
\begin{displaymath}
\mu\{x\ |\   f(x)\neq h(x)\} \leq \mu\{x\ |\   f(x)\neq g(x)\} + \mu\{x\ |\   g(x)\neq h(x)\},
\end{displaymath}
da cui segue che $\mu\{x\ |\   f(x)\neq h(x)\} = 0$. Questo prova la transitività.
\end{oss}
\begin{oss}
Per funzioni continue la nozione di equivalenza è inessenziale: precisamente due funzioni $f,g\in\mathcal{M}$ continue sono equivalenti se e solo se coincidono.
L'implicazione $(\Leftarrow)$ è ovvia. Viceversa se, per assurdo, esistesse $x_0$ tale che $f(x_0)\neq g(x_0)$, allora esisterebbe
$\varepsilon > 0$ tale che per ogni $x\in B(x_0,\varepsilon)$ si avrebbe che $f(x_0)\neq g(x_0)$; siccome  $\mu(B(x_0,\varepsilon)) > 0$, segue che
$f$ e $g$ non sono equivalenti, assurdo.
\end{oss}
\begin{oss}\label{misnulla}
Ogni funzione è misurabile se ristretta ad un insieme di misura nulla. Infatti  sia $f:(X,\mathfrak{M},\mu)\to (\mathbb{R},\mathfrak{B}(\mathbb{R}))$ con $\mu(X)=0$: allora
per ogni $B\in\mathfrak{B}(\mathbb{R})$ si ha che $f^{-1}(B)\subset X$ e quindi $\mu(f^{-1}(B))=0$ a causa della completezza di $\mu$.
Siccome ogni sottoinsieme di misura nulla è misurabile, segue che $f^{-1}(B)\in\mathfrak{M}$, cioé $f$ è misurabile.
\end{oss}
\begin{prop}
Siano $f,g$ due funzioni equivalenti definite su un insieme $X$ misurabile. Se $f$ è una funzione misurabile, allora $g$ è una funzione misurabile.\\
\newline \dimo  Sia $A\subset X$ l'insieme ove $f(x)=g(x)$: allora su $A$ vale 
\begin{displaymath}
\{x\ |\   f(x) < c\} = \{x\ |\   g(x) < c\}, \quad \forall c\in \mathbb{R},
\end{displaymath}
e quindi $g$ è misurabile su $A$ per il lemma \ref{critmis}. Inoltre su $X\smallsetminus A$  $g$ è misurabile per l'osservazione \ref{misnulla}. Quindi $g$ è misurabile su $X$.\\*  
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\end{section}
\begin{section}{Convergenza di funzioni}
Le funzioni misurabili si comportano bene rispetto all'operatore limite:
\begin{prop}\label{limfnzmis}
Il limite puntuale di funzioni misurabili è una funzione misurabile.\\
\newline \dimo  Sia $\{f_n\}_{n \in \mathbb{N}}$ una successione di funzioni misurabili e poniamo $f := 
\lim_{n\to+\infty}f_n(x)$: si tratta allora di mostrare che $f$ è una funzione misurabile. A tal scopo è sufficiente
provare la relazione
\begin{equation} \label{eqlim}
\{x\ |\   f(x) < c\} = \bigcup_k \bigcup_n \bigcap_{m \geq n} \Big\{x\ |\   f_n(x) < c-\frac{1}{k}\Big\}.
\end{equation}
Se prendiamo un $x$ nell'insieme a sinistra, allora segue dalla definizione di limite che esistono 
$k\in\mathbb{R}$ e $n \in\mathbb{N}$ tali che per ogni $m \geq n$ si ha che 
$f_n(x) < c-\frac{1}{k}$; 
viceversa se prendiamo un $x$ nell'insieme a destra dell'uguale, allora vuol dire che esistono $k \in \mathbb{R}$ e $n 
\in \mathbb{N}$ tale che per ogni $m \geq n$ 
si ha che $f_n(x) < c-\frac{1}{k}$, e quindi sempre dalla definizione di limite segue che, definitivamente, $f(x) 
< c-\frac{1}{k} < c$. A questo punto mettendo insieme l'equazione \ref{eqlim} e il lemma \ref{critmis}, otteniamo la tesi. 
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
Vediamo ora una definizione di convergenza più debole di quella puntuale:
\begin{defin}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni. Si dice che $f_n$ \emph{converge quasi ovunque} ad una funzione $f$ (e si scrive $f_n\to f$  $q.o.$)
se \index{Convergenza! quasi ovunque} 
\begin{displaymath}
\mu\{x\ |\   \lim_{n\to +\infty}f_n(x)\neq f(x)\}=0
\end{displaymath}
\end{defin}
\begin{prop}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni misurabili definite su $X$ tali che $f_n\to f$  $q.o$. Allora $f(x)$ è una funzione misurabile.\\
\newline \dimo  Sia $A\subset X$ l'insieme ove $\lim_{n\to +\infty}f_n(x)=f(x)$. Allora, sull'insieme $A$, risulta che $f$ è una 
funzione misurabile per la proposizione \ref{limfnzmis}. Inoltre $f$ è misurabile su $X\smallsetminus A$ per l'osservazione \ref{misnulla},
e quindi $f$ è misurabile su $X$.   
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
\begin{prop}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni misurabili definite su $X$ convergente quasi ovunque a $f(x)$. Allora
$f_n$ converge quasi ovunque a $g$ se e solo se $f$ è equivalente a $g$.\\
\newline \dimo  $(\Rightarrow)$ Se, per assurdo, $f\nsim g$, allora esistono un insieme $B\subset X$ con $\mu(B)\neq 0$
e un $x_0\in B$ tale che $f(x_0)\neq g(x_0)$. Allora, per tale $x_0$, si ha che $f(x_0)=\lim_{n\to +\infty}f_n(x_0)=g(x_0)$ con $f(x_0)\neq g(x_0)$,
contro l'unicità del limite.\\ 
$(\Leftarrow)$ Viceversa sia $A\subset X$ l'insieme ove $f(x)=g(x)$ : allora su $A$ accade che 
$\lim_{n\to +\infty}f_n(x)=f(x)=g(x)$. Su $X\smallsetminus A$ l'uguaglianza precedente può anche essere falsa, e quindi, complessivamente, si ha che $f_n$ converge a $g$ quasi ovunque 
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
Ci accingiamo ora a dimostrare un importante risultato che ci fornisce un fruttuoso legame tra convergenza uniforme e convergenza quasi ovunque.
\begin{teo}{\textbf{(di Egorov)}} \index{Teorema! di Egorov}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni misurabili definite su un insieme $E$ misurabile convergenti ad una funzione $f(x)$ quasi ovunque;
allora
\begin{itemize}
\item[$i)$] esistono $\delta >0$ ed $E_{\delta}\subset E$ misurabile tale che $\mu(E_{\delta})>\mu(E)-\delta$ ;
\item[$ii)$] la successione $\{f_n(x)\}_{n\in\mathbb{N}}$ converge uniformemente su $E_{\delta}$ .
\end{itemize}
\dimo  Definiamo gli insiemi
\begin{displaymath}
E_n^m := \bigcap_{i\geq n}\Big\{x\ |\  |  f_i(x)-f(x)|\leq\frac{1}{m}\Big\};
\end{displaymath}
abbiamo che gli $E_n^m$ sono misurabili e vale la catena ascendente di inclusoni
\begin{equation}\label{catasc1}
E_1^m\subseteq E_2^m\subseteq\ldots\subseteq E_n^m\subseteq\ldots
\end{equation}
Definiamo inoltre l'insieme misurabile 
\begin{displaymath}
E^m := \bigcup_m E_n^m.
\end{displaymath}
Alla luce delle inclusioni \ref{catasc1}, possiamo scrivere un'altra catena ascendente di inclusioni:
\begin{equation}\label{catasc2}
E^m\smallsetminus E_1^m\supseteq E^m\smallsetminus E_2^m\supseteq\ldots\supseteq E^m\smallsetminus E_n^m\supseteq\ldots
\end{equation}
A questo punto possiamo applicare la proprietà di continuità della misura grazie alle inclusioni \ref{catasc2} e concludere che 
\begin{equation}\label{mis=0}
\mu(\bigcap_n E^m\smallsetminus E_n^m)=\lim_{n\to +\infty}\mu(E^m\smallsetminus E_n^m)=0,
\end{equation}
visto che 
\begin{displaymath}
\bigcap_n E^m\smallsetminus E_n^m = E^m\smallsetminus\bigcup_n E_n^m = \varnothing .
\end{displaymath}
Nella terminologia dei limiti, possiamo riscrivere la relazione \ref{mis=0} in tal modo:
\begin{displaymath}
\forall\varepsilon >0, \forall m\in\mathbb{N}\quad  \exists n_0(m):\quad \forall n\geq n_0(m) \quad \mu(E^m\smallsetminus E_n^m)<\frac{\delta}{2^m}. 
\end{displaymath}
Poniamo ora 
\begin{displaymath}
E_{\delta} := \bigcap_m E_{n_0(m)}^m;
\end{displaymath}
risulta che $E_{\delta}$ è un insieme misurabile contenuto in $E$ che soddisfa la tesi: innanzitutto dalla definizione di $E_{\delta}$ segue subito l'affermazione $ii)$
poiché se $x\in E_{\delta}$ allora
\begin{displaymath}
\forall m \quad \exists n_0(m):\quad  \forall i\geq n_0(m), \forall x\in E,\quad   |  f_i(x)-f(x)| <\frac{1}{m} ; 
\end{displaymath}
scegliendo quindi $m_0<1/\varepsilon$ segue che le $f_n$ convergono uniformemente ad $f$ su $E_{\delta}$.
Per provare invece la relazione $i)$, cominciamo col provare che $\mu(E\smallsetminus E^m)=0$ : infatti se $x\in E\smallsetminus E^m$
allora per ogni $\varepsilon >0$ esiste sempre un $i$ abbastanza grande tale che $|  f_i(x)-f(x)|\geq\varepsilon$, cioé le $f_n$ non convergono
ad $f$ su $E\smallsetminus E^m$ ; dall'ipotesi di convergenza quasi ovunque delle $f_n$ ad $f$ segue quindi che $\mu(E\smallsetminus E^m)=0$.
Risulta quindi che 
\begin{displaymath}
\mu(E\smallsetminus E_{n_0(m)}^m)\leq\mu(E\smallsetminus E^m)+\mu(E^m\smallsetminus E_{n_0(m)}^m)\leq\frac{\delta}{2^m}
\end{displaymath}
Allora possiamo calcolare la misura di $E\smallsetminus E_{\delta}$:
\begin{displaymath}
\mu(E\smallsetminus E_{\delta})=\mu(\bigcup_m E\smallsetminus E_{n_0(m)}^m)\leq\sum_m\mu(E\smallsetminus E_{n_0(m)}^m)<\delta.
\end{displaymath}
Ma $E_{\delta}$ è misurabile, per cui $\mu(E\smallsetminus E_{\delta})=\mu(E)-\mu(E_\delta)<\delta$, da cui la tesi.  
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Vediamo ora una nuova definizione di convergenza:
\begin{defin}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni misurabili convergenti ad una funzione $f(x)$. Si dice che 
$f_n(x)$ \emph{converge in misura} a $f(x)$ se per ogni $\varepsilon>0$ si ha \index{Convergenza!in misura}
\begin{displaymath}
\lim_{n\to \infty}\mu\{x\ |\  |  f_n(x)-f(x)|\geq\varepsilon\}=0.
\end{displaymath}
\end{defin}
\begin{prop}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni misurabili convergenti ad una funzione $f(x)$ in misura. Allora 
$f_n$ converge a $g$ in misura se e solo se $f$ è equivalente a $g$.\\
\newline \dimo  $(\Rightarrow)$ Sia $f_n$ convergente in misura a $g$ ; 
notiamo che vale la seguente identità (figlia della diseguaglianza triangolare)
\begin{displaymath}
\{x\ |\ |f-g|\geq \delta\}\subseteq \Big\{x\ \Big|\ |f-f_n|\geq \frac{\delta}{2}\Big\}\cup\Big\{x\ \Big|\ |f_n-g|\geq \frac{\delta}{2}\Big\},
\end{displaymath}
da cui possiamo immediatamente dedurre che
\begin{displaymath}
\mu\{x\ |\ |f-g|\geq \delta\}\leq \mu\Big\{x\ \Big|\  |f-f_n|\geq \frac{\delta}{2}\Big\}+\mu\Big\{x\ \Big|\ |f_n-g|\geq \frac{\delta}{2}\Big\};
\end{displaymath}
si conclude quindi che 
\begin{equation}\label{muf-g=0}
\mu\{x\ |\ |f-g|\geq \delta\}=0.
\end{equation}
Si noti inoltre che vale l'ovvia identità (pregasi verificare per esercizio!)
\begin{equation}\label{fdiversog}
\{x\ |\   f(x)\neq g(x) \}=\bigcup_n\Big\{x\ \Big|\ |f(x)-g(x)|\geq\frac{1}{n}\Big\}
\end{equation}
Ponendo $\{\delta_n\} := \frac{1}{n}$ e osservando le relazioni \ref{muf-g=0}  e  \ref{fdiversog} otteniamo che:
\begin{displaymath}
\mu\{x\ |\ |f(x)\neq g(x) \}\leq\sum_n \Big\{x\ \Big|\ |f(x)-g(x)|\geq\frac{1}{n}\Big\}=0,
\end{displaymath}
da cui segue che $f$ è equivalente a $g$.\\
$(\Leftarrow)$ Viceversa sia $f\sim g$ ; nello stesso modo di prima si prova che 
\begin{displaymath}
\mu\{x\ |\ |f_n-g|\geq \delta\}\leq \mu\Big\{x\ \Big|\ |f_n-f|\geq \frac{\delta}{2}\Big\}+
\mu\Big\{x\ \Big|\ |f-g|\geq \frac{\delta}{2}\Big\},
\end{displaymath}
da cui segue subito la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{prop}
I diligenti lettori   si chiederanno: ci saranno del legami tra convergenza quasi ovunque e convergenza in misura? La risposta a tale quesito è affermativa, e verrà esauriantemente
fornita nei successivi teoremi. Vediamo:
\begin{teo}\label{qoimplicamis}
Sia $\{f_n(x)\}_{n\in\mathbb{N}}$ una successione di funzioni convergente a $f(x)$ quasi ovunque. Allora $f_n$ converge a $f$ in misura.\\
\newline \dimo  Sia $A$ l'insieme ove $f_n\nto f$; definiamo inoltre i seguenti insiemi:
\begin{displaymath}
E_k(\varepsilon) := \{x\ |\   f_k(x)-f(x)|\geq\varepsilon\},
\end{displaymath}
\begin{displaymath}
R_n(\varepsilon) := \bigcup_{k\geq n}E_k(\varepsilon),
\end{displaymath}
\begin{displaymath}
M := \bigcap_n R_n(\varepsilon).     
\end{displaymath}
Notiamo che 
\begin{displaymath}
R_1(\varepsilon)\supseteq R_2(\varepsilon)\supseteq\ldots\supseteq R_n(\varepsilon)\supseteq\ldots
\end{displaymath}
e, conseguentemente, possiamo applicare la proprietà di continuità della misura all'insieme M:
\begin{equation}\label{misuraM}
\mu(M)=\lim_{n\to +\infty}\mu(R_n(\varepsilon)). 
\end{equation}
Dimostriamo ora che $M\subset A$ : infatti se $x_0\in M$ allora per ogni n esiste $k\geq n$ tale che $|  f_k(x_0)-f(x_0)|\geq\varepsilon$, cioé 
per tale $x_0$ si ha che $f_n(x_0)\nto f_(x_0)$, o, in altri termini, $x_0\in A$. A questo punto, da quanto appena dimostrato e 
dalla relazione \ref{misuraM}, deduciamo che $\mu(R_n(\varepsilon))\to 0$. Infine dal fatto che $E_k(\varepsilon)\subseteq R_n(\varepsilon)$ deduciamo
che $\mu(E_k(\varepsilon))\to 0$, cioé la tesi.
\begin{flushright}
\emph{c.v.d}.
\end{flushright}
\end{teo}
\begin{oss}
Il viceversa del teorema precedente è falso: come controesempio consideriamo la successione di funzioni 
\begin{displaymath}
f_k^{(i)} := \left\{\begin{array}{ll}
1 & \textrm{se $x\in(\frac{i-1}{k},\frac{i}{k})$}\\
0 & \textrm{altrimenti} 
\end{array} \right.
\end{displaymath}
Evidentemente si ha che le $f_k^{(i)}$ non convergono in alcun punto (per convincersi di questo è sufficiente tracciare il grafico di tali funzioni);
tuttavia esse convergono in misura a $0$ visto che 
\begin{displaymath}
\mu\{x\ |\   f_k^{(i)}\geq\varepsilon\}=\mu\{x\ |\   f_k^{(i)}=1\}=\mu\Big(\frac{1}{k}\Big)\to 0
\end{displaymath}
\end{oss}
Tuttavia vale una sorta di viceversa del teorema \ref{qoimplicamis}
\begin{teo}
Sia $\{f_n\}_{n\in\mathbb{N}}$ una successione di funzioni definite in $E$ convergenti ad $f(x)$ in misura.
Allora esiste una sottosuccessione $\{f_{n_k}\}_{k\in\mathbb{N}}$ convergente ad $f$ quasi ovunque.\\
\newline \dimo Sia $\{\varepsilon_k\}_{k\in\mathbb{N}}$ una succesione tale che $\lim_{n\to +\infty}\varepsilon_k = 0$ 
e sia $\{\eta_k\}_{k\in\mathbb{N}}$ una successione tale che $\sum_k \eta_k$ sia una serie convergente. Grazie all'ipotesi
possiamo definire ricorsivamente la successione $\{n_k\}_{k\in\mathbb{N}}$ in tal modo: esiste $n_1$ tale che
\begin{displaymath}
\mu\{x\ |\   f_{n_1}(x)-f(x)|\geq\varepsilon_1\}<\eta_1,
\end{displaymath}
successivamente esiste $n_2>n_1$ tale che
\begin{displaymath}
\mu\{x\ |\   f_{n_2}(x)-f(x)|\geq\varepsilon_2\}<\eta_2
\end{displaymath}
e, in generale, esite $n_k>n_{k-1}$ tale che
\begin{displaymath}
\exists n_1\in\mathbb{N} : \mu\{x\ |\   f_{n_k}(x)-f(x)|\geq\varepsilon_k\}<\eta_k
\end{displaymath}
Definiamo ora gli insiemi
\begin{displaymath}
E_k(\varepsilon_k) := \{x\ |\   f_k(x)-f(x)|\geq\varepsilon_k\},
\end{displaymath}
\begin{displaymath}
R_n := \bigcup_{k\geq n}E_k(\varepsilon_k),\qquad M := \bigcap_n R_n.   
\end{displaymath}
Alla luce del fatto che 
\begin{displaymath}
R_1\supseteq R_2\supseteq\ldots\supseteq R_n\supseteq\ldots
\end{displaymath}
possiamo applicare la proprietà di continuità della misura all'insieme $M$ e concludere che
\begin{equation}\label{muM=0}
\mu(M)=\lim_{n\to +\infty}\mu(R_n);
\end{equation}
inoltre possiamo stimare la misura degli $R_n$ :
\begin{equation}\label{muRn}
\mu(R_n)\leq\sum_{k=n}^{\infty}\mu(E_k(\varepsilon_k))<\sum_{k=n}^{\infty}\eta_k\to 0.
\end{equation}
In conclusione da \ref{muM=0}  e  \ref{muRn} segue che $\mu(M)=0$. A questo punto ci rimane solo da dimostrare che
$f_{n_k}(x)$ convergono su $E\smallsetminus M$ : infatti se $x_0\in E\smallsetminus M$ allora esiste $n$ tale che per ogni
$k\geq n$ si ha che $|  f_k(x_0)-f(x_0)| <\varepsilon_k$ ; siccome avevamo scelto gli $\{\varepsilon_k\}_{k\in\mathbb{N}}$
in modo tale che $\varepsilon_k\to 0$, segue la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\end{section}
\end{chapter}
\begin{chapter}{Integrale di Lebesgue}
\lettrine[lines=1]{E}{d eccoci arrivati} a quello che indubbiamente costituisce il nucleo della teoria
della misura e dei complementi di analisi: l'integrale di Lebesgue. 
Si tratta di un'integrazione la cui idea di base è molto, molto simile a quella
di Riemann (la quale, siamo ragionevolmente certi, il lettore non sentiva impellentemente il bisogno
insopprimibile di ridefinire), ma che la estende, allargando non di poco un campo di utilità 
già piuttosto vasto; insomma, tanto fumo, ma anche tanto arrosto.
\begin{section}{Definizione dell'integrale}
\begin{defin}
Una funzione si dice \emph{semplice} se assume una quantità al più numerabile di
valori, ovvero se il suo codominio è discreto: \index{Funzione!semplice}
\begin{displaymath}
Y = \{y_{1}, \ldots, y_{n}, \ldots\}.
\end{displaymath}
\end{defin}
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.4]
\draw[thick, ->](-1,0)--(5,0);
\draw[thick, ->](0,-1)--(0,5);
\draw (-1,3)--(1,3);
\draw (1,1)--(2,1);
\draw (2,2)--(3,2);
\draw (3,4)--(5,4);
\filldraw[fill=green!30!white, thin](10,0,4)--(10,0,6)--(12,0,6)--(12,0,4)--cycle;
\draw[thick, ->](10,0,0)--(10,0,6);
\draw[thick, ->](10,0,0)--(10,6,0);
\draw[thick, ->](10,0,0)--(16,0,0);
\filldraw[fill=green!30!white, thin](12,1.5,0)--(14,1.5,0)--(14,1.5,2)--(16,1.5,2)--(16,1.5,4)--(14,1.5,4)--
(14,1.5,6)--(12,1.5,6)--(12,1.5,4)--(10,1.5,4)--(10,1.5,2)--(12,1.5,2)--cycle;
\filldraw[fill=green!30!white, thin](10,3,0)--(10,3,2)--(12,3,2)--(12,3,0)--cycle;
\filldraw[fill=green!30!white, thin](14,2,0)--(14,2,2)--(16,2,2)--(16,2,0)--cycle;
\filldraw[fill=green!30!white, thin](14,1,4)--(14,1,6)--(16,1,6)--(16,1,4)--cycle;
\end{tikzpicture}
\end{center}
\caption{Esempi di funzioni semplici}
\end{figure}
Enunciamo e dimostriamo ora due teoremi che caratterizzano le funzioni semplici.
\begin{teo}
Sia $f$ una funzione semplice definita sullo spazio di misura $(X,\mathfrak{S}_X)$ a
valori in $Y=\{y_{1}, \ldots, y_n, \ldots\}$; $f$ è misurabile se e solo se
\begin{displaymath}
f^{-1}({y_i}) \in \mathfrak{S}_X, \quad \forall y_i \in Y.
\end{displaymath}
\dimo
Se $f$ è misurabile, la tesi è ovvia; viceversa poiché l'insieme $\{y_i\}_i$ è un sistema di generatori per la
$\sigma$-algebra dei singleton $\mathfrak{S}_Y=\sigma(\{y_i\})$ definita su $Y$, la tesi
segue subito dal lemma \ref{lemmtess}
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Risulta chiaro che, se $f$ è una funzione semplice definita su un insieme $A$,
definendo degli insiemi $A_n$ come
\begin{displaymath}
A_n = \{x \in A |  f(x) = y_n\}
\end{displaymath}
otteniamo una partizione di $A$, ovvero $A=\bigcupdot_n A_n$, e quindi ogni funzione
semplice si può sempre scrivere in modo unico come
\begin{displaymath}
f(x) = \sum_n y_n\textrm{\Large$\chi$}_{A_n}(x).
\end{displaymath}
D'ora in avanti chiameremo \emph{partizione canonica rispetto a $f$} questa particolare
partizione di $A$. \index{Partizione canonica}
\begin{teo}\label{succfunzsempmis}
Una funzione $f$ è misurabile se e solo se esiste una successione $\{f_n\}_n$ di
funzioni semplici misurabili che converge uniformemente ad $f$.\\
\newline
\dimo
$(\Leftarrow)$ Segue subito dalla proposizione \ref{limfnzmis}. \\
$(\Rightarrow)$ Viceversa, definiamo le $f_n$ come segue:
\begin{displaymath}
f_n^{m} = \frac{m}{n} \textrm{\Large$\chi$}_{\{x\ |\frac{m}{n} \leq f(x) \leq \frac{m+1}{n}\}}(x), \quad m \in \mathbb{Z}, n \in \mathbb{N}.
\end{displaymath}
è evidente che le $f_m^{m}$ sono semplici; inoltre per il teorema precedente
sono misurabili (infatti si ha $A_n^{m}=\{x \in A |  \frac{m}{n} \leq f(x) \leq \frac{m+1}{n}\}$,
i quali sono misurabili). Infine si ha per costruzione
$f_n^{m}(x) \leq f(x) \leq f_n^{m}(x)+\frac{1}{n}$ e dunque
\begin{displaymath}
\forall \varepsilon >0 \quad \exists n_{0} : \forall n \geq n_{0}, \forall x \quad |  f_{n}(x)-f(x)| < \varepsilon,
\end{displaymath}
che è la definizione di convergenza uniforme.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Ora possiamo finalmente introdurre il concetto di integrale di Lebesgue per le funzioni
semplici su insiemi di misura finita.
\begin{defin}
Sia $f$ una funzione semplice, definita su un insieme
$A$ con $\mu(A)<+\infty$, che prenda valori in $\{y_1, \ldots, y_n, \ldots\}$ e sia
$\{A_n\}_n$ la partizione canonica di $A$ rispetto a $f$. Risulta naturale porre 
\footnote{Si noti che il simbolo di integrale $\int$
si è conservato, ma invece di essere seguito da $dx$, ci troviamo con un $d\mu$; la ragione di questa
notazione è evidente dalla definizione (e i più audaci possono avanzare anche un parallelismo tra 
le due notazioni \ldots).}
\begin{equation}
\int_{A} f(x)d\mu = \sum_{n} y_{n}\mu(A_{n}). \label{serieintlebesgue}
\end{equation}
$f$ si dice \emph{integrabile secondo Lebesgue} su $A$, o più semplicemente \emph{$L$-integrabile}, 
se la serie \ref{serieintlebesgue} è assolutamente convergente, 
cioé se \index{$L$-integrabilità!di funzioni semplici}
\begin{displaymath}
\sum_n|y_n|\mu(A_n) <+\infty. 
\end{displaymath}
In tal caso l'\emph{integrale di Lebesgue} di $f$ su $A$ è dato dalla somma della
serie  \ref{serieintlebesgue}.
\end{defin}
Notiamo esplicitamente che se invece di considerare la partizione canonica $\{A_n\}_n$
di $A$ usata sinora si definisce una seconda partizione $\{B_k\}_k$ (e ciò comporta la possibilità di avere 
più indici $k$ corrispondenti ad uno stesso valore $y_n$), il valore dell'integrale \ref{serieintlebesgue} 
non cambia, come mostra il seguente
\begin{teo}
L'integrale di Lebesgue per funzioni semplici definite su un insieme $A$ di misura finita
non dipende dalla partizione scelta su $A$.\\
\newline
\dimo
Scriviamo
\begin{displaymath}
f(x) = \sum_n y_n \textrm{\Large$\chi$}_{A_n}(x) = \sum_k y_k \textrm{\Large$\chi$}_{B_k}(x),
\end{displaymath}
ove $\{A_n\}_n$ è la partizione canonica di $A$ e $\{B_k\}_k$ è la
partizione definita poc'anzi; allora risulta
\begin{displaymath}
A_n = A_n \cap A = A_n \cap (\bigcupdot_k B_k) = \bigcupdot_k (A_n \cap B_k),
\end{displaymath}
e analogamente $B_k=\bigcupdot_n (A_n \cap B_k)$, da cui si conclude che
\begin{displaymath}
\int_{A} f(x)d\mu = \sum_n y_n\mu(A_n) = \sum_{n,k} y_n\mu(A_n \cap B_k) = \sum_k y_k\mu(B_k).
\end{displaymath}
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Similmente a quanto fatto per la misura di Lebesgue, definita dapprima su rettangoli
e insiemi elementari ed estesa successivamente ad una categoria più ampia di insiemi,
così avviene per l'\emph{integrale} di Lebesgue: dopo aver analizzato il caso delle
funzioni semplici, considereremo le funzioni qualsiasi definite su insiemi di misura finita
e successivamente su insiemi di misura arbitraria.
\begin{defin}
Sia $f$ una funzione qualsiasi definita su un insieme $A$ di misura finita; $f$ si dice
\emph{$L$-integrabile} su $A$ se esiste una successione $\{f_n\}_n$ di funzioni semplici
$L$-integrabili su $A$ che converga uniformemente ad $f$. In tal caso si pone 
\index{$L$-integrabilità!di funzioni qualsiasi}
\begin{equation}
\int_{A} f(x)d\mu = \lim_{n\to \infty} \int_{A} f_n(x)d\mu. \label{intdilebesguefunzqualsiasi}
\end{equation}
\end{defin}
Affinchè tale definizione sia ben posta, dobbiamo verificare alcune condizioni.
\begin{itemize}
\item[$i)$] Il limite \ref{intdilebesguefunzqualsiasi} deve esistere finito per ogni scelta della 
successione $\{f_n\}_n$
che soddisfi la definizione; ma infatti dalla convergenza uniforme segue che per ogni
$\varepsilon >0$ si ha definitivamente $|  f_n(x)-f_m(x)| <\varepsilon$, da cui
\begin{multline*}
\Big|\int_{A} f_n(x)d\mu - \int_{A} f_m(x)d\mu\Big|  \leq \int_{A} |  f_n(x)-f_m(x)|  d\mu\leq\\
\leq \sup_x\ |\   f_n(x)-f_m(x)|\mu(A) < \varepsilon \mu(A);
\end{multline*}
la tesi segue dal fatto che $L^1(A)$, l'insieme delle funzioni integrabili, è completo (e qui facciamo un atto di fede).
\item[$ii)$] Il limite \ref{intdilebesguefunzqualsiasi}  non deve dipendere dalla particolare scelta della successione
$\{f_n\}_n$; supponiamo per assurdo che esistano due successioni $\{f_n\}_n$,
$\{\tilde{f}_n\}_n$ tali che
\begin{displaymath}
\lim_{n\to \infty} \int_{A} f_n(x)d\mu \neq \lim_{n\to \infty} \int_{A} \tilde{f}_n(x)d\mu;
\end{displaymath}
allora la successione $\{g_n\}_n=\{f_n\}_n \cup \{\tilde{f}_n\}_n$ non ammette
limite, il che è assurdo perché contraddice $i)$.
\item[$iii)$] Se $f$ è semplice, la definizione data coincide con quella precedente;
infatti basta considerare $\{f_n\}_n=f$ per ogni $n \in \mathbb{N}$.
\end{itemize}
Le prime due proprietà ci assicurano che il limite \ref{intdilebesguefunzqualsiasi} non dipende in alcun modo dalla
particolare scelta di $\{f_n\}_n$ e che quindi affinchè $f$ sia $L$-integrabile su $A$ 
è sufficiente trovarne una sola che soddisfi le richieste della definizione;
la terza invece ci mostra come questa nuova definizione sia effettivamente un'estensione di
quella vecchia. Dunque la definizione di $L$-integrabilità di funzioni qualsiasi su insiemi
di misura finita è ben posta.\newline
Consideriamo ora insiemi $X$ di misura infinita e diamo la seguente
\begin{defin}
Sia $X$ un insieme di misura infinita; si dice \emph{successione esaustiva} per $X$ una
successione $\{X_n\}_n$ di sottoinsiemi di $X$ tale che: \index{Successione esaustiva}
\begin{itemize}
\item[$i)$] $\mu(X_n)<+\infty$, $\forall n \in \mathbb{N}$;
\item[$ii)$] $X = \bigcup_n X_n$.
\end{itemize}
In tal caso diremo che una misura $\mu$ definita su $X$ è \emph{$\sigma$-finita}. \index{$\sigma$-finitezza}
\end{defin}
Per semplicità considereremo solo spazi $X$ che ammettono una rappresentazione mediante
successione esaustiva, come appena indicato nella definizione.
\begin{defin}
Sia $f$ una funzione qualsiasi definita su un insieme $X$ di misura infinita; $f$ si dice
\emph{$L$-integrabile} su $X$ se lo è su ogni $A \subset X$ tale che $\mu(A)<+\infty$, e
se per ogni successione esaustiva $\{X_n\}_n$ esiste finito il limite \index{$L$-integrabilità!su 
insiemi di misura infinita}
\begin{equation}
I = \lim_{n\to \infty} \int_{X_n} f(x)d\mu, %(3)
\end{equation}
ed esso non dipende dalla particolare scelta di $\{X_n\}_n$. In tal caso si pone
\begin{displaymath}
\int_X f(x)d\mu = I.
\end{displaymath}
\end{defin}
Il motivo di questa differenza tra le due definizioni di \emph{$L$-integrabilità} su un
insieme sta nel fatto che, se $\mu(X)=+\infty$, in generale dalla convergenza uniforme di
$\{f_n\}_n$ a $f$ non deriva la convergenza uniforme della successione degli integrali
$\int_X f_n(x)d\mu$ (si veda l'appendice per un controesempio).
\end{section}
\begin{section}{Proprietà dell'integrale}
Illustreremo in questa sezione le principali proprietà dell'integrale di Lebesgue,
cominciando da quelle più ovvie; anche in questo caso partiremo per comodità con il
mostrarle per funzioni semplici, estendendo poi la dimostrazione al caso di funzioni
definite su insiemi di misura finita e infinita.
\begin{enumerate}
\item \textbf{Se $f$, $g$ sono $L$-integrabili su $A$, allora lo è anche $f+g$, e vale:}
\begin{displaymath}
\int_A (f(x)+g(x))d\mu = \int_A f(x)d\mu + \int_A g(x)d\mu.
\end{displaymath}
\begin{itemize}
\item[$a.$] Siano dapprima $f$ e $g$ semplici, $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}_{A_i}(x)$,
$g(x)=\sum_j \beta_j  \textrm{\Large$\chi$}_{B_j}(x)$, da cui segue subito:
\begin{displaymath}
f(x)+g(x)=\sum_{i,j} (\alpha_i+\beta_j)  \textrm{\Large$\chi$}_{A_i \cap B_j}(x);
\end{displaymath}
allora si ottiene
\begin{align*}
\int_A (f(x)+g(x))d\mu &= \sum_{i,j} (\alpha_i+\beta_j)\mu(A_i \cap B_j)\\
&= \sum_{i,j} \alpha_i\mu(A_i \cap B_j) + \sum_{i,j} \beta_j\mu(A_i \cap B_j)\\
&= \sum_i \alpha_i\mu(A_i) + \sum_j \beta_j\mu(B_j)\\
&= \int_A f(x)d\mu + \int_A g(x)d\mu.
\end{align*}
In forza di queste uguaglianze, dalla convergenza assoluta delle serie
$\sum_i (\alpha_i)\mu(A_i)$ e $\sum_j (\beta_j)\mu(B_j)$ si ricava la
convergenza assoluta di $\sum_{i,j} (\alpha_i+\beta_j)\mu(A_i \cap B_j)$, e quindi
$f+g$ è $L$-integrabile su $A$.\newline
\item[$b.$]Siano ora $f$, $g$ generiche e siano $\{f_n\}_n$, $\{g_n\}_n$ due successioni di
funzioni semplici $L$-integrabili su $A$ che convergono uniformemente rispettivamente a $f$ e
$g$. Allora la successione $\{f_n+g_n\}_n$ converge uniformemente a $f+g$ su $A$, e
pertanto
\begin{align*}
\int_A (f(x)+g(x))d\mu &= \lim_{n\to \infty} \int_A (f_n(x)+g_n(x))d\mu\\
&= \lim_{n\to \infty} \int_A f_n(x)d\mu + \lim_{n\to \infty} \int_A g_n(x)d\mu\\
&= \int_A f(x)d\mu + \int_A g(x)d\mu < +\infty.
\end{align*}
\item[$c.$] Se infine siamo su un insieme $X$ tale che $\mu(X)=+\infty$, sfruttando la definizione e i
risultati precedenti si ha
\begin{align*}
\int_X (f(x)+g(x))d\mu &= \lim_{k\to\infty} \int_{X_k} (f(x)+g(x))d\mu\\
&= \lim_{k\to\infty} \lim_{n\to \infty} \int_{X_k} (f_n(x)+g_n(x))d\mu\\
&= \lim_{k\to\infty} \lim_{n\to \infty} \Big(\int_{X_k} f_n(x)d\mu + \int_{X_k} g_n(x)d\mu\Big)\\
&= \lim_{k\to\infty} \Big(\int_{X_k} f(x)d\mu + \int_{X_k} g(x)d\mu\Big)\\
&= \int_X f(x)d\mu + \int_X g(x)d\mu < +\infty.
\end{align*}
\end{itemize}
\item \textbf{Se $f$ è $L$-integrabile su $A$ e $k \in \mathbb{R}$, allora lo è anche $kf$ e vale:}
\begin{displaymath}
\int_A kf(x)d\mu = k\int_A f(x)d\mu.
\end{displaymath}
La dimostrazione di questo asserto è del tutto analoga alla precedente e viene
pertanto lasciata come esercizio per il lettore.
\item \textbf{Se $f$ è misurabile e limitata su $A$, ovvero $|  f(x)|  \leq M$, allora $f$
è $L$-integrabile su $A$.}
\begin{itemize}
\item[$a.$] Sia dapprima $f$ semplice, $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}_{A_i}(x)$; dalla limitatezza di
$f$ si deduce che $|\alpha_i|  \leq M$, $\forall i$, e quindi
\begin{displaymath}
\sum_i |\alpha_i|\mu(A_i) \leq M\sum_i \mu(A_i) = M\mu(A) < +\infty.
\end{displaymath}
\item[$b.$] Sia ora $f$ generica; per il teorema \ref{succfunzsempmis} possiamo trovare una successione $\{f_n\}_n$ di
funzioni semplici misurabili che converge uniformemente a $f$. Da questo segue che
definitivamente $|  f_n(x)|  \leq M$, il che implica l'integrabilità delle $f_n$, da cui
segue per definizione l'integrabilità di $f$.
\item[$c.$] Se invece siamo su un insieme $X$, con $\mu(X)=+\infty$, questa proprietà perde di
validità. Infatti se ad esempio $f(x)=c$ è una funzione costante, risulta
\begin{displaymath}
\int_X f(x)d\mu = c\mu(X) = +\infty.
\end{displaymath}
\end{itemize}
\item \textbf{Se $f$ è non negativa integrabile su un insieme $A$, allora}
\begin{displaymath}
\int_A f(x)d\mu \geq 0.
\end{displaymath}
\begin{itemize}
\item[$a.$] Se $f$ è semplice è del tipo $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}_{A_i}(x)$, con $\alpha_i>0$.
Dunque
\begin{displaymath}
\int_A f(x)d\mu = \sum_i \alpha_i\mu(A_i) \geq 0.
\end{displaymath}
\item[$b.$] Se $f$ è qualsiasi, esiste una successione $\{f_n\}_n$ di funzioni semplici e integrabili
su $A$ che converge uniformemente a $f$; poiché $f\geq0$ si avrà definitivamente
$f_n\geq0$. Ma le $f_n$ sono semplici e quindi per quanto appena visto vale
$\int_A f_n(x)d\mu\geq0$, da cui si conclude
\begin{displaymath}
\int_A f(x)d\mu = \lim_{n\to \infty} \int_A f_n(x)d\mu \geq 0.
\end{displaymath}
\item[$c.$] Se infine $X$ è un insieme di misura infinita basta scrivere
\begin{displaymath}
\int_X f(x)d\mu = \lim_{k\to\infty} \int_{X_k} f(x)d\mu \geq 0.
\end{displaymath}
\end{itemize}
\begin{oss}
Da quanto appena mostrato segue che, se $f$ e $g$ sono due funzioni integrabili su un
insieme $A$ tali che $f(x)\leq g(x)$, allora
\begin{displaymath}
\int_A f(x)d\mu \leq \int_A g(x)d\mu.
\end{displaymath}
Infatti basta notare che $g(x)-f(x)\geq 0$ e applicare la proprietà $4$.
\end{oss}
\item \textbf{Sia $f$ integrabile su un insieme $A$ tale che $\mu(A)=0$; allora}
\begin{displaymath}
\int_A f(x)d\mu = 0.
\end{displaymath}
\begin{itemize}
\item[$a.$] Se $f$ è semplice, $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}_{A_i}(x)$, si ha
$\int_A f(x)d\mu=\sum_i \alpha_i\mu(A_i)$. Siccome $\mu(A)=\sum_i \mu(A_i)=0$, si deve
avere $\mu(A_i)=0$ per ogni $i$ e dunque $\int_A f(x)d\mu=0$.\newline
\item[$b.$] Se $f$ è qualsiasi, esiste una successione $\{f_n\}_n$ di funzioni semplici e integrabili
su $A$ che converge uniformemente ad $f$. Siccome per ogni $n$ $\int_A f_n(x)d\mu=0$ per
quanto appena mostrato, si conclude che
\begin{displaymath}
\int_A f(x)d\mu = \lim_{n\to \infty} \int_A f_n(x)d\mu = 0.
\end{displaymath}
\end{itemize} 
\begin{oss}
Da quanto appena mostrato segue che, se $f$ e $g$ sono due funzioni integrabili su $A$ tali
che $f(x)=g(x)$ quasi ovunque, allora
\begin{displaymath}
\int_A f(x)d\mu = \int_A g(x)d\mu.
\end{displaymath}
Abbiamo $f(x)-g(x)=0$ quasi ovunque; sia $A'$ l'insieme su cui $f(x)=g(x)$. Si deduce
subito che $\mu(A\smallsetminus A')=0$, da cui
\begin{displaymath}
\int_A (f(x)-g(x))d\mu = \int_{A'} (f(x)-g(x))d\mu + \int_{A\smallsetminus A'} (f(x)-g(x))d\mu;
\end{displaymath}
il primo integrale è nullo in quanto $f(x)-g(x)=0$, il secondo è pure nullo grazie alla
proprietà 5 appena illustrata.
\end{oss}
\begin{oss}
In generale se una certa proprietà vale quasi ovunque, passando all'integrale essa vale
ovunque. La dimostrazione di ciò si ottiene come nella precedente osservazione,
grazie alla proprietà 5.
\end{oss}
\item \textbf{Se $f$ è integrabile su $A$, allora}
\begin{displaymath}
\Big|\int_A f(x)d\mu\Big|  \leq \int_A |  f(x)|  d\mu.
\end{displaymath}
\begin{itemize}
\item[$a.$] Se $f$ è semplice, $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}{A_i}(x)$, si ha subito
\begin{displaymath}
\Big|\int_A f(x)d\mu\Big|  = \Big|\sum_i \alpha_i\mu(A_i)\Big|  \leq \sum_i |\alpha_i|\mu(A_i) = 
\int_A |f(x)|  d\mu,
\end{displaymath}
dato che $|  f(x)| =\sum_i |\alpha_i|   \textrm{\Large$\chi$}_{A_i}(x)$.\newline
\item[$b.$] Se $f$ è qualsiasi e $\mu(A)<+\infty$, esiste una successione $\{f_n\}_n$ di funzioni
semplici e integrabili su $A$ che converge uniformemente a $f$; allora
\begin{displaymath}
\Big|\int_A f(x)d\mu\Big|  = \Big|\lim_{n\to \infty} \int_A f_n(x)d\mu\Big|  \leq \lim_{n\to \infty} \int_A |  f_n(x)|  d\mu = \int_A |  f(x)|  d\mu.
\end{displaymath}
\item[$c.$] Infine se siamo su un insieme $X$ di misura infinita si ha
\begin{displaymath}
\Big|\int_X f(x)d\mu\Big|  = \Big|\lim_{k\to\infty} \int_{X_k} f(x)d\mu\Big|  \leq \lim_{k\to\infty} \int_{X_k} |  f(x)|  d\mu = \int_x\ |\   f(x)|  d\mu.
\end{displaymath}
\end{itemize}
\item \textbf{Siano $f$ e $\phi$ definite su un insieme $A$ tali che $\phi$ sia ivi
integrabile e $|  f(x)|\leq\phi(x)$ per quasi ogni $x\in A$. Allora $f$ è integrabile su
$A$.}
\begin{itemize}
\item[$a.$] Se $f$ e $\phi$ sono semplici possiamo scriverle come $f(x)=\sum_i \alpha_i  \textrm{\Large$\chi$}_{A_i}(x)$,
$\phi(x)=\sum_i \beta_i  \textrm{\Large$\chi$}_{A_i}(x)$, con $|\alpha_i|\leq\beta_i$ per ogni $i$, ove
$\{A_i\}_i$ è una generica partizione di $A$. Allora
\begin{displaymath}
\Big|\int_A f(x)d\mu\Big|  \leq \int_A |  f(x)|  d\mu = \sum_i |\alpha_i|\mu(A_i) \leq \sum_i |\beta_i|\mu(A_i) < +\infty,
\end{displaymath}
ovvero $f$ è integrabile su $A$.\newline
\item[$b.$] Se $f$ e $\phi$ sono qualsiasi e $\mu(A)<+\infty$, esiste una successione $\{f_n\}_n$ di
funzioni semplici e misurabili che converge uniformemente ad $f$, ed esiste una successione
$\{\phi_n\}_n$ di funzioni semplici e integrabili su $A$ che converge uniformemente a
$\phi$. poiché $|  f(x)|\leq\phi(x)$ quasi ovunque, si deve avere definitivamente
$|  f_n(x)|\leq\phi_n(x)$ quasi ovunque, da cui deduciamo dal caso precedente che le $f_n$
sono integrabili su $A$, e quindi per definizione lo è anche $f$.\newline
\item[$c.$] Nel caso generale di un insieme $X$ di misura infinita vale
\begin{multline*}
\Big|\int_X f(x)d\mu\Big|  \leq \int_x\ |\   f(x)|  d\mu = \lim_{k\to\infty} \int_{X_k} |  f(x)|  d\mu\leq\\
\leq \lim_{k\to\infty} \int_{X_k} \phi(x)d\mu = \int_X \phi(x)d\mu < +\infty,
\end{multline*}
e quindi $f$ è integrabile su $X$.
\end{itemize}
\item \textbf{$f$ misurabile su $A$ è integrabile su $A$ se e solo se lo è $|  f| $.}\\
$(\Leftarrow)$ segue subito dalla proprietà 6, a prescindere dal tipo di
funzione in questione e dalla misura dell'insieme su cui integriamo. \\
$(\Rightarrow)$ Viceversa, sia al solito $f$ semplice, $f(x)=\sum_i \alpha_i 
\textrm{\Large$\chi$}_{A_i}$; poiché $f$ è integrabile per
ipotesi, abbiamo
\begin{displaymath}
\int_x\ |f(x)|  d\mu = \sum_i |\alpha_i|\mu(A_i) < +\infty,
\end{displaymath}
cioé $|  f| $ è integrabile su $A$.\newline
Se $f$ è qualsiasi e $\mu(A)<+\infty$, esiste una successione $\{f_n\}_n$ di funzioni
semplici e integrabili su $A$ che converge uniformemente ad $f$. Ma allora $|  f_n| $ converge
uniformemente ad $|  f| $, la quale è quindi integrabile su $A$.\newline
Se infine siamo su un insieme $X$ di misura infinita \color{red}*MANCA DEL TESTO*\color{black}
\end{enumerate}
Esistono poi una serie di proprietà non banali dell'integrale che ci accingiamo ad
enunciare e dimostrare; in particolare l'integrale di Lebesgue è $\sigma$-additivo e
assolutamente continuo rispetto alla misura di Lebesgue. Porremo poi l'accento su alcuni
teoremi di vitale importanza di passaggio al limite sotto il segno di integrale, molto
utili in innumerevoli situazioni pratiche. Ordunque mettiamoci al lavoro.
\begin{teo}\textbf{(di $\sigma$-additività dell'integrale)}
Sia $f$ una funzione integrabile su un insieme $A$ e sia $\{A_n\}_n$ una partizione di tale
insieme. Allora $f$ è integrabile su ciascun $A_n$ e vale
\begin{displaymath}
\int_A f(x)d\mu = \sum_n \int_{A_n} f(x)d\mu,
\end{displaymath}
ove la serie a secondo membro è assolutamente convergente.\\
\newline
\dimo
Sia dapprima $f$ semplice, cioé $f(x)=\sum_k \beta_k  \textrm{\Large$\chi$}_{B_k}(x)$, ove $\{B_k\}_k$ è
la partizione canonica di $A$, e definiamo
\begin{displaymath}
B_{n,k} = \{x \in A_n |  f(x)=\beta_k\} = A_n \cap B_k.
\end{displaymath}
Allora valgono le uguaglianze $A_n=\bigcupdot_k B_{n,k}$, $B_k=\bigcupdot_n B_{n,k}$, e
quindi
\begin{align*}
\int_A f(x)d\mu &= \sum_k \beta_k\mu(B_k) = \sum_k \beta_k \sum_n \mu(B_{n,k})=
 \sum_{n,k} \beta_k\mu(B_{n,k}) = \sum_n \int_{A_n} f(x)d\mu.
\end{align*}
Quindi segue subito che $f$ è integrabile su ogni $A_n$, e la serie
$\sum_n \int_{A_n} f(x)d\mu$ converge assolutamente.\newline
Se $f$ è qualsiasi, il fatto che $f$ è integrabile su $A$ implica che essa è
approssimabile con funzioni semplici ed integrabili su $A$; esisterà quindi $\tilde{f}$
semplice e integrabile su $A$ tale che
\begin{displaymath}
|  f(x)-\tilde{f}(x)|  < \varepsilon.
\end{displaymath}
Siccome $\tilde{f}$ è semplice, per quanto dimostrato poc'anzi essa dev'essere
integrabile su ogni $A_n$ e deve valere
\begin{displaymath}
\int_A \tilde{f}(x)d\mu = \sum_n \int_{A_n} \tilde{f}(x)d\mu.
\end{displaymath}
Inoltre dal fatto che $\Big||f(x)| -|\tilde{f}(x)|\Big|\leq|f(x)-\tilde{f}(x)| <\varepsilon$ (la cui
facile verifica è lasciata per esercizio) segue che $|  f(x)| <|\tilde{f}(x)| +\varepsilon$,
e siccome $|\tilde{f}(x)| +\varepsilon$ è integrabile su $A_n$ lo è anche $|  f| $, e
quindi anche $f$. Inoltre
\begin{displaymath}
\Big|\sum_n \int_{A_n} f(x)d\mu\Big|  \leq \sum_n \int_{A_n} |  f(x)|  d\mu \leq \sum_n \int_{A_n} |\tilde{f}(x)|  d\mu + \varepsilon\mu(A) < +\infty,
\end{displaymath}
ed ecco che $\sum_n \int_{A_n} f(x)d\mu$ converge assolutamente. Infine consideriamo le
seguenti formule:
\begin{equation*}
\Big|\sum_n \int_{A_n} (f(x)-\tilde{f}(x))d\mu\Big|  \leq \sum_n \int_{A_n} |  f(x)-\tilde{f}(x)|  d\mu 
< \varepsilon\sum_n \mu(A_n) = \varepsilon\mu(A),
\end{equation*}
\begin{equation*}
\Big|\int_A (f(x)-\tilde{f}(x))d\mu\Big|  \leq \int_A |  f(x)-\tilde{f}(x)|  d\mu < \varepsilon\mu(A);
\end{equation*}
combinandole opportunamente si ottiene
\begin{multline*}
\Big|\int_A f(x)d\mu - \sum_n \int_{A_n} f(x)d\mu\Big|  = \\
 =\Big|\int_A f(x)d\mu - \int_A \tilde{f}(x)d\mu + \sum_n \int_{A_n} \tilde{f}(x)d\mu - 
\sum_n \int_{A_n} f(x)d\mu\Big|\leq\\
\leq \Big|\int_A (f(x)-\tilde{f}(x))d\mu\Big|  + \Big|\sum_n \int_{A_n} (f(x)-\tilde{f}(x))d\mu\Big| 
< 2\varepsilon\mu(A),
\end{multline*}
da cui la tesi nel caso in cui $\mu(A)<+\infty$. Se invece consideriamo un insieme $X$ tale
che $\mu(X)=+\infty$, si ha
\begin{multline*}
\int_X f(x)d\mu = \lim_{k\to\infty} \int_{X_k} f(x)d\mu = \lim_{k\to\infty} \sum_n \int_{X_{n,k}} f(x)d\mu=\\
= \sum_n \lim_{k\to\infty} \int_{X_{n,k}} f(x)d\mu = \sum_n \int_{X_n} f(x)d\mu,
\end{multline*}
il che conclude la dimostrazione.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{cor}
Se $f$ è una funzione integrabile su un insieme $A$, lo è anche su ogni sottoinsieme
$A' \subseteq A$ misurabile.\\
\newline
\dimo
Basta notare che $A=A'\cupdot(A \smallsetminus A')$ e poi applicare il teorema precedente.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
Notiamo che vale una specie di viceversa a questo teorema, ove però tra le ipotesi è
contemplata la convergenza della serie $\sum_n \int_{A_n} |  f(x)|  d\mu$ anzichè la
convergenza assoluta di $\sum_n \int_{A_n} f(x)d\mu$.
\begin{teo}
Sia $f$ una funzione definita su $A$ misurabile e sia $\{A_n\}_n$ una partizione di tale
insieme. Sia $f$ integrabile su ciascun $A_n$ e sia $\sum_n \int_{A_n} f(x)d\mu$
convergente. Allora $f$ è integrabile su tutto $A$ e vale la formula precedente:
\begin{displaymath}
\int_A f(x)d\mu = \sum_n \int_{A_n} f(x)d\mu.
\end{displaymath}
\dimo
Sia $f(x)=\sum_k \beta_k  \textrm{\Large$\chi$}_{B_k}(x)$ semplice; poniamo $B_{n,k}=B_k \cap A_n$ come prima,
così che anche stavolta si abbia $A_n=\bigcupdot_k B_{n,k}$, $B_k=\bigcupdot_n B_{n,k}$,
da cui
\begin{align*}
\sum_n \int_{A_n} f(x)d\mu &= \sum_{n,k} \beta_k\mu(B_{n,k}) = \sum_k \beta_k \sum_n \mu(B_{n,k})
&= \sum_k \beta_k\mu(B_k) = \int_A f(x)d\mu
\end{align*}
e quindi $f$ è integrabile su $A$.\newline
Se ora $f$ è generica, esiste $\tilde{f}$ semplice e integrabile su ogni $A_n$ tale che valga
$|  f(x)-\tilde{f}(x)| <\varepsilon$. Allora vale
\begin{displaymath}
\sum_n \int_{A_n} |\tilde{f}(x)|  d\mu \leq \sum_n \int_A |  f(x)|  d\mu + \varepsilon\mu(A) < +\infty,
\end{displaymath}
e quindi dal caso precedente si deduce che $\tilde{f}$ è integrabile su $A$. Segue quindi
che anche $f$ è integrabile su $A$, grazie alla relazione
$|  f(x)|\leq|\tilde{f}(x)| +\varepsilon$. La dimostrazione della formula
\begin{displaymath}
\int_A f(x)d\mu = \sum_n \int_{A_n} f(x)d\mu
\end{displaymath}
è identica a quella effettuata nel teorema precedente, sia nel caso di un insieme di
misura finita, sia nel caso di un insieme di misura infinita, e non la ripetiamo qui.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
A questo punto vale la pena illustrare una condizione di \emph{non} integrabilità che,
sebbene possa sembrare un'idea un po' esotica a prima vista, si rivelerà
estremamente preziosa nello svolgimento di alcuni esercizi.
\begin{teo}
Sia $f$ una funzione misurabile su un insieme $A$ e supponiamo che esista una successione
$\{f_n\}_n$ di funzioni misurabili e non integrabili su $A$ che converge uniformemente ad
$f$. Allora anche $f$ non è integrabile su $A$.\\
\newline
\dimo
Cominciamo dal caso in cui le $f_n$ siano semplici, cioé sia
$f_n(x)=\sum_i \alpha_{i,n}  \textrm{\Large$\chi$}_{A_{i,n}}(x)$; allora avremo definitivamente
$|  f_n(x)-f(x)| <\varepsilon$ in virtù della convergenza uniforme di $f_n$ a $f$. Inoltre
$|  f_n(x)|\leq|  f(x)| +\varepsilon$, e quindi
\begin{displaymath}
+\infty = \int_A |  f_n(x)|  d\mu \leq \int_A |  f(x)|  d\mu + \varepsilon\mu(A),
\end{displaymath}
il che ci dice che $\int_A |  f(x)|  d\mu=+\infty$, ovvero $f$ non è integrabile su
$A$.\newline
Se le $f_n$ sono generiche, per ogni $n$ esiste una successione $\{f_{n,k}\}_k$ di funzioni
semplici, misurabili e non integrabili che converge uniformemente a $f_n$, da cui
\begin{displaymath}
f(x) = \lim_{n\to \infty} f_n(x) = \lim_{n,k} f_{n,k}(x),
\end{displaymath}
e quindi la tesi segue dal punto precedente.\newline
Infine consideriamo il solito insieme $X$ di misura infinita; notiamo che la restrizione
$f_n| _{X_k}$ delle $f_n$ a ciascun insieme $X_k$ della successione esaustiva converge
uniformemente alla restrizione $f| _{X_k}$, ovvero per quanto appena visto vale
$\int_{X_k} |  f(x)|  d\mu=+\infty$, così possiamo concludere che
\begin{displaymath}
\int_X f(x)d\mu = \lim_{k\to\infty} \int_{X_k} f(x)d\mu = +\infty.
\end{displaymath}
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Dopo questo breve ma fruttuoso excursus torniamo a concentrare le nostre energie sulle
proprietà dell'integrale e prima di mostrarne l'assoluta continuità rispetto a $\mu$
illustriamo un risultato propedeutico dovuto al matematico russo Pafnutij L'vovi\v{c}
\v{C}h\"{e}by\v{s}hev.
\begin{teo}\textbf{(Disuguaglianza di \u{C}h\"{e}by\u{s}hev)} \index{Disuguaglianza di \u{C}h\"{e}by\u{s}hev}
Sia $f$ una funzione non negativa integrabile su $A$. Allora per ogni $c \in \mathbb{R}$
positiva vale la disuguaglianza
\begin{displaymath}
\mu\{x\ |\   f(x) \geq c\} \leq \frac{1}{c}\int_A f(x)d\mu.
\end{displaymath}
\dimo
Poniamo $A'=\{x\ |\   f(x)\geq c\}$; allora per la $\sigma$-additività dell'integrale abbiamo
\begin{displaymath}
\int_A f(x)d\mu = \int_{A'} f(x)d\mu + \int_{A \smallsetminus A'} f(x)d\mu \geq \int_{A'} f(x)d\mu \geq c\mu(A'),
\end{displaymath}
da cui $\mu(A')\leq\frac{1}{c}\int_A f(x)d\mu$.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{cor}
Sia $f$ integrabile su $A$ tale che $\int_A |  f(x)|  d\mu=0$; allora $f(x)=0$ quasi ovunque.\\
\newline
\dimo
Dobbiamo provare che $\mu\{x\ |\   f(x)\neq 0\}=0$; notiamo che vale l'uguaglianza
\begin{displaymath}
\{x\ |\   f(x) \neq 0\} = \bigcup_n \Big\{x\ |\   f(x) > \frac{1}{n}\Big\},
\end{displaymath}
che per la sua facilità nell'essere verificata è lasciata per esercizio al volenteroso
lettore. Dunque grazie alla disuguaglianza di \u{C}h\"{e}by\u{s}hev risulta
\begin{displaymath}
\mu\{x\ |\   f(x) \neq 0\} \leq \sum_n \mu\Big\{x\ |\   |  f(x)|  \geq \frac{1}{n}\Big\} \leq n\int_A |  f(x)|  d\mu,
\end{displaymath}
da cui la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{teo}\textbf{(di assoluta continuità dell'integrale)}
Sia $f$ integrabile su un insieme misurabile $A$. Allora per ogni $\varepsilon>0$ esiste
$\delta>0$ tale che per ogni insieme $A_{\delta} \subset A$ tale che
$\mu(A_{\delta})<\delta$ si ha
\begin{displaymath}
\Big|\int_{A_{\delta}} f(x)d\mu\Big|  < \varepsilon.
\end{displaymath}
\dimo
Poniamo
\begin{displaymath}
A_n = \{x\ |\   n \leq |  f(x)|  < n+1\};
\end{displaymath}
evidentemente risulta $A_i \cap A_j = \emptyset$ ogni volta che $i\neq j$, e
$A=\bigcupdot_n A_n$. Definiamo inoltre degli insiemi opportuni:
\begin{displaymath}
B_N = \bigcupdot_{n=0}^N A_n, \quad C_N = A \smallsetminus B_N.
\end{displaymath}
Grazie alla $\sigma$-additività dell'integrale si ha
\begin{displaymath}
\int_A |  f(x)|  d\mu = \sum_n \int_{A_n} |  f(x)|  d\mu < +\infty,
\end{displaymath}
e quindi possiamo trovare un $N$ sufficientemente grande per cui
\begin{displaymath}
\sum_{n=N+1}^{\infty} \int_{A_n} |  f(x)|  d\mu = \int_{C_N} |  f(x)|  d\mu < \frac{\varepsilon}{2}.
\end{displaymath}
Scegliamo ora $\delta$ tale che $0<\delta<\varepsilon/(2(N+1))$, prendiamo
$A_{\delta} \subset A$ tale che $\mu(A_{\delta})<\delta$ e notiamo che
$$A_{\delta} = A_{\delta} \cap A = A_{\delta} \cap (B_N \cupdot C_N)
= (A_{\delta} \cap B_N) \cupdot (A_{\delta} \cap C_N),$$
in modo tale che
\begin{multline*}
\Big|\int_{A_{\delta}} f(x)d\mu\Big|  \leq \int_{A_{\delta}} |  f(x)|  d\mu= \int_{A_{\delta} \cap B_N} 
|  f(x)|  d\mu + \int_{A_{\delta} \cap C_N} |  f(x)|  d\mu \leq\\
\leq (N+1)\mu(A_{\delta}) + \int_{C_N} |  f(x)|  d\mu < \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon,
\end{multline*}
dove per maggiorare il primo dei due integrali abbiamo usato la diseguaglianza di \v{C}h\"{e}by\v{s}hev.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{oss}
Si noti che nella dimostrazione di quest'ultimo risultato non abbiamo utilizzato il fatto
che la misura di $A$ fosse finita, e quindi esso vale automaticamente su insiemi di misura
qualsiasi.
\end{oss}
Sia $f(x)$ una funzione non negativa integrabile su un insieme $X$. Per ogni $A \subseteq
X$ definiamo la funzione $F:\mathfrak{M}_X \mapsto \mathbb{R}$ come
\begin{displaymath}
F(A) = \int_A f(x)d\mu,
\end{displaymath}
ove $\mu$ è la misura di Lebesgue su $\mathfrak{M}_X$, cioé sostanzialmente vediamo
l'integrale di Lebesgue come una funzione reale di insiemi L-misurabili. Le proprietà ed
i teoremi provati in questo capitolo mostrano che $F$ è ben definita e non negativa;
inoltre è $\sigma$-additiva, cioé vale
\begin{displaymath}
F(\bigcupdot_n A_n) = \sum_n \int_{A_n} f(x)d\mu = \sum_n F(A_n).
\end{displaymath}
In altre parole $F$ gode di tutte le proprietà delle quali una funzione necessita per
essere ritenuta un'onesta misura $\sigma$-additiva definita su $(X,\mathfrak{M}_X,\mu)$, e
quindi l'integrale di Lebesgue può essere visto come una misura a tutti gli effetti, che
conserva tra l'altro la proprietà di essere assolutamente continua rispetto a $\mu$,
ovvero
\begin{displaymath}
\forall \varepsilon > 0, \quad \exists \delta > 0 : \forall A \subseteq X, \quad \mu(A) < 
\delta \rightarrow |  f(A)|  < \varepsilon.
\end{displaymath}
\end{section}
\begin{section}{Teoremi di passaggio al limite sotto segno di integrale}
\begin{teo}{\textbf{(di Lebesgue o di convergenza dominata)}} \index{Teorema!di Lebesgue}
\index{Teorema!della convergenza dominata}
Consideriamo una successione $\{f_n\}_{n\in\mathbb{N}}$ di funzioni misurabili su un insieme $A$ che
converga quasi ovunque ad una funzione $f$ e tale che $|  f_n(x)|\leq\phi(x)$ per ogni $n$,
ove $\phi$ è una funzione integrabile su $A$. Allora anche $f$ è integrabile su $A$ e
vale
\begin{displaymath}
\lim_{n\to +\infty} \int_A f_n(x)d\mu = \int_A f(x)d\mu.
\end{displaymath}
\dimo Ovviamente dev'essere $|  f(x)|\leq\phi(x)$, da cui otteniamo subito l'integrabilità della
$f$ grazie alla proprietà $7$. Ora serviamoci dell'assoluta continuità dell'integrale e
del teorema di Egorov: in virtù della prima, preso $\varepsilon>0$, esiste $\delta>0$
tale che
\begin{equation}\label{perassolutacontinuità}
\int_B \phi(x)d\mu < \frac{\varepsilon}{4}
\end{equation}
per ogni $B \subset A$ tale che $\mu(B)<\delta$; grazie al secondo possiamo scegliere $B$
in modo tale che $\{f_n\}_n$ converga uniformemente su $A \smallsetminus B$. Questo equivale a
poter trovare un $N$ sufficientemente grande tale che, per ogni $n \geq N$, valga
\begin{equation}\label{perteodiegorov}
|  f_n(x)-f(x)|  < \frac{\varepsilon}{2\mu(A \smallsetminus B)}.
\end{equation}
Ma allora combinando insieme \ref{perassolutacontinuità} e \ref{perteodiegorov} otteniamo
\begin{multline*}
\Big|\lim_{n\to +\infty} \int_A f_n(x)d\mu -\int_A f(x)d\mu \Big|\leq \int_A |f_n(x)-f(x)|d\mu=\\
=\int_{A\smallsetminus B}|f_n(x)-f(x)|d\mu + \int_B |f_n(x)-f(x)|d\mu <\\
< \frac{\varepsilon}{2\mu(A\smallsetminus B)}\mu(A\smallsetminus B)+2\int_B \phi(x)d\mu<
\frac{\varepsilon}{2}+\frac{\varepsilon}{2}=\varepsilon
\end{multline*}
che è la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{cor}
Sia $\{f_n\}_{n\in\mathbb{N}}$ una successione di funzioni limitate e integrabili su $X$ insieme di misura finita, convergente ad una funzione $f(x)$ quasi ovunque.
Allora $f$ è integrabile su $X$ e vale la formula
\begin{displaymath}
\int_X f(x)d\mu=\lim_{n\to+\infty}\int_X f_n d\mu.
\end{displaymath}
\dimo Siccome le $f_n$ sono limitate, esiste $M>0$ tale che $|  f_n(x)|\leq M$. Allora basta porre $\phi(x)=M$ ed 
applicare il teorema di Lebesgue per giungere alla tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{teo}{\textbf{(di Beppo Levi o di convergenza monotona)}} \index{Teorema!di Beppo Levi}
\index{Teorema!della convergenza monotona}
Consideriamo una successione $\{f_n\}_{n\in\mathbb{N}}$ di funzioni integrabili su un insieme $A$ tali che
\begin{equation}\label{decrescenza}
f_1(x) \leq f_2(x) \leq \ldots \leq f_n(x) \leq \ldots,
\end{equation}
\begin{displaymath}
\int_A f_n(x)d\mu \leq K \quad \forall n \in \mathbb{N}.
\end{displaymath}
Allora quasi ovunque esiste la quantità $\lim_{n\to \infty} f_n(x)=f(x)$; inoltre tale $f$ è integrabile su $A$
e vale la relazione
\begin{displaymath}
\lim_{n\to \infty} \int_A f_n(x)d\mu = \int_A f(x)d\mu.
\end{displaymath}
\dimo Anzitutto notiamo che, senza perdere in generalità, possiamo assumere che $f_1(x) \geq 0$;
infatti se così non fosse basterebbe considerare $\tilde{f}_n=f_n-f_1$ e si otterrebbe lo
stesso risultato. Definiamo poi
\begin{displaymath}
\Omega = \{x \in A|  \lim_{n\to \infty} f_n(x) = +\infty\};
\end{displaymath}
l'idea è di mostrare che questo insieme ha misura zero e che quindi il limite della
nostra successione esiste quasi ovunque, come richiesto nel teorema. A tal proposito
notiamo che possiamo riscrivere $\Omega=\bigcap_r \bigcup_n \Omega_n^{(r)}$, ove
\begin{displaymath}
\Omega_n^{(r)} = \{x \in A|  f_n(x) > r\},
\end{displaymath}
e quindi, per la condizione \ref{decrescenza}, si ha per ogni $r$ che
\begin{equation}\label{inclusioni}
\Omega_1^{(r)} \subseteq \Omega_2^{(r)} \subseteq \ldots \subseteq \Omega_n^{(r)} \subseteq \ldots 
\end{equation}
Grazie alla diseguaglianza di \u{C}h\"{e}by\u{s}hev sappiamo che $\mu(\Omega_n^{(r)}) \leq K/r$, da cui,
grazie a \ref{inclusioni}, segue che $\mu(\bigcup_n \Omega_n^{(r)}) \leq K/r$; ma poiché ovviamente si ha che
$\Omega \subseteq \bigcup_n \Omega_n^{(r)}$ deve anche essere $\mu(\Omega) \leq K/r$, il che deve
valere per ogni $r$ e quindi $\mu(\Omega)=0$, proprio quello che volevamo mostrare.\newline
Ora dedichiamoci alla seconda parte del teorema; invece che mostrare direttamente
l'enunciato ci limiteremo a trovare una funzione $\phi$ integrabile su $A$
che maggiori $f$ la tesi seguirà subito dal teorema di
Lebesgue. Sia dunque
\begin{displaymath}
A_r = \{x \in A|  r-1 \leq f(x) < r\}
\end{displaymath}
e definiamo
\begin{displaymath}
\phi(x) = \sum_{r=1}^{\infty} r\textrm{\Large${\Large \textrm{\Large$\chi$}}$}_{A_r}(x).
\end{displaymath}
Poniamo inoltre $B_s=\bigcup_{r=1}^s A_r$ e notiamo immediatamente che
$\phi(x) \leq f(x)+1$; siccome $f$ ed $f_n$ sono limitate su $B_s$, possiamo applicare il teorema di Lebesgue e concludere che 
\begin{multline*}
\sum_{r=1}^s r\mu(A_r) = \int_{B_s} \phi(x)d\mu \leq \int_{B_s} f(x)d\mu + \mu(B_s)\leq\\
\leq \int_{B_s} f(x)d\mu + \mu(A) =\lim_ {n\to +\infty}\int_{B_s} f_n(x)d\mu + \mu(A)\leq K + \mu(A),
\end{multline*}
ovvero le somme $\sum_{r=1}^s r\mu(A_r)$ sono limitate per ogni $s$. Ma allora la serie
\begin{displaymath}
\sum_{r=1}^{\infty} r\mu(A_r) = \int_A \phi(x)d\mu
\end{displaymath}
converge, ovvero $\phi$ è integrabile su $A$. Per quanto osservato in precedenza, la tesi
si ottiene applicando il teorema di Lebesgue.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{oss}
Al posto della condizione \ref{decrescenza} si può equivalentemente considerare il caso in cui
\begin{displaymath}
f_1(x) \geq f_2(x) \geq \ldots \geq f_n(x) \geq \ldots,
\end{displaymath}
Infatti in questo caso è sufficiente porre $\tilde{f}_n=-f_n$ ed applicare a questa nuova
successione, che soddisfa \ref{decrescenza}, il teorema appena dimostrato.
\end{oss}
\begin{cor}
Siano $\{f_n\}_{n\in\mathbb{N}}$ funzioni non negative definite in $X$ tali che la serie 
\begin{displaymath}
\sum_{n=1}^{\infty}\int_X f_n(x)d\mu
\end{displaymath}
sia convergente. Allora la serie $\sum_{n=1}^{\infty}f_n(x)$ conerge quasi ovunque e vale la relazione
\begin{displaymath}
\sum_{n=1}^{\infty}\int_X f_n(x)d\mu=\int_X\sum_{n=1}^{\infty}f_n(x)d\mu.
\end{displaymath}
\dimo Poniamo $S_k:=\sum_{n=1}^k f_k(x)$: dall'ipotesi si deduce immediatamente che 
\begin{displaymath}
S_1(x)\leq S_2(x)\leq S_3(x)\leq\ldots\leq S_k(x)\leq\ldots,
\end{displaymath}
\begin{displaymath}
\int_X S_k(x)d\mu\leq K
\end{displaymath}
per un qualche $K\in\mathbb{R}^+$. Quindi il teorema di Beppo Levi implica che $S_k(x)$ ammette limite quasi ovunque e
\begin{multline*}
\sum_{n=1}^{\infty}\int_X f_n(x)d\mu =\lim_{k\to+\infty}\int_X\sum_{n=1}^k f_n(x)d\mu=\\
=\int_X\lim_{k\to+\infty}\sum_{n=1}^k f_n(x)d\mu=\int_X\sum_{n=1}^{\infty}f_n(x)d\mu.
\end{multline*}
Abbiamo così ottenuto la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{teo}{\textbf{(di Fatou)}}\index{Teorema!di Fatou}
Consideriamo una successione $\{f_n\}_{n\in\mathbb{N}}$ di funzioni misurabili non negative su un insieme
$A$ che converga quasi ovunque ad una funzione $f$; supponiamo inoltre che le $f_n$ soddisfino la condizione
\begin{displaymath}
\int_A f_n(x)d\mu \leq K \quad \forall n \in \mathbb{N}.
\end{displaymath}
Allora $f$ è integrabile su $A$ e
\begin{displaymath}
\int_A f(x)d\mu \leq K.
\end{displaymath}
\dimo
Per dimostrare questo teorema vogliamo metterci nella condizione di poter applicare il
teorema di Beppo Levi. Definiamo quindi una successione opportuna $\{\phi_{n}\}_{n\in\mathbb{N}}$ come
segue:
\begin{displaymath}
\phi_n(x) := \inf_{k \geq n} f_k(x);
\end{displaymath}
anzitutto le $\phi_n$ sono misurabili, in quanto possiamo scrivere
\begin{displaymath}
\{x \in A|  \phi_n(x) < c\} = \bigcup_{k \geq n} \{x \in A|  f_k(x) < c\},
\end{displaymath}
(verificalo per esercizio!). Inoltre, per costruzione, valgono le
seguenti proprietà:
\begin{displaymath}
\phi_1(x) \leq \phi_2(x) \leq \ldots \leq \phi_n(x) \leq \ldots,
\end{displaymath}
\begin{displaymath}
\lim_{n\to \infty} \phi_n(x) = f(x).
\end{displaymath}
Infine $0 \leq \phi_n(x) \leq f_n(x)$, da cui segue che le $\phi_n$ sono integrabili e
\begin{displaymath}
\int_A \phi_n(x)d\mu \leq \int_A f_n(x)d\mu \leq K.
\end{displaymath}
Ora possiamo applicare il teorema di Beppo Levi alle $\phi_n$ e ottenere la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{cor}
Siano $\{f_n\}_{n\in\mathbb{N}}$ integrabili su $X$ e non negative. Allora
\begin{displaymath}
\int_X\liminf_n f_n(x)d\mu\leq\liminf_n\int_X f_n(x)d\mu.
\end{displaymath}
\dimo Poniamo nuovamente $\phi_n := \inf_{k\geq n}f_k(x)$; siccome per ogni $k\geq n$ si ha che $\phi_n\leq f_k$, 
allora vale in particolare che 
\begin{displaymath}
\int_X\phi_n(x)d\mu\leq\inf_{k\geq n}\int_X f_k(x)d\mu. 
\end{displaymath}
Notiamo che la seguente relazione:
\begin{displaymath}
\lim_{n\to+\infty}\phi_n(x)= \sup_n\inf_{k\leq n}\phi_n(x)=\liminf_n f_n(x);
\end{displaymath}
Inoltre $\phi_1\leq\phi_2\leq\phi_3\leq\ldots$ e quindi dal teorema di Beppo Levi segue che
\begin{align*}
\int_X\liminf_n f_n(x)d\mu &= \int_X\lim_{n\to+\infty}\phi_n(x)d\mu\\
&=\lim_{n\to+\infty}\int_X\phi_n(x)d\mu \leq\lim_{n\to+\infty}\inf_{k\geq n}\int_X f_k(x)d\mu\\
&=\sup_n\inf_{k\geq n}\int_X f_k(x)d\mu = \liminf_n\int_X f_n(x)d\mu.
\end{align*}
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{oss}
Si noti che i teoremi di Beppo Levi, Lebesgue e Fatou si possono agevolmente generalizzare agli insiemi di misura infinita. A titolo d'esempio
verifichiamo quello di Beppo Levi, gli altri due vengono lasciati come esercizio all'esimio lettore. Si tratta di fatto di provare che
\begin{displaymath}
\lim_{n\to+\infty}\int_Xf_n(x)d\mu=\int_X f(x)d\mu,
\end{displaymath}
ove $f(x)=\lim_{n\to+\infty}f_n(x)$ quasi ovunque. Presa la solita successione esaustiva $\{X_k\}_{k\in\mathbb{N}}$ di $X$, segue che
\begin{align*}
\int_X f(x)d\mu &= \lim_{k\to+\infty}\int_{X_k} f(x)d\mu = \lim_{k\to+\infty}\lim_{n\to+\infty}\int_{X_k}f_n(x)d\mu\\
&= \lim_{n\to+\infty}\lim_{k\to+\infty}\int_{X_k}f_n(x)d\mu = \lim_{n\to+\infty}\int_X f_n(x)d\mu,
\end{align*}
e la formula di passaggio al limite è verificata.
\end{oss}
\begin{subsection}{Funzioni integrali parametriche}
In questa sezione discuteremo riguardo ad un utile applicazione del teorema di Lebesgue. Vediamo:
siano $A$ un insieme misurabile e $f(x,y):A\times (a,b)\to\mathbb{R}$ una funzione misurabile per ogni $x\in A$ e per quasi ogni $y\in (a,b)$. 
Per funzione integrale parametrica intendiamo una funzione del tipo:
\begin{equation}
\xi(y)=\int_A f(x,y)d\mu_x \tag{$*$}
\end{equation}
ove $\mu_x$ è la misura definita su $A$.
Vediamo allora di caratterizzare la continuità e la derivabilità di funzioni del tipo $(*)$ sfruttando proprio il benemerito teorema di convergenza dominata:
\begin{props}
Consideriamo una funzione $\xi(y)$ del tipo $(*)$ e supponiamo che valgano le seguenti condizioni:
\begin{itemize}
\item[$i)$] Esista $\varphi:A\to\mathbb{R}$ integrabile su $A$ tale che $|  f(x,y)|\leq\varphi(x)$ per quasi ogni $x\in A$ e per ogni $y\in (a,b)$ fissato;
\item[$ii)$] $f(x,y)$ sia continua in $(a,b)$ per quasi ogni $x\in A$ fissato.
\end{itemize}
Allora $\xi(y)$ è continua in (a,b).\\
\\
\dimo Proviamo che presa una qualunque successione $\{y_n\}_{n\in\mathbb{N}}$ in $(a,b)$ convergente ad un certo $y_0$,
allora $\lim_{n\to+\infty}\xi(y_n)=\xi(y_0)$. A tal scopo, definiamo la successione $\{f_n\}_{n\in\mathbb{N}}\subset A$ ponendo $f_n(x):=f(x,y_n)$.
Siccome $f$ è misurabile per ogni $x\in A$,e per quasi ogni $y\in (a,b)$, segue che anche le $f_n$ soddisfano questa proprietà;
inoltre dall'ipotesi $i)$ segue che le $f_n$ sono anche integrabili su $A$. Infine da $ii)$ si arguisce che $\lim_{n\to+\infty}f_n(x)=f(x,y_0)$ per quasi ogni $x\in A$.
Grazie ancora alla provvidenziale ipotesi $i)$, possiamo applicare l'annunciato teorema di convergenza dominata e concludere che:
\begin{multline*}
\lim_{n\to+\infty}g(y_n) = \lim_{n\to+\infty}\int_A f(x,y_n)d\mu_x=\\
 =\int_A\lim_{n\to+\infty}f(x,y_n)d\mu_x = \int_A f(x,y_0)d\mu_x= g(y_0).
\end{multline*}
E la tesi è raggiunta.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\begin{props}
Sia $\xi(y)$ una funzione del tipo $(*)$. Supponiamo che si verifichino i seguenti fatti:
\begin{itemize}
\item[i)] $f(x,y)$ sia derivabile per ogni $y\in (a,b)$ e per quasi ogni $x\in A$,
\item[$ii)$] esista $\varphi(x)$ integrabile su $A$ tale che $|\frac{\partial f}{\partial x}(x,y)|\leq\varphi(x)$ per quasi ogni $x\in A$ e per ogni $y\in (a,b)$ fissato.
Allora $\xi(y)$ è derivabile su $(a,b)$ e vale la formula:
\begin{displaymath}
\xi '(y)=\int_A \frac{\partial f}{\partial x}(x,y)d\mu_x.
\end{displaymath}
\end{itemize}
\dimo Fissato un certo $y_0\in (a,b)$, definiamo la funzione 
\begin{displaymath}
F(x,h):=\left\{\begin{array}{ll}
\frac{f(x,y_0+h)-f(x,y_0)}{h} & \textrm{se $h\neq 0$}\\
\frac{\partial f}{\partial x}(x,y_0) & \textrm{se $h=0$}
\end{array}
\right.
\end{displaymath}
Per dimostrare che $\xi$ è derivabile si tratta di provare che esiste finito
\begin{displaymath}
\lim_{h\to 0}\frac{\xi(y_0+h)-\xi(y_0)}{h}=\lim_{n\to+\infty}\frac{\xi(y_0+h_n)-\xi(y_0)}{h_n},
\end{displaymath}
ove $\{h_n\}_{n\in\mathbb{N}}$ è una successione tale che $h_n\to 0$. Facciamo ora un po' di conti:
\begin{displaymath}
\frac{\xi(y_0+h_n)-\xi(y_0)}{h_n} = \int_A \frac{f(x,y_0+h_n)-f(x,y_0)}{h_n}d\mu_x = \int_A F(x,h_n)d\mu_x. 
\end{displaymath}
Notando ora che la funzione $F$ è continua rispetto alla variabile $h$ e sfruttando l'ipotesi $ii)$, possiamo
applicare il teorema di Lebesgue e concludere che 
\begin{multline*}
\xi '(y_0) = \lim_{n\to+\infty}\frac{\xi(y_0+h_n)-\xi(y_0)}{h_n}
= \lim_{n\to+\infty}\int_A F(x,h_n)d\mu_x=\\
=\int_A\lim_{n\to+\infty}F(x,h_n)d\mu_x= \int_A\frac{\partial f}{\partial x}(x,y_0)d\mu_x < +\infty. 
\end{multline*}
Abbiamo pertanto mostrato che $\xi$ è derivabile e che vale la formula della tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{props}
\end{subsection}
\end{section}
\begin{section}{Henry Lebesgue vs Bernard Riemann}
Abbiamo visto una serie di comode proprietà di cui gode l'integrale di Lebesgue, da
quelle più banali a quelle meno intuitive, fino a dimostrare degli importanti teoremi di
passaggio al limite sotto il segno di integrale. Abbiamo addirittura visto che esso si
comporta esattamente come una misura $\sigma$-additiva. Cosa si può volere di più da un
integrale? Ebbene, la teoria di Lebesgue non smette mai di stupire: come ci accingiamo a
mostrare, qualora una funzione $f$ sia integrabile secondo Riemann su un dato insieme $A$,
essa è anche integrabile secondo Lebesgue su tale insieme, e nondimeno i due integrali
coincidono. In altre parole, l'integrale di Lebesgue estende il defezionario integrale di
Riemann. Per questioni di semplicità daremo una dimostrazione di questo fatto nel caso in cui $f$
sia una funzione reale di variabile reale, ma il risultato ha validità generale.
Prima di tutto diamo alcuni brevissimi richiami sull'integrale di Riemann (ne daremo altri nel
prossimo, ed unico, teorema di questa sezione):
\idefin \label{defintriemannmia}
Sia $f:[a,b]\to \R$ e consideriamo l'insieme $\mathscr P$ delle partizioni di $[a,b].$ Definiamo
\emph{somma inferiore relativa alla partizione $p$}\index{Somma!inferiore} 
$$s(f,p)=\sum_{i=1}^n m_i (x_i-x_{i+1}), \quad m_i=\inf_{x\in [x_i,x_{i+1}]}f(x)$$
e \emph{somma superiore relativa alla partizione $p$}\index{Somma!superiore} 
$$S(f,p)=\sum_{i=1}^n M_i (x_i-x_{i+1}), \quad M_i=\sup_{x\in [x_i,x_{i+1}]}f(x).$$
A questo punto definiamo \emph{integrale inferiore}\index{Integrale!inferiore} la quantità
$$\underline{\int_a^b} f(x)dx=\sup_{p\in\mathscr P} s(f,p) $$
e \emph{integrale superiore}\index{Integrale!superiore} la quantità
$$\overline{\int_a^b} f(x)dx=\inf_{p\in\mathscr P} S(f,p) $$
e diciamo che $f$ è integrabile su $[a,b]$ se i due integrali coincidono.
\edefin
\begin{teo}
Sia $f:[a,b]\to\mathbb{R}$ una funzione Riemann-integrabile su $[a,b]$; allora $f$ è
anche Lebesgue-integrabile su $[a,b]$ e
\begin{displaymath}
\int_a^b f(x)dx = \int_{[a,b]} f(x)d\mu,
\end{displaymath}
ovvero gli integrali di Riemann e Lebesgue coincidono.\newline
\\
\dimo
Poniamo $\int_a^b f(x)dx=I$ e partizioniamo l'intervallo $[a,b]$ in $2^n$ parti uguali,
scegliendo $x_k=a+\frac{k}{2^n}(b-a)$; definiamo poi le quantità
$M_{n,k}=\sup_{x_{k-1} \leq x \leq x_k}f$, $m_{n,k}=\inf_{x_{k-1} \leq x \leq x_k}f$, e
consideriamo
\begin{displaymath}
\Omega_n = \frac{b-a}{2^n}\sum_{k=1}^{2^n}M_{n,k}, \quad \omega_n = \frac{b-a}{2^n}\sum_{k=1}^{2^n}m_{n,k}.
\end{displaymath}
poiché $\Omega_n$ e $\omega_n$ rappresentano rispettivamente l'area sottesa da una
funzione maggiorante e da una funzione minorante di $f$, e poiché le successioni
$\{\Omega_n\}_n$, $\{\omega_n\}_n$ sono rispettivamente non crescente e non decrescente, la
Riemann-integrabilità di $f$ su $[a,b]$ ci dice che
\begin{displaymath}
\lim_{n\to \infty} \Omega_n = I = \lim_{n\to \infty} \omega_n.
\end{displaymath}
Dopo questi banali richiami di Analisi I, definiamo due funzioni che maggiorano e minorano
la $f$:
\begin{displaymath}
\phi_n(x) = \sum_{k=1}^{2^n}M_{n,k}  \textrm{\Large$\chi$}_{x_{k-1} \leq x < x_k}(x), \quad \psi_n(x) = \sum_{k=1}^{2^n}m_{n,k}
  \textrm{\Large$\chi$}_{x_{k-1} \leq x < x_k}(x);
\end{displaymath}
è più che evidente che per costruzione si ha
\begin{displaymath}
\int_{[a,b]} \phi_n(x)d\mu = \Omega_n, \quad \int_{[a,b]} \psi_n(x)d\mu = \omega_n.
\end{displaymath}
Inoltre notiamo che le successioni $\{\phi_n\}_n$, $\{\psi_n\}_n$ sono rispettivamente non
crescente e non decrescente, e pertanto valgono quasi ovunque i limiti
$\lim_{n\to \infty} \phi_n(x)=\phi(x) \geq f(x)$, $\lim_{n\to \infty} \psi_n(x)=\psi(x) \leq f(x)$. Questo ci dice
che possiamo applicare il teorema di Beppo Levi, ottenendo
\begin{displaymath}
\int_{[a,b]} \phi(x)d\mu = \lim_{n\to \infty} \Omega_n = I = = \lim_{n\to \infty} \omega_n = \int_{[a,b]} \psi(x)d\mu,
\end{displaymath}
da cui segue subito che $\int_{[a,b]} (\phi(x)-\psi(x))d\mu=0$, cioé
$\phi(x)=\psi(x)=f(x)$ quasi ovunque e quindi
\begin{displaymath}
\int_{[a,b]} f(x)d\mu = I.
\end{displaymath}
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
Ora che abbiamo dimostrato questo fatto, serviamocene per dimostrare che esistono funzioni integrabili secondo
Lebesgue ma non secondo Riemann (e quindi Lebesgue in effetti è più bravo di Riemann, anche se Riemann è di gran
lunga più simpatico). In primo luogo diamo per buono il seguente
\ilemma \label{condintriemannmia}
Una funzione è $R$-integrabile su $[a,b]$ se e solo se per ogni $\epsi>0$ esiste una partizione $p_\epsi\in\mathscr P$
tale che $S(f,p_\epsi)-s(f,p_\epsi)< \epsi$. 
\end{lemma}
%e a questo punto dimostriamo invece la seguente
%\iprop
%Se $f$ è monotona su $[a,b]$, allora è ivi $R$-integrabile.\\
%\newline
%\dimo Supponiamo $f$ non descrescente e prendiamo una partizione $p$; allora
%\begin{multline*}
%S(f,p)-s(f,p)=\sum_{i=1}^n(M_i-m_i)(x_i-x_{i-1})=\\
%=\sum_{i=1}^n(f(x_i)-f(x_{i-1}))(x_i-x_{i-1})
%\leq \delta \sum_{i=1}^n(f(x_i)-f(x_{i-1})) \leq \\ \leq \delta (f(b)-f(a))\leq \epsi 
%\end{multline*}
%a patto di porre $\delta\leq \epsi/(M-m).$
%\eprop
%Tutto ciò per dimostrare che presa in $[a,b]$ una qualsiasi successione $A=\{a_n\}_n$, esiste una funzione monotona
%discontinua esattamente su $A$. Sia $\lam\in\R$ e definiamo la funzione (\emph{funzione di Heaviside})\index{Funzione!di Heaviside}
%\bd
%w_a(x)=\left\{
%\begin{array}{ll}
%0 & \textrm{se $x < a$}\\
%1 & \textrm{se $x \geq a$}\\
%\end{array}
%\right. 
%\ed
%\begin{figure}[h!]
%\bc
%\begin{tikzpicture}[scale=1]
%\draw[->](-3,0)--(3,0); 
%\draw[->](0,-0.2)--(0,1.2);
%\draw[line width=1.2pt](-3,0)--(1,0);
%\draw[line width=1.2pt](1,1)--(3,1);
%\filldraw[black](1,1) circle (0.08);
%\draw[dashed](1,1)--(1,0);
%\draw[dashed](1,1)--(0,1);
%\draw(1,0)node[anchor=north]{$\lam$};
%\draw(0,1)node[anchor=east]{1};
%\end{tikzpicture}
%\ec
%\end{figure}
%Ora possiamo definire per ogni $N$ positiva
%$$f_N(x)=\sum_{n=1}^N \frac{1}{2^n}w_{a_n}(x)$$
%e notiamo che per costruzione vale
%$$0\leq f(x)=\sum_{n=1}^\infty \frac{1}{2^n}w_{a_n}(x) \leq 1.$$
%La successione delle $f_N$ converge puntualmente a $f$ ed anche uniformemente; infatti 
%$$0\leq f(x)-f_N(x)=\sum_{n=N+1}^\infty \frac1{2^n}w_{a_n}(x)\leq \sum_{n=N+1}^\infty \frac1{2^n} $$
%cioè $0\leq f(x)-f_N(x)\leq 1/2^N$ per ogni $x\in [a,b]$, cioè basta porre $2^N>1/\epsi$ (cioè $N>\log_2\epsi$)
%per ottenere la convergenza uniforme.\\
%Se $x$ è un punto di continuità per tutte le $f_N$, allora allora anche $f$ è continua in $x$, cioè $f$ è continua
%su $[a,b]\smallsetminus S$. Ora, supponiamo $n\neq m,$ cioè $a_n\neq a_m$; allora
%$$\lim_{x\to a_n^+}f(x)-\lim_{x\to a_n^-}=\frac1{2^n}.$$
Se come successione prendiamo quella dei razionali tra $a$ e $b$, cioè $Q=\Q\cap [a,b]$, notiamo che 
la funzione caratteristica $\chii_Q(x)$ non è $R$-integrabile, poichè per ogni $p\in\mathscr P$
si ha $s(f,p)=0<1=S(f,p)$; tuttavia questa funzione è $L$-integrabile perchè è una
funzione semplice (assume un solo valore) definita su un misurabile ($\Q$ e $[a,b]$ sono misurabili e quindi anche la loro
intersezione lo è).
\end{section}
\begin{section}{Misura prodotto. Teoremi di Fubini e Tonelli}
Iniziamo col dare qualche cenno riguardo alla definizione di misura prodotto ed alle sue peculiari proprietà: 
innanzitutto considerati due spazi misurabili $(X,\mathfrak{S}_X,\mu_x)$ e $(Y,\mathfrak{S}_Y,
\mu_y)$, possiamo definire una $\sigma$-algebra sullo spazio
$X\times Y$ ponendo
\begin{displaymath}
\mathfrak{S}_X\otimes\mathfrak{S}_Y := \sigma\{A\times B|  A\in\mathfrak{S}_X,B\in
\mathfrak{S}_Y\}.
\end{displaymath}
L'arguto (ma disattento!) lettore si chiederà immediatamente perché non si è posto  $\mathfrak{S}_X\otimes
\mathfrak{S}_Y =\{A\times B|  A\in\mathfrak{S}_X,B\in\mathfrak{S}_Y \}$:
il motivo è lapalissiano visto che l'insieme $\{A\times B|  A\in\mathfrak{S}_X, B
\in\mathfrak{S}_Y\}$ è un semianello ma non un anello (e quindi figuriamoci una $\sigma$-algebra).
Possiamo ora trasformare l'insieme $(X\times Y,\mathfrak{S}_X\otimes\mathfrak{S}_Y)$ in uno spazio misurabile 
ponendo:
\begin{displaymath}
\mu_x\otimes\mu_y(A\times B) := \mu_x(A)\mu_y(B)\quad\textrm{per ogni $A\times B\in\mathfrak{S}_X\otimes
\mathfrak{S}_Y$}.
\end{displaymath}
Si può dimostrare che tale misura è ben definita, completa e $\sigma$-additiva in quanto costituisce il 
prolungamento di Lebesgue della misura additiva
\begin{displaymath}
m_x\otimes m_y := m_x(A)m_y(B)\quad\textrm{per ogni $A\times B\in S_1\times S_2$},
\end{displaymath}
ove $S_1\times S_2$ è il semianello prodotto definita dalla relazione
\begin{displaymath}
S_1\times S_2 := \{A\times B|  A\in\mathfrak{S}_X, B\in\mathfrak{S}_Y\}.
\end{displaymath}
Se esistesse qualcuno interessato a questa tematica, può fare riferimento al libro  
``Elementi di teoria delle funzioni e di analisi funzionale''  degli esimi autori Kolmogorov e Fomin, il quale,
a nostro giudizio, dovrebbe essere posseduto da ogni buon studente con ambizioni di laurea in matematica.
Vediamo ora alcuni lemmi:
\begin{lemma}\label{costruzioneinsiemiB}
Sia $A$ un insieme misurabile. Allora esiste un insieme $B$ misurabile tale che $B\supset A$ e 
$\mu(B)=\mu(A)$ costruibile in tal modo:
\begin{displaymath}
B=\bigcap_n B_n\quad\textrm{con $B_1\supset B_2\supset\ldots\supset B_n\supset\ldots$},
\end{displaymath}
\begin{displaymath}
B_{nk}=\bigcup_k B_{nk}\quad\textrm{con $B_{n1}\subset B_{n2}\subset\ldots\subset B_{nk}\subset\ldots$},
\end{displaymath}
e i $B_{nk}$ insiemi elementari.\newline
\dimo
\dimo Essendo $A$ misurabile, esiste $C_n=\bigcup_r\Delta_{nr}$ per certi \footnote{Ricordiamo che con $\mathfrak{R}$ indichiamo la famiglia di tutti i rettangoli.}
$\Delta_{nr}\in\mathfrak{R}$ 
tale che $C_n\supset A$ e $\mu(A)\geq\mu(C_n)-1/n$. Poniamo ora
\begin{displaymath}
B_n := \bigcap_{k=1}^n C_k;
\end{displaymath}
per costruzione risulta che $B_1\supset B_2\supset\ldots\supset B_n\supset\ldots$, e inoltre dalla definizione dei $C_n$ segue subito che 
esistono $\delta_{ns}\in\mathfrak{R}$ tali che $B_n=\bigcup_s \delta_{ns}$. 
Definiamo ora 
\begin{displaymath}
B_{nk}:=\bigcup_{s=1}^k\delta_{ns};
\end{displaymath}
per costruzione i $B_{nk}$ sono elementari e $B_{n1}\subset B_{n2}\subset\ldots\subset B_{nk}\subset\ldots$; inoltre
\begin{displaymath}
B_n=\bigcup_k\bigcup_{s=1}^k\delta_{ns}=\bigcup_k B_{nk}.
\end{displaymath}
Da ultimo poniamo 
\begin{displaymath}
B=\bigcap_n B_n;
\end{displaymath}
siccome $A\subset C_n$ per ogni $n$, allora segue che $B\supset A$, e quindi $\mu(B)\geq\mu(A)$. Inoltre $B\subset C_n$ per ogni $n$,
e quindi, ricordando l'ipotesi iniziale, otteniamo che $\mu(A)\geq\mu(C_n)-1/n\geq\mu(B)-1/n$ per ogni $n$, e quindi $\mu(A)\geq\mu(B)$.
Abbiamo pertanto dimostrato tutto quello che c'era da dimostrare.
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
\begin{lemma}\label{misuraprodotto}
Siano $(X,\mathfrak{S}_X,\mu_x)$,$(Y,\mathfrak{S}_Y,\mu_y)$ due spazi misurabili e consideriamo gli insiemi 
$A_x:=\{y\in Y|  (x,y)\in A\}$ e $A_y=\{x\in x\ |\   (x,y)\in A\}$ per un certo $A\subset X\times Y$.
Allora, posto $\mu:=\mu_x\otimes\mu_y$, vale la seguente relazione:
\begin{displaymath}
\mu(A)=\int_X\mu_y(A_x)d\mu_x=\int_Y\mu_x(A_y)d\mu_y.
\end{displaymath}
\dimo La dimostrazione si articola in diversi passi:
passo $i)$: proviamo la tesi per gli insiemi del tipo $A=A_{y_0}\times A_{x_0}$ per certi $x_0\in X$,$y_0\in Y$ fissati. Definiamo le funzioni
$\varphi_A(x):=\mu_y(A_x)$ e $\varphi_A(y):=\mu_x(A_y)$: è palese che per arrivare alla tesi basterà provare che 
$\mu(A)=\int_X\varphi_A(x)d\mu_x$ (l'altra formula seguirà per simmetria ed è lasciata come esercizio). Fissato allora un $x\in X$
abbiamo che 
\begin{displaymath}
(A_{y_0}\times A_{x_0})_x=
\left\{\begin{array}{ll}
A_{x_0} & \textrm{se $x\in A_{y_0}$}\\
\varnothing & \textrm{altrove}
\end{array}
\right.
\end{displaymath}
da cui 
\begin{displaymath}
\varphi_A(x)=\mu_y(A_{x_0})\textrm{\Large$\chi$}_{A_{y_0}}(x).
\end{displaymath}
Integrando otteniamo quindi che 
\begin{displaymath}
\int_X\varphi_A(x)d\mu_x=\mu_x(A_{y_0})\mu_y(A_{x_0})=\mu(A),
\end{displaymath}
e la tesi è provata. Notiamo, in particolare, che la tesi è provata per i rettangoli.
\\
passo $ii)$: per la $\sigma$-additività di $\mu$ e per la linearità dell' integrale, la tesi segue subito per gli insiemi che 
si scrivono come unione disgiunta di quelli del passo $i)$, ergo, in particolare, per gli insiemi elementari (dimostra questo fatto per esercizio.).
\\
passo $iii)$: proviamo la tesi per gli insiemi definiti nel lemma \ref{costruzioneinsiemiB}: anzitutto i $B_{nk}$ sono elementari, e perciò la tesi è provata 
per il passo $ii)$. Proviamola per i $B_n$: considerata la funzione $\varphi_{B_{nk}}(x)=\mu_y((B_{nk})_x)$, abbiamo che da
$B_{n1}\subset B_{n2}\subset\ldots\subset B_{nk}\subset\ldots$ segue che $\varphi_{B_{n1}}\leq\varphi_{B_{n2}}\leq\ldots\leq\varphi_{B_{nk}}\leq\ldots$,
e quindi dal teorema di Beppo Levi possiamo dedurre che esiste quasi ovunque $\lim_{k\to+\infty}\varphi_{B_{nk}}$; inoltre dalla continuità della misura 
sappiamo che $\mu_y(B_n)=\lim_{k\to+\infty}\mu_y(B_{nk})$, e pertanto possiamo concludere che per ogni $x\in X$ vale la formula
\begin{displaymath}
\varphi_{B_n}=\lim_{k\to+\infty}\varphi_{B_{nk}}.
\end{displaymath}
Allo stesso modo si prova che per ogni $x\in X$ vale che $\varphi_B=\lim_{n\to+\infty}\varphi_{B_n}$. Sempre per Beppo Levi segue che 
\begin{displaymath}
\lim_{k\to+\infty}\int_X\varphi_{B_{nk}}(x)d\mu_x=\int_X\varphi_{B_n}(x)d\mu_x,
\end{displaymath}
e siccome $\mu(B_{nk})=\int_X\varphi_{B_{nk}}(x)d\mu_x$, allora si conclude che 
\begin{displaymath}
\mu(B_n)=\lim_{k\to+\infty}\mu(B_{nk})=\int_X\varphi_{B_n}d\mu_x.
\end{displaymath}
Nello stesso identico modo si prova che $\mu(B)=\int_X\varphi_B(x)d\mu_x$, e così si conclude il passo $iii)$.
\\
passo $iv)$: verifchiamo la tesi per un qualsivoglia insieme di misura nulla: sia quindi $A$ misurabile con $\mu(A)=0$ e consideriamo 
l'insieme $B\supset A$ del lemma \ref{costruzioneinsiemiB}; allora $\mu(B)=\mu(A)=0$ e quindi $\varphi_B(x)=\mu_y(B_x)=0$. Inoltre
$A_x\subset B_x$ e quindi anche $\varphi_A(x)$ è nulla. Segue dunque che 
\begin{displaymath}
0=\mu(A)=\int_X\varphi_A(x)d\mu_x,
\end{displaymath}
cioé la tesi.\\
passo $v)$: quinto e ultimo passo, nel quale si prover'a la tesi per un insieme misurabile arbitrariamente scelto: sia allora $A$ tale insieme,
e, considerati il provvidenziale insieme $B$ del lemma \ref{costruzioneinsiemiB} ed un qualunque insieme $C$ di misura nulla, segue che posso rappresentare 
$A$ nella forma $A=B\smallsetminus C$ (visto che $\mu(A)=\mu(B)-\mu(C)=\mu(B)$). Allora segue subito che $\varphi_A(x)=\varphi_B(x)-\varphi_C(x)=\varphi_B(x)$ 
da cui
\begin{displaymath}
\int_X\varphi_A(x)d\mu_x=\int_X\varphi_B(x)d\mu_x=\mu(B).
\end{displaymath}
Ricordando per la $k$-esima volta che $\mu(B)=\mu(A)$, segue la tesi del teorema.
\begin{flushright}
$\square$
\end{flushright}
\end{lemma}
\begin{oss}
Si noti che nel teorema precedente si devono sottointendere le seguenti ipotesi:
\begin{itemize}
\item[$i)$] Gli insiemi $A_x$ e $A_y$ sono rispettivamente $\mu_y$ e $\mu_x$ misurabili per ogni $x,y$ fissati.
\item[$ii)$] Le funzioni $\varphi_A(x)$ e $\varphi_A(y)$ sono misurabili.\\
Senza queste ipotesi aggiuntive, il teorema precedente sarebbe privo di significato.
\end{itemize}
\end{oss}
\begin{cor}
Siano $(X,\mathfrak{S}_X,\mu_x)$,$(Y,\mathfrak{S}_Y,\mu_y)$ due spazi misurabili e consideriamo l'insieme
\begin{displaymath}
A=\{(x,y)\in X\times Y|  x\in M,0\leq y\leq f(x)\},
\end{displaymath}
ove $f$ è una funzione da $X$ in $Y$ e $M$ è un insieme $\mu_x$-misurabile. Allora
\begin{displaymath}
\mu(A)=\int_M f(x)d\mu_x.
\end{displaymath}
\dimo è una banale applicazione del lemma \ref{misuraprodotto}: in tal caso abbiamo
\begin{displaymath}
A_x=\left\{\begin{array}{ll}
[0,f(x)] & \textrm{se $x\in M$}\\
\varnothing & \textrm{altrimenti}
\end{array}
\right.
\end{displaymath}
e quindi
\begin{displaymath}
\varphi_A(x)=f(x)\textrm{{\LARGE$  \textrm{\Large$\chi$}$}}_M(x).
\end{displaymath}
Applicando il lemma suddetto segue pedissequamente la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{cor}
\begin{teo}\textbf{(di Fubini-Tonelli)} Siano $(X,\mathfrak{S}_X,\mu_x)$,$(Y,\mathfrak{S}_Y,\mu_y)$ due spazi misurabili e $A\subset X\times Y$ un insieme misurabile.
Sia inoltre $f(x,y)$ una funzione integrabile su $A$ rispetto alla misura prodotto $\bar{\mu}:=\mu_x\otimes\mu_y$. Allore vale che
\begin{displaymath} \index{Teorema!di Fubini-Tonelli}
\int_A f(x,y)d\bar{\mu} = \int_X d\mu_x \int_{A_x} f(x,y)d\mu_y = \int_Y d\mu_y \int_{A_y} f(x,y)d\mu_x.
\end{displaymath}
\dimo Iniziamo a considerare il caso in cui $f(x,y) \geq 0$; nel caso generale basterà notare
che $f(x,y)=f^+(x,y)-f^-(x,y)$, ove $f^+$ e $f^-$ sono rispettivamente la parte positiva e
negativa\footnote{Ricordiamo che cosa sono la parte positiva e la parte negativa di $f$:
\begin{displaymath}
f^+(x,y) = \frac{|  f(x,y)| +f(x,y)}{2}, f^-(x,y) = \frac{|  f(x,y)| -f(x,y)}{2}
\end{displaymath}}
di $f$, e applicare il risultato ottenuto per funzioni positive ad esse. Sia $\mu$ la misura di Lebesgue definita sulla retta reale, e
consideriamo lo spazio $U:=X\times Y\times\mathbb{R}$ equipaggiato con la misura
$\tilde{\mu}=\mu_x\otimes\mu_y\otimes\mu=\bar{\mu}\otimes\mu$. Sia poi $W \subseteq U$ il seguente insieme:
\begin{displaymath}
W := \{(x,y,z) \in U |  (x,y) \in A, 0 \leq z \leq f(x,y)\};
\end{displaymath}
per il corollario precedente abbiamo che
\begin{displaymath}
\tilde{\mu}(W) = \int_A f(x,y)d\bar{\mu};
\end{displaymath}
se ora poniamo $\xi:=\mu_y\otimes\mu$ e $W_x=\{(y,z)| (x,y,z) \in W\}$ possiamo applicare il lemma \ref{misuraprodotto}
e concludere che
\begin{displaymath}
\tilde{\mu}(W) = \int_X \xi(W_x)d\mu_x.
\end{displaymath}
Infine notiamo che vale l'uguaglianza
\begin{displaymath}
W_x=A_x\times [0,f(x,y)],
\end{displaymath}
e pertanto, ancora fruendo del corollario precedente, possiamo affermare che
\begin{displaymath}
\xi(W_x) = \int_{A_x} f(x,y)d\mu_y.
\end{displaymath}
A questo punto anche il lettore non troppo sveglio capirà senza particolari problemi che,
combinando assieme le tre formule ottenute, si ottiene nientepopodimenoche la tesi.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{teo}\textbf{(di Tonelli)} Siano $A\subset X\times Y$ e $f(x,y)$ come nel teorema precedente. Se esiste almeno
una delle due quantità\index{Teorema!di Tonelli}
\begin{displaymath}
\int_X d\mu_x \int_{A_x} |  f(x,y)|  d\mu_y,\int_Y d\mu_y \int_{A_y} |  f(x,y)|  d\mu_x,
\end{displaymath}
allora $f$ è integrabile su $A$ (e in particolare vale il teorema di Fubini-Tonelli).\newline
\\
\dimo
Senza perdere in generalità supponiamo che esista la prima delle due quantità
menzionate nella tesi, e sia essa uguale ad $I$. Definiamo inoltre la successione
\begin{displaymath}
f_n(x,y) := \min\{|  f(x,y)| ,n\},
\end{displaymath}
che, per costruzione, è una successione monotona non decrescente che converge quasi ovunque
a $|  f(x,y)| $. Inoltre le $f_n$ sono funzioni misurabili e limitate, in quanto minori o
uguali ad $n$, e quindi integrabili grazie alla proprietà $(3)$ (in particolare per le
$f_n$ vale quindi il teorema di Fubini). poiché poi $f_n(x,y) \leq |  f(x,y)| $, si ha
\begin{displaymath}
\int_A f_n(x,y)d\bar{\mu} = \int_X d\mu_x \int_{A_x} f_n(x,y)d\mu_y \leq I < +\infty.
\end{displaymath}
Ma ora siamo nelle condizioni di poter applicare il teorema di Beppo Levi ed ottenere
quindi l'integrabilità su $A$ di $|  f(x,y)| $. Ma allora basta ricordare la proprietà $(8)$
per concludere che anche $f(x,y)$ è integrabile su $A$.
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\begin{esem}
Dall'esistenza degli integrali
\begin{displaymath}
\int_X d\mu_x\int_{A_x}f(x,y)d\mu_y\quad \textrm{e}\quad\int_Y d\mu_y\int_{A_y}f(x,y)d\mu_x,
\end{displaymath}
non possiamo generalmente dedurre alcunchè sull'integrabilità di $f$ sull'insieme $A$ rispetto alla misura $\bar{\mu}$. Consideriamo il seguente esempio:
definiamo la funzione $f(x,y)$  sul quadrato chiuso $Q=[-1,1]\times[-1,1]$ ponendo
\begin{displaymath}
f(x,y):=\left\{\begin{array}{ll}
\frac{xy}{(x^2+y^2)^2} & \textrm{se $(x,y)\neq(0,0)$}\\
0 & \textrm{altrove}
\end{array}
\right..
\end{displaymath}
Siccome $f$ è dispari rispetto ad entrambe le variabili, otteniamo che il suo integrale su intervalli simmetrici rispetto all'origine è nullo, cioé
\begin{displaymath}
\int_{-1}^{1} dy\int_{-1}^{1} f(x,y)dx=\int_{-1}^{1} dx\int_{-1}^{1} f(x,y)dy=0.
\end{displaymath}
Tuttavia $\int_Q |  f(x,y)|  dxdy=+\infty$: infatti, siccome $Q\supsetneq \{(x,y)\in\mathbb{R}^2|  x^2+y^2\leq 1\}$, possiamo dire che
\begin{displaymath}
\int_Q |  f(x,y)|  dxdy\geq \int_{\{x^2+y^2\leq 1\}}|  f(x,y)|  dxdy=+\infty,
\end{displaymath}
ove l'ultimo conto è semplice ed è lasciato come esercizio. Pertanto $f$ non è integrabile su $Q$ per la proprietà 8 dell'integrale di Lebesgue.
\end{esem}
\begin{esem}
Sia $Q=[0,1]\times [0,1]$ e definiamo $f:Q\to\mathbb{R}$ ponendo
\begin{displaymath}
f(x,y):=\left\{
\begin{array}{ll}
\frac{x^2-y^2}{(x^2+y^2)^2} & \textrm{se $(x,y)\neq (0,0)$}\\
0 & \textrm{altrove}
\end{array}
\right.
\end{displaymath}
siccome valgono le formule 
\begin{displaymath}
\frac{\partial}{\partial y}(\frac{y}{x^2+y^2})=\frac{x^2-y^2}{(x^2+y^2)^2}=\frac{\partial}{\partial x}(\frac{-x}{x^2+y^2}),
\end{displaymath}
segue che 
\begin{displaymath}
\int_{0}^{1}dx\int_{0}^{1}\frac{x^2-y^2}{(x^2+y^2)^2}dy=\frac{\pi}{4},
\end{displaymath}
\begin{displaymath}
\int_{0}^{1}dy\int_{0}^{1}\frac{x^2-y^2}{(x^2+y^2)^2}dx=-\frac{\pi}{4}.
\end{displaymath}
Per il teorema di Fubini-Tonelli si conclude che $f(x,y)$ non è integrabile su $Q$; inoltre dal teorema di Tonelli segue anche che 
\begin{displaymath}
\int_{0}^{1}dx\int_{0}^{1}\frac{|  x^2-y^2| }{(x^2+y^2)^2}dy=\int_{0}^{1}dy\int_{0}^{1}\frac{|  x^2-y^2| }{(x^2+y^2)^2}dx=+\infty.
\end{displaymath}
\end{esem}
\begin{esem}
Vediamo ora un'applicazione del teorema di Fubini: definiamo le funzioni $\Gamma$ e $\beta$ di Eulero
ponendo \index{Funzione! Gamma di Eulero} \index{Funzione!Beta di Eulero}
\begin{displaymath}
\Gamma(p):=\int_{0}^{\infty}x^{p-1}e^{-x}dx,\beta(p,q):=\int_{0}^{1}x^{p-1}(1-x)^{q-1}dx.
\end{displaymath}
Proviamo che per ogni $p,q>0$ vale la seguente formula:
\begin{displaymath}
\beta(p,q)=\frac{\Gamma(p)\Gamma(q)}{\Gamma(p+q)}.
\end{displaymath}
Per il teorema di Fubini-Tonelli abbiamo che 
\begin{displaymath}
\Gamma(p)\Gamma(q)=\int_{\mathbb{R}^+\times\mathbb{R}^+}x^{p-1}y^{q-1}e^{-(x+y)}dxdy;
\end{displaymath}
operiamo ora il seguente cambio diffeomorfo di coordinate:
\begin{displaymath}
\varphi(x,y)=(x,x+y)=(u,v),
\end{displaymath}
il quale ammette come trasformazione inversa
\begin{displaymath}
\varphi^{-1}(u,v)=(u,v-u)=(x,y).
\end{displaymath}
Applicando il teorema di cambiamento di variabile otteniamo che
\begin{multline*}
\int_{\mathbb{R}^+\times\mathbb{R}^+}x^{p-1}y^{q-1}e^{-(x+y)}dxdy = \int_{\{u>0,v-u>0\}}u^{p-1}(v-u)^{q-1}e^{-v}dudv=\\
 = \int_{0}^{\infty}e^{-v}dv\int_{0}^{v}u^{p-1}(v-u)^{q-1}du.
\end{multline*}
Ponendo $u/v=t$ e risolvendo l'integrale scritto sopra ancora con la formula di cambiamento di variabile si giunge celermente
alla tesi (questi ultimi calcoli li lasciamo al lettore come esercizio).
\end{esem}
\end{section}
\end{chapter}
\begin{chapter}{Appendice}
\lettrine[lines=1]{N}{ell'appendice sono contenuti} esempi interessanti, applicazioni e chiarimenti della teoria,
correzioni,etc.: insomma tutto quello che avreste voluto sapere su complementi di analisi ma non avete 
mai osato chiedere.
\begin{section}{Misura del conteggio}
Consideriamo una successione $\{\omega_n \}_{n \in\mathbb{N}}$   e un sottoinsieme $A \subset \mathbb{N}$. Si definisce la misura del conteggio
su $\mathbb{N}$ ponendo \index{Misura!del conteggio}
\begin{displaymath}
\mu_\omega(A) := \sum_{{n_k} \in A} \omega_{n_k}
\end{displaymath}
Grazie a questa misura si può definire l'integrale per una qualsiasi funzione  $f:\mathbb{N}\to\mathbb{R}$ ponendo
\begin{displaymath}
\int_{\mathbb{N}} f d\mu_{\omega} := \sum_n f(n)\omega_n 
\end{displaymath}
risulta quindi immediato definire l'integrale su $A$ ponendo
\begin{displaymath}
\int_{A} f d\mu_{\omega} = \int_{\mathbb{N}} f   \textrm{\Large$\chi$}_{A} d \mu_{\omega} = \sum_{n_k \in A} f(n) \omega_{n_k}
\end{displaymath}
Considerata una funzione $f:\mathbb{N} \times \mathbb{N}\to\mathbb{R}$, il teorema di Tonelli ci dice che, se esiste finito almeno uno degli integrali
\begin{displaymath}
\int_{\mathbb{N}}d\mu_\omega\int_{\mathbb{N}}fd\mu_{\lambda} \quad \textrm{oppure} \quad \int_{\mathbb{N}}d\mu_\lambda\int_{\mathbb{N}}fd\mu_{\omega}
\end{displaymath}
allora $f$ è integrabile su $\mathbb{N} \times \mathbb{N}$ e vale la formula di Fubini-Tonelli; in particolare quello che abbiamo detto si traduce,
in termini di serie, dicendo che se almeno una tra le serie
\begin{displaymath}
\sum_n\omega_n\sum_m f(m,n)\lambda_m \quad \textrm{oppure} \quad \sum_m\lambda_m\sum_n f(m,n)\omega_n
\end{displaymath}
esite finita (i.e. è una serie convergente), allora esiste finita la serie 
\begin{displaymath}
\sum_{(m,n) \in \mathbb{N} \times \mathbb{N}}f(m,n)\omega_n\lambda_m  .
\end{displaymath}
In particolare, sotto le ipotesi del teorema di Tonelli, possiamo affermare che la somma di una serie resta inalterata se si scambiano
gli indici: infatti applicando Fubini-Tonelli otteniamo che
\begin{displaymath}
\int_{\mathbb{N} \times \mathbb{N}}fd(\mu_\omega \otimes \mu_\lambda) = \int_{\mathbb{N}}d\mu_\omega\int_{\mathbb{N}}fd\mu_\lambda = \int_{\mathbb{N}}d\mu_\lambda\int_{\mathbb{N}}fd\mu_\omega 
\end{displaymath}
cosa che, tradotta in termini di serie, è equivalente a 
\begin{displaymath}
\sum_{(m,n) \in \mathbb{N} \times \mathbb{N}}f(m,n)\omega_n\lambda_m = \sum_n\omega_n\sum_m f(m,n)\lambda_m = \sum_m\lambda_m\sum_n f(m,n)\omega_n  .
\end{displaymath}
\end{section}
\begin{section}{Usi notevoli di Fubini-Tonelli}
\begin{teo}
Vale la relazione 
\begin{displaymath}
\int_{\mathbb{R}}\frac{\sin(x)}{x}dx = \pi 
\end{displaymath}\\
\textbf{Dimostrazione:} Dimostriamo, cosa totalmente equivalente alla tesi, che
\begin{displaymath}
\int_{0}^{\infty}\frac{\sin(x)}{x}dx = \frac{\pi}{2}.
\end{displaymath}
\begin{figure}[h!]
\begin{asy}
import graph;
size(13cm,4cm);
scale(false);
xlimits(-10,10);
ylimits(-0.5,1.5);
crop();
real f(real x) {return (x != 0.0) ? (sin(x))/x : 0.0;}
path g=graph(f,-10,-0.001,operator ..)--(-0.001,0)--(-10,0)--cycle;
path h=graph(f,0.001,10,operator ..)--(10,0)--(0.001,0)--cycle;
filldraw(g,palegreen);
filldraw(h,palegreen);
xaxis("$x$");
yaxis("$y$");
draw(graph(f,-10,-0.001));
draw(graph(f,0.001,10));
label("$\frac{\sin(x)}{x}$", (1,0.8), NE);
\end{asy}
\end{figure}
\newline
Consideriamo la funzione $f(x,y) = \sin(x)e^{-xy}$ e l'insieme $E_A := (0,A) \times \mathbb{R}$
definito per $A > 0$. Anzitutto proviamo che $f \in L^{1}(E_A)$ : abbiamo che 
\begin{displaymath}
\int_{0}^{A}dx\int_{0}^{\infty}|sin(x)|  e^{-xy}dy = \int_{0}^{A}\frac{|sin(x)| }{x}dx \leq \int_{0}^{A}\frac{|x|}{x}dx < +\infty
\end{displaymath}
e quindi il teorema di Tonelli ci assicura che $f$ è integrabile su $E_A$. Ciò fatto possiamo applicare il teorema di Fubini-Tonelli
per integrare $f$ su $E_A$ ottenendo che 
\begin{equation}\label{eq1}
\iint_{E_A}f(x,y)dxdy = \int_{0}^{\infty}dy\int_{0}^{A}\sin(x)e^{-xy}dx  .
\end{equation}
Risolvendo per parti si ottiene che
\begin{equation}\label{eq2}
\int_{0}^{A}e^{-xy}\sin(x)dx = \frac{1 - e^{-Ay}\{\cos(A) + y\sin(A)\}}{1 + y^2}  .
\end{equation}
Mettendo assieme \ref{eq1} e \ref{eq2} si ottiene che
\begin{displaymath}
\int_{E_A}f(x,y)dxdy = \int_{0}^{\infty}\frac{1}{1 + y^2}dy - \int_{0}^{\infty}\frac{e^{-Ay}\{\cos(A) + y\sin(A)\}}{1 + y^2}dy =
\end{displaymath}
\begin{displaymath}
=\frac{\pi}{2} - \int_{0}^{\infty}g_A(y)dy ,
\end{displaymath}
ove si è posto 
\begin{displaymath}
g_A(y) := \frac{e^{-Ay}\{\cos(A) + y\sin(A)\}}{1 + y^2}  .
\end{displaymath}
Otteniamo quindi l'equazione
\begin{equation}\label{eq3}
\int_{0}^{\infty}\frac{|sin(x)| }{x}dx = \frac{\pi}{2} - \int_{0}^{\infty}g_A(y)dy  .
\end{equation}
Proviamo ora che 
\begin{equation}\label{eq4}
\lim_{A\to+\infty}\int_{0}^{\infty}g_A(y)dy = 0.
\end{equation}
Sia $\{A_n\}_{n \in \mathbb{N}}$ una successione tale che $\lim_{n\to+\infty}A_n = +\infty$ : allora provare la relazione \ref{eq4} 
è equivalente a provare la relazione
\begin{displaymath}
\lim_{n\to+\infty}\int_{0}^{\infty}g_{A_n}(y)dy = 0  :
\end{displaymath}
siccome
\begin{displaymath}
g_A(y) \leq \frac{e^{-y}(1 + y)}{1 + y^2} \leq \frac{1}{1 + y^2} \in L^1(0,+\infty) ,
\end{displaymath}
il teorema di Lebesgue implica che 
\begin{equation}\label{eq5}
\lim_{n\to+\infty}\int_{0}^{\infty}g_{A_n}(y)dy = \int_{0}^{\infty}\lim_{n\to+\infty}g_{A_n}(y)dy = 0  .
\end{equation}
Mettendo assieme \ref{eq3} e \ref{eq5} otteniamo che
\begin{displaymath}
\int_{0}^{\infty}\frac{|sin(x)| }{x}dx = \lim_{A\to+\infty}\int_{0}^{A}\frac{|sin(x)| }{x}dx = \frac{\pi}{2} 
\end{displaymath}
Abbiamo così concluso la dimostrazione.  
\begin{flushright}
$\square$
\end{flushright}
\end{teo}
\end{section}
\begin{section}{Ma cosa cambia se la misura è infinita?}
In questo paragrafo diamo un esempio di una funzione $f(x)$ e di una successione $f_n (x)$ covergente 
uniformemente ad $f$ tali che, su un insieme $E$ di misura infinita, 
esista finito $\int_E f_n (x)d\mu$ ma si abbia che $\lim_{n\to+\infty}\int_E f_n (x)d\mu = +\infty$. Ciò
 mostra che la definizione di integrale di Lebesgue per funzioni qualsiasi
è ben posta solo su insiemi di misura finita: quando invece si desidera integrare su insiemi di misura 
infinita, bisogna ricorrere alla successioni esaustive.
Sia quindi $f(x) = \frac{1}{\sqrt{x}}$ definita sul dominio $E = (0,+\infty)$ e consideriamo la solita 
successione di funzioni semplici approssimanti $f$ ponendo 
\begin{displaymath}
f_{n}^{m} := \frac{m}{n}\Large\chi_{\{x\ |\   \ \frac{m}{n} \leq f(x) \leq \frac{m+1}{n}\}}(x)
\end{displaymath}
Otteniamo allora che 
\begin{equation}\label{intfunzsempl}
\int_E f_{n}^{m}d\mu = \sum_m \frac{m}{n}\mu(A_n^{m})
\end{equation}
ove si ha che  
\begin{equation}\label{defAnm}
A_n^{m} = \Big\{x\ \Big|  \ 0 \leq \Big(\frac{n}{m+1}\Big)^2 \leq x \leq \Big(\frac{n}{m}\Big)^2 < +\infty \Big\}
\end{equation}
Non sussistono quindi limitazioni sugli interi $m,n$, e mettendo assieme \ref{intfunzsempl} e \ref{defAnm} 
si ottiene che
\begin{displaymath}
\int_E f_{n}^{m} d\mu = \sum_m \frac{m}{n} \Big\{\Big(\frac{n}{m+1}\Big)^2 - \Big(\frac{n}{m}\Big)^2 \Big\} = 
n\sum_m\frac{2m+1}{m^2(m+1)^2} < +\infty
\end{displaymath}
poiché l'ultima serie scritta ha lo stesso carattere di $\sum_m \frac{1}{m^3}$, che è convergente.
Tuttavia la funzione $f$ non è integrabile su $E$ secondo la vecchia definizione poiché
\begin{displaymath}
\int_E f(x)d\mu = \lim_{n\to+\infty}n\sum_m\frac{2m+1}{m^2(m+1)^2} = +\infty .
\end{displaymath}
\end{section}
\end{chapter}
\begin{chapter}{La rivincita di Riemann}
\lettrine[lines=1]{L}{ebesgue avrà pure il merito} di aver sviluppato una teoria di più largo respiro rispetto a Riemann, ma resta comunque il fatto
che l'integrale alla sua maniera non si può calcolare esplicitamente quasi mai e bisogna sempre rifarsi a quello originale, sapendo che
tanto coincidono; questo capitolo dunque vuole dare a Riemann ciò che è di Riemann, uscendo 
dalla stretta teoria della misura e proponendoci invece ulteriori nozioni
sulla R-integrabilità ed esempi di ciò che ci si può concretamente fare (capito signor Lebesgue?).
\begin{section}{Approfondimenti sull'integrale di Riemann}
Riprendiamo, ancora, l'integrale di Riemann:
\idefin Sia $f:[a,b]\to\R$ e prendiamo una partizione $p$. Per ogni intervallo della partizione sia $\xi_i^*\in[x_{i-1},x_i]$ 
(un tale $\xi_i^*$ si dice \emph{punto base}\index{Punto base});
chiamiamo \emph{somma di Riemann relativa alla funzione $f$, alla partzione $p$ ed alla scelta
dei punti base $\xi^*=(\xi^*_1,\ldots,\xi^*_n)$}\index{Somma di Riemann} la quantità 
$$\mathfrak s(f,p,\xi^*)=\sum_{i=1}^nf(\xi^*_i)(x_i-x_{i-1}).$$ 
\edefin
Per ogni partizione $p\in\mathscr P$ scelta abbiamo $s(f,p)\leq \mathfrak s(f,p,\xi^*) \leq S(f,p).$
\idefin
Consideriamo una funzione $f$ e prendiamo una partizione $p$; 
definiamo l'\emph{ampiezza di suddivisione di $p$}\index{Ampiezza di una partizione} come $\delta(p)=\max_{i=1,\ldots,n}(x_i-x_{i-1})$.
Diciamo che 
$$\lim_{\delta\to 0}\mathfrak s(f,p,\xi^*)=I$$
se per ogni $\epsi>0$ esiste $\overline \delta$ tale che per ogni $p\in\mathscr P$ si ha $\delta(p)<\overline \delta$ e per ogni 
scelta dei punti base $\xi^*$ si ha $|\mathfrak s(f,p,\xi^*)-I|<\epsi.$
\edefin
Sfruttiamo questa definzione per dare una condizione necessaria e sufficiente per l'integrabilità:
\iteo
Una funzione $f$ è $R$-integrabile su $[a,b]$ se e solo se esiste $\lim_{\delta\to 0}\mathfrak s(f,p,\xi^*)$. In tal caso 
si pone $\int_a^b f(x)dx=\lim_{\delta\to 0}\mathfrak s(f,p,\xi^*).$\\
\newline
\dimo ($\Leftarrow$) Supponiamo che $\lim_{\delta\to 0}\mathfrak s(f,p,\xi^*)$ esista e sia pari ad $I$. 
Prendiamo due insiemi di punti base $\xi^*$ e $\eta^*$ in modo tale che, stando alla terminologia
usata nella definzione \ref{defintriemannmia}, si abbia
$$f(\xi_i^*)\leq m_i+\frac{\epsi}{b-a},\quad f(\eta_i^*)\leq M_i-\frac{\epsi}{b-a}.$$ 
A questo punto, grazie alla scelta fatta, vale
$$I-\epsi \leq \mathfrak s(f,p,\xi^*) \leq s(f,p) +\epsi,\quad I+\epsi \geq \mathfrak s(f,p,\xi^*) \geq S(f,p)-\epsi$$
da cui $S(f,p)\leq I+2\epsi$ e $s(f,p)\geq I-2\epsi$, da cui $S(f,p)-s(f,p)\leq 2\epsi$ e quindi $f$ è integrabile in
base al lemma \ref{condintriemannmia}.\\
($\Rightarrow$)\color{red}DA FINIRE E MANCA UN PEZZO DOPO\color{black}
\eteo
\end{section}
\begin{section}{Potenziali}
Consideriamo due punti, $P$ di coordinate $(X,Y,Z)$ e $Q$ di coordinate $(x,y,z)$; il punto $Q$ possieda una carica elettrica pari a $q$.
Il \emph{potenziale di una forza} $F$ \index{Potenziale di una forza} (che, dal punto di vista
matematico è un campo vettoriale) è una funzione $U$ tale che $F=-\nabla U.$
\footnote{Noi parleremo di potenziale elettrico, ma questo discorso vale, con le opportune modifiche, anche per quello gravitazionale}
La fisica ci dice (e noi ci fidiamo) che in questo caso il potenziale assume la forma 
$$u(X,Y,Z)=\frac{\epsi_0q}{\|PQ\|}$$
ove $\epsi_0$ è la \emph{costante dielettrica universale nel vuoto}\index{costante dielettrica universale}. Naturalmente, sarebbe inutile
da parte nostra accontentarci di sapere cosa succede con soli 2 punti, quindi mettiamoci in un caso molto più utile e complicato,
considerando un insieme bidimensionale elettricamente carico $\Omega$ e calcoliamone il potenziale in un punto $P=(X,Y,Z)\not\in\Omega$.\\
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\filldraw[line width=1.2pt, fill=green!30!white](2,8.5)..controls(4,9)..(6,11)..controls(8,13)and(12,12)..(12,10)
..controls(12,8)..(14,6)..controls(16,4)and(15,0)..(12,2)..controls(9,4)..(5,4)..controls(2,4)and(0,8)..(2,8.5);
\draw[step=1, ultra thin, draw=black] (0,0) grid (16,13);
\draw(8,7)node{$\Omega$};
\draw[line width=1.2pt](2,8.5)..controls(4,9)..(6,11)..controls(8,13)and(12,12)..(12,10)
..controls(12,8)..(14,6)..controls(16,4)and(15,0)..(12,2)..controls(9,4)..(5,4)..controls(2,4)and(0,8)..(2,8.5);
\filldraw[fill=black](20,8)circle(0.08);
\draw(21,8)node{$P$};
\end{tikzpicture}
\end{center}
\end{figure}
\lq\lq Quadrettiamo'' $\Omega$ in rettangolini; ogni rettangolino $R$ conterrà un po' di carica, sia $q_R$, e del resto ha sicuramente un area 
$A_R$, per cui possiamo definire la \emph{densità superficiale}\index{Densità! superficiale} $\delta_R$ del rettangolino come 
$\delta_R=q_R/A_R$. Per ogni punto $(x,y)$ di $\Omega$ prendiamo i rettangoli $R_{x,y}$, di area variabile $\delta$, che contengono
tale punto e definiamo una \lq\lq densità puntuale''\index{Densità!puntuale} (è solo un nome, non possiamo definire una \emph{vera} \lq\lq densità puntuale'', 
che non avrebbe senso dato che il punto non ha area)
$$\delta(x,y)=\lim_{\delta\to 0}\frac{\mathrm{carica}(R_{x,y},\delta)}{\mathrm{area}(R_{x,y},\delta)};$$
ora osserviamo che per ottenere la carica nell'immediato intorno di un punto \footnote{non possiamo
che ragionare così, per l'osservazione fatta prima sulla densità puntuale}
basta moltiplicare $\delta(x,y)$ per l'area del rettangolino infinitesimo di lati $dx$ e $dy$ che lo contiene, e la nostra 
esperienza di integratori provetti ci dice che a questo punto per ottenere il potenziale generato da $\Omega$ su $P$ basta integrare:
$$U(X,Y,Z)=\epsi_0\int_\Omega\frac{\delta(x,y)dxdy}{\sqrt{(X-x)^2+(Y-y)^2+Z^2}}.$$ 
In maniera del tutto analoga, se consideriamo un insieme $\Omega$ tridimensionale anzichè contenuto in un piano, varrà
$$U(X,Y,Z)=\epsi_0\int_\Omega\frac{\delta(x,y,z)dxdydz}{\sqrt{(X-x)^2+(Y-y)^2+(Z-z)^2}}.$$ 
\iesem
Supponiamo di avere un disco $D$ orizzontale, di raggio $R$, con centro nell'origine degli assi e carico elettricamente, con densità
puntuale di carica costante e pari a $q$.\\
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\shadedraw[inner color=green!10!white,outer color=green!30!white,draw=black](0,0,0)ellipse(5 and 2.5);
\draw[->](0,0,0)--(0,10,0);
\draw[->](0,0,0)--(10,0,0);
\draw[->](0,0,0)--(0,0,10);
\filldraw[fill=black](0,7,0)circle(0.08);
\draw(0.8,7,0)node{$P$};
\end{tikzpicture}
\end{center}
\end{figure}
Calcoliamo il potenziale nel punto $P=(0,0,h)$: 
$$U(0,0,h)=\int_D\frac{\epsi_0qdxdy}{\sqrt{x^2+y^2+h^2}}=\int_0^{2\pi} d\vartheta\int_0^R\frac{\epsi_0q\rho d\rho}{\sqrt{\rho^2+h^2}}=
2\pi\epsi_0q(\sqrt{R^2+h^2}-|h|).$$
\eesem
\iesem
Calcoliamo il potenziale generato da una sfera piena $\Theta$, carica con densità
puntuale costante pari a $q$ e di raggio $R$ nel punto $P=(0,0,h)$ (nel corso dei calcoli, con la notazione
$D_z$ indicheremo il disco individuato dall'intersezione tra il piano orizzontale di altezza $z$ e $\Theta$; inoltre
supporremo che $h$ sia più in alto del polo nord della sfera per evitare fastidiosi cambi di segno dell'integrale): \\
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\filldraw[fill=black](0,7,0)circle(0.08);
\shade[ball color=green!30!white](0,0,0)circle(5);
\draw[dashed,ultra thin](0,0)ellipse(5 and 2.5);
\draw[rotate=90,ultra thin,dashed](0,0)ellipse(5 and 2.5);
\draw[->](0,0,0)--(0,10,0);
\draw[->](0,0,0)--(10,0,0);
\draw[->](0,0,0)--(0,0,10);
\draw(0.8,7,0)node{$P$};
\end{tikzpicture}
\end{center}
\end{figure}
\begin{multline*}
U(0,0,h)=\int_\Theta\frac{\epsi_0qdxdydz}{\sqrt{x^2+y^2+(h-z)^2}}=\int_{-R}^Rdz\int_{D_z}\frac{\epsi_0qdxdy}{\sqrt{x^2+y^2+(h-z)^2}}=\\
\\=2\pi\epsi_0q\int_{-R}^R \sqrt{R^2+h^2-2hz}-(h-z)dz=\frac{4\pi R^3}{3h}q\epsi_0.
\end{multline*}
\eesem
\end{section}
\begin{section}{Area di una superficie}
\idefin Una \emph{superficie parametrizzata}\index{Superficie parametrizzata} è una coppia $(\varphi, \Sigma)$, con $\varphi: D\sse \R^{n}\to \R^{n+1}$,
ove $D$ è aperto, $\varphi\in \mathcal C^1(\overline D)$ e $\Sigma=\varphi(\overline D)$.
\edefin
Il problema delle superfici è definirne l'area, come dimostra il seguente
\iesem\textbf{(cilindro di Schwarz)}\index{Cilindro di Schwarz} Cerchiamo di calcolare la superficie laterale del cilindro retto di raggio
$r$ ed altezza $h$ \lq\lq triangolandola''. \footnote {che è una mossa 
stupida per il cilindro, ma se la triangolazione, che appare un metodo più che sensato per calcolare la superficie, è un'idea valida 
deve funzionare in \emph{ogni} caso} Dividiamo la superficie laterale in $m$ fasce orizzontali e approssimiamo ognuna delle circonferenze
individuate, comprese le due basi, con un poligono di $n$ lati (per capirci, chiameremo dischi questi poligoni inscritti nei cerchi):\\
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.3]
\shadedraw[left color=green!30!white, right color=green!10!white, draw=black](5,0,0)--(5,10,0)--(-5,10,0)--(-5,0,0)--cycle;
\shadedraw[left color=green!30!white, right color=green!10!white, draw=black](0,0,0)ellipse(5 and 2.5);
\filldraw[fill=white](0,10,0)ellipse(5 and 2.5);
\draw[dashed](0,2.5,0)ellipse(5 and 2.5);
\draw[dashed](0,5,0)ellipse(5 and 2.5);
\draw[dashed](0,7.5,0)ellipse(5 and 2.5);
\draw(15,5,0)circle(5);
\draw(2.5+15,5-0.866*5,0)--(5+15,0+5,0)--(2.5+15,5+0.866*5,0)--(-2.5+15,5+0.866*5,0)--(-5+15,5+0,0)--(-2.5+15,5-0.866*5,0)--cycle;
\draw(15,5,0)--(5+15,0+5,0);
\draw(15,5,0)--(2.5+15,5+0.866*5,0);
\draw(17.5,5.5,0)node{\small $2\pi/n$};
\draw(16,5,0)arc(0:60:1);
\draw[|-|](-5.75,2.5,0)--(-5.75,5,0);
\draw(-7.5,2.5+0.5*2.5,0)node{\small$ h/m$};
\end{tikzpicture}
\end{center}
\end{figure}
\newline
Disponiamo ogni disco ruotato di $2\pi/n$ (sempre nello stesso senso) rispetto a quello che sta sotto, così che congiungendo 
ogni vertice di un disco con i due più vicini di quello sotto otteniamo, ad ogni \lq\lq piano'' del cilindro, una superficie
come questa:\\
\begin{figure}[h!]
\begin{center}
\begin{tikzpicture}[scale=0.5]
\draw(2.5,0,-0.866*5)--(5,0,0)--(2.5,0,0.866*5)--(-2.5,0,0.866*5);
\draw(0,4,-5)--(0.866*5,4,-2.5)--(0.866*5,4,2.5)--(0,4,5)--(-0.866*5,4,2.5)--(-0.866*5,4,-2.5)--cycle;
\filldraw[fill=green!50!white, draw=black](-5,0,0)--(-0.866*5,4,2.5)--(-2.5,0,0.866*5)--cycle;
\filldraw[fill=green!30!white, draw=black](-2.5,0,0.866*5)--(0,4,5)--(2.5,0,0.866*5)--cycle;
\filldraw[fill=green!20!white, draw=black](0.866*5,4,-2.5)--(5,0,0)--(0.866*5,4,2.5)--cycle;
\filldraw[fill=green!10!white, draw=black](0.866*5,4,2.5)--(2.5,0,0.866*5)--(5,0,0)--cycle;
\filldraw[fill=green!20!white, draw=black](2.5,0,0.866*5)--(0.866*5,4,2.5)--(0,4,5)--cycle;
\filldraw[fill=green!40!white, draw=black](-2.5,0,0.866*5)--(0,4,5)--(-0.866*5,4,2.5)--cycle;
\draw[dashed](0.866*5,4,-2.5)--(2.5,0,-0.866*5);
\draw[dashed](0,4,-5)--(2.5,0,-0.866*5);
\draw[dashed](0,4,-5)--(-2.5,0,-0.866*5);
\draw[dashed](-0.866*5,4,-2.5)--(-5,0,0);
\draw[dashed](-0.866*5,4,-2.5)--(-2.5,0,-0.866*5);
\draw[dashed](-2.5,0,0.866*5)--(-5,0,0)--(-2.5,0,-0.866*5)--(2.5,0,-0.866*5)--(5,0,0);
\draw(0,4.5,5)node{$P$};
\draw(0.5,0,5)node{$H$};
\draw[dashed](0,4,5)--(0,0,0.866*5);
\end{tikzpicture}
\end{center}
\end{figure}
\newline
L'area della superficie del cilindro sarà pertanto in funzione dei $2mn$ triangoli (tutti uguali), cioè di $n$ e $m$, e
sarà pari alla somma di tutte le aree dei triangoli $T$ ovvero $A=2nmA_T$; il problema è appunto calcolare $A_T$, che è il semiprodotto
della base per l'altezza. Per la base il problema è di facile risoluzione, perchè coincide con la lunghezza del lato del poligono
regolare inscritto, e si calcola più che facilmente che esso è pari a $2r\sin\frac\pi n$. Per l'altezza, facendo riferimento
alla figura, avremo 
$$P=\Big(x,r\cos^2 \frac\pi n ,r\sin\frac\pi n\cos\frac\pi n\Big),\quad H=\Big(x-\frac h m,r\cos \frac\pi n,r\sin\frac\pi n\Big)$$
e quindi l'altezza dei triangoli è pari a
\begin{multline*}
|PH|=\sqrt{\frac{h^2}{m^2}+r^2\cos^2 \frac\pi n\Big(1-\cos^2 \frac\pi n\Big)^2+r^2\sin^2 \frac\pi n\Big(1-\cos^2 \frac\pi n\Big)^2}=\\
= \sqrt{\frac{h^2}{m^2}+r^2\Big(1-\cos^2 \frac\pi n\Big)^2}
\end{multline*}
e pertanto l'area del poliedro è 
\begin{multline*}
2mnA_T=2mnr\sin\frac\pi n\sqrt{\frac{h^2}{m^2}+r^2\Big(1-\cos^2 \frac\pi n\Big)^2}=\\
=2\pi  \frac n\pi r\sin \frac\pi n \sqrt{h^2+r^2m^2\Big(1-\cos^2 \frac\pi n\Big)^2}=\\
=\underbrace{2\pi rh}_{\textrm{Area cilindro}}\cdot \frac n\pi \sin \frac\pi n\cdot
\sqrt{1+\frac{r^2m^2}{h^2}\Big(1-\cos^2 \frac\pi n\Big)^2} \sim_{n\to \infty}\\
 \sim_{n\to \infty}2\pi rh \cdot 1\cdot \sqrt{1+\frac{r^2m^2}{h^2}\Big( \frac{\pi^2}{2n^2}\Big)^2}=
2\pi rh \cdot 1\cdot \sqrt{1+\frac{\pi^4r^2}{4h^2}\frac{m^2}{n^4}}
\end{multline*}
ma $m^2/n^4$ ci crea dei problemi, perchè se per caso $m=kn^2$ abbiamo che il limite per $n\to \infty$ dell'area del poliedro è
$$2\pi rh \cdot 1\cdot \sqrt{1+\frac{\pi^4r^2}{4h^2}k^2}$$
e il terzo fattore del prodotto è arbitrariamente grande al variare di $k$, per cui non ci siamo; la triangolazione non è una buona idea per
calcolare la superficie laterale del cilindro.
\eesem
Questo esempio serve per dire che non sempre quello che sembra intuitivo è la scelta corretta; per questo la dimostrazione della fondatezza 
dell definizione di area, che segue, è enunciata senza dimostrazione (diabolicamente difficile):
\idefin
Data una superficie parametrizzata $\varphi:\R^n\to\R^{n+1}$, definiamo \emph{area della superficie}\index{Area di una superficie} la quantità
$$\int_D\|\varphi_{u_1}\wedge \varphi_{u_2}\wedge\ldots \wedge \varphi_{u_n}\|du_1du_2\ldots du_n$$
ove $\varphi_{u_i}$ è la derivata parziale della $\varphi$ rispetto alla $i$-esima variabile. 
\edefin
Il prodotto vettore di $n$-vettori $v_1,\ldots, v_n$ di $\R^{n+1}$ si esegue, come nel caso di 2 vettori di $\R^3$, calcolando il determinante 
(detto \emph{gramiano}\index{Determinante gramiano}, dal matematico Gram) della matrice 
che ha nella prima riga i vettori $e_1,\ldots, e_{n+1}$ della base standard di $\R^{n+1}$ e nelle altre righe le componenti dei vettori $v_i$.
\idefin
Due parametrizzazioni $\varphi_1:D_1\to \R^n$ e  $\varphi_2:D_2\to \R^n$ di una stessa
superficie $\Sigma$ sono \emph{equivalenti}\index{Superficie parametrizzata!equivalente} se esiste un diffeomorfismo $h:D_1\to D_2$  tale che
$\varphi_1=\varphi_2\circ h.$
\edefin
\iprop
L'area della superficie non dipende dalla parametrizzazione scelta.\\
\newline
\dimo Dimostriamolo nel caso di una superficie in $\R^3$; sia $\varphi(u_1,u_2)=(\varphi^1(u_1,u_2),\varphi^2(u_1,u_2),\varphi^3(u_1,u_2))$, 
$h(x_1,x_2)=(h^1(x_1,x_2),h^2(x_1,x_2))$
e poniamo $\psi=\varphi \circ h$. A questo punto
\bd
\psi_{x_1}(x_1,x_2)=
\left[
\begin{matrix}
\frac{\partial \psi^1 }{\partial x_1} (x_1,x_2)\\
\frac{\partial \psi^2 }{\partial x_1} (x_1,x_2)\\
\frac{\partial \psi^2 }{\partial x_1} (x_1,x_2)\\
\end{matrix}
\right]=
\left[
\begin{matrix}
\Big\langle \frac{\partial \varphi^1}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_1} (x_1,x_2)\Big\rangle\\
\Big\langle \frac{\partial \varphi^2}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_1} (x_1,x_2)\Big\rangle\\
\Big\langle \frac{\partial \varphi^3}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_1} (x_1,x_2)\Big\rangle\\
\end{matrix}
\right]
\ed
\bd
\psi_{x_2}(x_1,x_2)=
\left[
\begin{matrix}
\frac{\partial \psi^1 }{\partial x_2} (x_1,x_2)\\
\frac{\partial \psi^2 }{\partial x_2} (x_1,x_2)\\
\frac{\partial \psi^2 }{\partial x_2} (x_1,x_2)\\
\end{matrix}
\right]=
\left[
\begin{matrix}
\Big\langle \frac{\partial \varphi^1}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_2} (x_1,x_2)\Big\rangle\\
\Big\langle \frac{\partial \varphi^2}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_2} (x_1,x_2)\Big\rangle\\
\Big\langle \frac{\partial \varphi^3}{\partial u_i}(u_1(x_1,x_2),u_2(x_1,x_2)),\frac{\partial h^i}{\partial x_2} (x_1,x_2)\Big\rangle\\
\end{matrix}
\right]
\ed
Ora, facendo fare a qualcun altro i calcoli, si riesce a dimostrare che 
$$\|\psi_{x_1}\wedge \psi_{x_2}\|=\|\varphi_{u_1}\wedge \varphi_{u_2}\det J_h\|$$
e concludiamo osservando che il secondo membro dell'equazione è esattamente quello che otterremo
se avessimo effettuato un cambio di variabile dell'integrale che definisce la superficie di $\varphi,$ per cui visto che
l'integrale avrebbe avuto dominio $h(D)$, abbiamo ottenuto la tesi.
\eprop
\end{section}
\begin{section}{$k$-forme}
Riprendiamo ed approfondiamo lo studio delle forme differenziali:
\idefin
Definiamo \emph{0-forme}\index{0-forma} le funzioni $f:\R^3\to\R$ di classe $\mathcal C^k$ definite su di un aperto; chiamiamo
\emph{1-forma}\index{1-forma} l'espressione
$$\omega=\sum_{i=1}^3a_{i}(x_1,x_2,x_3)dx_i.$$
\edefin
Notiamo che i $dx_i$ sono una base per lo spazio delle 1-forme (i coefficienti sono le funzioni).
Osserviamo che il differenziale di una 0-forma è una 1-forma: $$df=\sum_{i=1}^3 \frac{\partial f}{\partial x_i}dx_i;$$
inoltre sappiamo già che le 1-forme si integrano sulle 1-superfici, cioè le curve da
$[a,b]$ a $\R^3$ (vedi il lavoro di una forza) e vale
$$\int_\gamma\omega=\int_a^b \sum_{i=1}^3 a_i(\gamma(u))\gamma_i'(u)du.$$ In particolare, se $\omega=df$ (in tal caso
si dice che è \emph{esatta}), per il teorema 
fondamentale del calcolo integrale, vale $\int_\gamma df=f(\gamma(b)-\gamma(a))$ e dunque se la curva è chiusa
l'integrale è nullo. 
\idefin
Una forma bilineare $\alpha:E\times E\to \R$ si dice \emph{bilineare}\index{Forma!bilineare} se è lineare in ogni variabile, ed
inoltre si dice \emph{alternata}\index{Forma!bilineare!alternata} se $\alpha(u,v)=-\alpha(v,u)$.
\edefin
Esempi di forma bilineare alternate sono $\alpha(\vec u,\vec v)=\|\vec u\|\|\vec v\|\sin\vartheta$ e
$\alpha(\vec u,\vec v)=\det \left[\begin{matrix} u_1 & u_2\\ v_1 & v_2\end{matrix}\right]=u_1v_2-u_2v_1$. Cerchiamo
ora di definire una base per lo spazio delle forme bilineari alternate: sappiamo dall'algebra lineare che 
ogni applicazione lineare è rappresentata su una base da una matrice, ed in particolare una matrice antisimmetrica
rappresenta una forma bilineare antisimmetrica su tale base. Definiamo un applicazione $\alpha=dx_i\wedge dx_j$
in modo tale che $dx_i\wedge dx_j=0$ se $i=j$ mentre se $i\neq j$ si abbia
\bd
\alpha(e_k,e_\ell)=\left\{\begin{array}{cl} 1 & (k,\ell)=(i,j)\\ -1 & (k,\ell)=(j,i)\\ 0 & \textrm{altrimenti}\end{array}\right.
\ed
Tale applicazione è rappresentata da una matrice di questo tipo:
$\left[\begin{matrix} 0 & 0 & 0 \\ 0 & 0 & 1_{ij} \\ 0 & -1_{ji} & 0 \end{matrix}\right]$. Si
vede subito che una qualsiasi matrice antisimmetrica è combinazione lineare di matrici di questo
tipo, che quindi costituiscono una base per lo spazio delle matrici antisimmetriche; ne segue che 
$dx_i\wedge dx_j$ è una base per lo spazio delle forme bilineari alternate, e questo ci serve per la prossima
\idefin
Una $2-forma$\index{2-forma} è un'applicazione da $A\sse \R^3$ nello spazio delle forme bilineari alternate, ovvero
$$\omega=\sum_{i=1}^3\sum_{j=1}^3a_{ij}(x_1,x_2,x_3)dx_i\wedge dx_j.$$
\edefin
Notiamo che \lq\lq ufficialmente'' $\omega$ ha 9 termini, ma di fatto quelli non nulli sono solo 6 perchè $dx_i\wedge dx_i=0$.
Segue dalla definizione che il differenziale di una 1-forma è una 2-forma:
\iesem
Sia $\vec F$ un campo vettoriale e sia $\omega=F_1dx_1+F_2dx_2+F_3dx_3$:
\begin{multline*}
d\omega=\frac{\partial F_1}{\partial x_2} dx_2\wedge dx_1+\frac{\partial F_1}{\partial x_3} dx_3\wedge dx_1+\frac{\partial F_2}{\partial x_1} dx_1\wedge dx_2+\\
+\frac{\partial F_2}{\partial x_3} dx_3\wedge dx_2+\frac{\partial F_3}{\partial x_1} dx_1\wedge dx_3+\frac{\partial F_3}{\partial x_2} dx_2\wedge dx_3=\\
=\Big(\frac{\partial F_1}{\partial x_2}-\frac{\partial F_2}{\partial x_1}\Big)dx_2\wedge dx_1+
\Big(\frac{\partial F_1}{\partial x_3}-\frac{\partial F_3}{\partial x_1}\Big) dx_3\wedge dx_1+
\Big(\frac{\partial F_2}{\partial x_3}-\frac{\partial F_3}{\partial x_2}\Big) dx_3\wedge dx_2
\end{multline*}
\eesem
Le quantità scritte tra parentesi compaiono spesso nello studio delle forme, quindi gli diamo un nome:
\idefin
Definiamo \emph{rotore} di un campo $\vec F$\index{Rotore} il vettore
$$\Big[\frac{\partial F_1}{\partial x_2}-\frac{\partial F_2}{\partial x_1},\quad  
\frac{\partial F_1}{\partial x_3}-\frac{\partial F_3}{\partial x_1},\quad 
\frac{\partial F_2}{\partial x_3}-\frac{\partial F_3}{\partial x_2}\Big]$$
che, in notazione del tutto formale, dato il vettore 
$$\frac{\partial }{\partial x}=\Big[\frac{\partial }{\partial x_1},\frac{\partial }{\partial x_2},\frac{\partial }{\partial x_3}\Big]$$
può essere scritto come $\frac{\partial }{\partial x} \wedge \vec F$
\edefin 
Come le 1-forme si integrano sulle 1-superfici, le curve, le 2-forme si integrano sulle 2-superfici, ovvero le superfici nel senso abituale in cui 
le conosciamo; per l'esattezza data la superficie $(\varphi,\Sigma)$, con $\varphi(u,v)=(\varphi^1(u,v),\varphi^2(u,v),\varphi^3(u,v))$ la formula
che esprime il valore della 2-forma sulla 2-superficie è
$$\int_\Sigma \sum_{i=1}^3\sum_{j=1}^3a_{ij}(x_1,x_2,x_3)dx_i\wedge dx_j=
\int_\Sigma \sum_{i=1}^3\sum_{j=1}^3a_{ij}(\varphi(u,v))\frac{\partial (\varphi^i,\varphi^j)}{\partial (u,v)} dudv,$$
ove per definizione poniamo 
$$\frac{\partial (\varphi^i,\varphi^j)}{\partial (u,v)}= \frac{\partial \varphi^i}{\partial u}\frac{\partial \varphi^j}{\partial v}- 
\frac{\partial \varphi^i}{\partial v}\frac{\partial \varphi^j}{\partial u}=
\det\left[\begin{matrix}  \frac{\partial \varphi^i}{\partial u}&  \frac{\partial \varphi^i}{\partial v}
\\\frac{\partial \varphi^j}{\partial u} &  \frac{\partial \varphi^j}{\partial v}  \end{matrix}\right].$$
Si può dimostrare che il valore dell'integrale delle 2-forme su due  superfici equivalenti non dipende, a meno del segno del determinante della jacobiana
del diffeomorfismo, dalla parametrizzazione scelta.
\idefin
Sia $(\varphi,\Sigma)$ una 2-superficie parametrizzata e $\varphi(u_0,v_0)$ un punto di $\Sigma$. Se
$\frac{\partial \varphi}{\partial u}(u_0,v_0) \wedge \frac{\partial \varphi}{\partial v}(u_0,v_0)\neq 0$, definiamo
il \emph{vettore normale a $\Sigma$ in $(u_0,v_0)$}\index{Vettore normale} come
$$\vec N(\varphi(u_0,v_0))=\frac{\frac{\partial \varphi}{\partial u} (u_0,v_0)\wedge \frac{\partial \varphi}{\partial v}(u_0,v_0)}
{\Big\|\frac{\partial \varphi}{\partial u} (u_0,v_0)\wedge \frac{\partial \varphi}{\partial v}(u_0,v_0)\Big\|}$$
\edefin
questo ci serve per la prossima
\iprop
Dato un campo $\vec F$, sia $\omega=F_1dx_2\wedge dx_3 +F_2dx_3\wedge dx_1 +F_3dx_1 \wedge dx_1$. Allora l'integrale di $\omega$
su una superficie $(\varphi, \Sigma)$, con $\varphi:D\sse \R^2 \to\R^3$, è uguale all'integrale su $D$ del prodotto
scalare tra $\vec F(\varphi(u,v))$ ed il vettore normale.\\
\newline
\dimo Abbiamo
\begin{multline*}
\int_\Sigma\omega= \int_\Sigma F_1dx_2\wedge dx_3 +F_2dx_3\wedge dx_1 +F_3dx_1 \wedge dx_1=\\
=\int_D F_1(\varphi(u,v))\Big(\frac{\partial \varphi^2}{\partial u}\frac{\partial \varphi^3}{\partial v}- 
\frac{\partial \varphi^2}{\partial v}\frac{\partial \varphi^3}{\partial u}\Big) -
-F_2(\varphi(u,v))\Big(\frac{\partial \varphi^3}{\partial u}\frac{\partial \varphi^1}{\partial v}- 
\frac{\partial \varphi^3}{\partial v}\frac{\partial \varphi^1}{\partial u}\Big)+\\
F_3(\varphi(u,v))\Big(\frac{\partial \varphi^1}{\partial u}\frac{\partial \varphi^2}{\partial v}- 
\frac{\partial \varphi^2}{\partial v}\frac{\partial \varphi^1}{\partial u}\Big)dudv=
\int_D\det\left[ \begin{matrix} F_1 & F_2 & F_3 \\ \frac{\partial \varphi^1}{\partial u} & \frac{\partial \varphi^2}{\partial u} & \frac{\partial \varphi^3}{\partial u}\\ 
 \frac{\partial \varphi^1}{\partial v} & \frac{\partial \varphi^2}{\partial v} & \frac{\partial \varphi^3}{\partial v}\end{matrix}\right]dudv=\\
\\=\int_D\vec F(\varphi(u,v))\Big( \frac{\partial \varphi}{\partial u}\wedge  \frac{\partial \varphi}{\partial v} \Big)dudv=
\int_D\langle \vec F (\varphi(u,v)), \vec N\rangle \|\vec N\|dudv. 
\end{multline*}
Notiamo che 
$$\int_D\langle \vec F (\varphi(u,v)), \vec N\rangle \|\vec N\|dudv=\int_\Sigma\langle \vec F (\varphi(u,v)), \vec N\rangle d\sigma$$
e quest'ultima espressione si chiama \emph{flusso di $\vec F$ attraverso $\Sigma$}\index{Flusso}.
\eprop
Finiamo dimostrando il seguente
\iteo\textbf{(Stokes)}\index{Teorema!di Stokes}
Sia $\omega$ una 1-forma in $\R^3$ e $\Sigma$ una 2-superficie parametrizzata su un insieme $D$. Allora  
$$\int_\Sigma d\omega=\int_{\partial^+ \Sigma}\omega.$$\\
\newline
\dimo Osserviamo che $\partial^+ \Sigma$ non è altro che una curva e per l'esattezza è l'immagine tramite la parametrizzazione
del bordo di $D$; allora si capisce bene che
$$\int_{\partial^+ \Sigma}\omega=\int_{\partial^+ \Sigma}\sum_{i=1}^3a_i(x_1,x_2,x_3)dx_i=$$
\color{red}finire\color{black}
\eteo
\end{section}
\end{chapter}
\newpage
\thispagestyle{empty} 
\
\newpage
\pagenumbering{Roman}
\printindex
\end{document}